@startuml
!theme plain
skinparam componentStyle rectangle
skinparam dpi 300

package "Local Development Environment" {
  
  component "RunPod Proxy Simulator\n(FastAPI)\nPort 8008" as Proxy {
    database "In-Memory Job Store" as JobStore
    component "Worker Queues\n(Per Endpoint)" as Queues
    component "Background Workers\n(Async Loops)" as Workers
  }
  
  component "Assessment Worker\n(Docker Container)\nPort 8001" as WorkerAssessment {
    component "POWSM Models\n(PR + G2P)" as Models
    component "MFA Alignment" as MFA
  }
  
  component "IPA Generation Worker\n(Docker Container)\nPort 8002" as WorkerIPA {
    component "POWSM G2P Model" as G2PModel
  }
  
  component "Application Server\n(Local Development)" as AppServer
}

' Configuration
component "Docker Compose\nConfiguration" as DockerCompose {
  note right
    WORKER_MAP environment variable:
    {
      "pronunciation-assessment": 
        "http://worker-assessment:8000",
      "ipa-generation": 
        "http://worker-generation:8000"
    }
  end note
}

' Flow
AppServer --> Proxy : POST /v2/{endpoint_id}/run
Proxy --> JobStore : Store Job (IN_QUEUE)
Proxy --> Queues : Enqueue Job
Queues --> Workers : Pull Job
Workers --> WorkerAssessment : POST /runsync (if assessment)
Workers --> WorkerIPA : POST /runsync (if IPA)
WorkerAssessment --> Models : Inference
WorkerAssessment --> MFA : Alignment
WorkerIPA --> G2PModel : Inference
WorkerAssessment --> Proxy : Return Results
WorkerIPA --> Proxy : Return Results
Proxy --> JobStore : Update Status (COMPLETED)
Proxy --> AppServer : Webhook Callback (if configured)

AppServer --> Proxy : GET /v2/{endpoint_id}/status/{job_id}
Proxy --> JobStore : Retrieve Job Status

note right of Proxy
  Simulates RunPod Cloud API:
  - Job queuing
  - Status polling
  - Webhook delivery
  - Sequential processing per worker
end note

note right of Workers
  Background async loops
  One per endpoint
  Handles retries and timeouts
end note

note right of Queues
  Ensures sequential processing
  Mimics single GPU pod behavior
end note

@enduml

