{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "# allow `import mod.assessment` when notebook lives in sig/exp\n",
        "repo_root = Path(\"../../mod\")\n",
        "sys.path.insert(0, str(repo_root.absolute()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from espnet2.bin.s2t_inference import Speech2Text\n",
        "from assessment.edit_distance import edit_operations\n",
        "\n",
        "DEVICE = \"cpu\"  # set to \"cuda\" if available\n",
        "LANG = \"<eng>\"\n",
        "PR_MODEL = \"espnet/powsm\"\n",
        "G2P_MODEL = \"espnet/powsm\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AUDIO_PATH = Path(\"/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/audio/powsm/12/umit12-r.wav\")\n",
        "TARGET_TEXT = \"The weather is rather warm this Thursday. I think we should go to the theater together. Thank you for thinking about this thoroughly.\"\n",
        "\n",
        "speech, rate = sf.read(AUDIO_PATH)\n",
        "if rate != 16000:\n",
        "    raise ValueError(f\"Expected 16kHz audio, got {rate}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pr = Speech2Text.from_pretrained(PR_MODEL, device=DEVICE, task_sym=\"<pr>\", lang_sym=LANG)\n",
        "g2p = Speech2Text.from_pretrained(G2P_MODEL, device=DEVICE, task_sym=\"<g2p>\", lang_sym=LANG)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_pred(raw: str) -> tuple[str, list[str]]:\n",
        "    if \"<notimestamps>\" in raw:\n",
        "        raw = raw.split(\"<notimestamps>\")[1]\n",
        "    raw = raw.strip()\n",
        "    tokens = []\n",
        "    for part in raw.split(\"//\"):\n",
        "        part = part.strip()\n",
        "        if not part:\n",
        "            continue\n",
        "        if part.startswith(\"/\"):\n",
        "            part = part[1:]\n",
        "        if part.endswith(\"/\"):\n",
        "            part = part[:-1]\n",
        "        if part:\n",
        "            tokens.append(part)\n",
        "    return raw, tokens\n",
        "\n",
        "\n",
        "def run_pr(audio):\n",
        "    raw = pr(audio, text_prev=\"<na>\")[0][0]\n",
        "    return parse_pred(raw)\n",
        "\n",
        "\n",
        "def run_g2p(text: str, audio=None):\n",
        "    audio_in = audio if audio is not None else np.zeros(1600, dtype=np.float32)\n",
        "    raw = g2p(audio_in, text_prev=text)[0][0]\n",
        "    return parse_pred(raw)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "ARPA_TO_IPA = {\n",
        "    \"AA\": \"ɑ\", \"AE\": \"æ\", \"AH\": \"ə\", \"AO\": \"ɔ\", \"AW\": \"aʊ\", \"AY\": \"aɪ\",\n",
        "    \"B\": \"b\", \"CH\": \"tʃ\", \"D\": \"d\", \"DH\": \"ð\", \"EH\": \"ɛ\", \"ER\": \"ɝ\",\n",
        "    \"EY\": \"eɪ\", \"F\": \"f\", \"G\": \"ɡ\", \"HH\": \"h\", \"IH\": \"ɪ\", \"IY\": \"i\",\n",
        "    \"JH\": \"dʒ\", \"K\": \"k\", \"L\": \"l\", \"M\": \"m\", \"N\": \"n\", \"NG\": \"ŋ\",\n",
        "    \"OW\": \"oʊ\", \"OY\": \"ɔɪ\", \"P\": \"p\", \"R\": \"ɹ\", \"S\": \"s\", \"SH\": \"ʃ\",\n",
        "    \"T\": \"t\", \"TH\": \"θ\", \"UH\": \"ʊ\", \"UW\": \"u\", \"V\": \"v\", \"W\": \"w\",\n",
        "    \"Y\": \"j\", \"Z\": \"z\", \"ZH\": \"ʒ\",\n",
        "}\n",
        "\n",
        "\n",
        "def arpa_seq_to_ipa(arpa_seq):\n",
        "    ipa_seq = []\n",
        "    for sym in arpa_seq:\n",
        "        base = sym.rstrip(\"012\")\n",
        "        ipa_seq.append(ARPA_TO_IPA.get(base, base.lower()))\n",
        "    return \"\".join(ipa_seq)\n",
        "\n",
        "\n",
        "def cmu_target_ipa(text: str) -> str:\n",
        "    try:\n",
        "        import cmudict\n",
        "    except ImportError as e:\n",
        "        raise ImportError(\"cmudict not installed; install with `pip install cmudict`\") from e\n",
        "\n",
        "    cmu = cmudict.dict()\n",
        "    words = re.findall(r\"[A-Za-z']+\", text.lower())\n",
        "    ipa_parts = []\n",
        "    for w in words:\n",
        "        pron_list = cmu.get(w)\n",
        "        if not pron_list:\n",
        "            continue  # skip OOV\n",
        "        ipa_parts.append(arpa_seq_to_ipa(pron_list[0]))\n",
        "    return \"\".join(ipa_parts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "CACHE_DIR = Path(\"cache\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def cache_path(audio_path: Path) -> Path:\n",
        "    return CACHE_DIR / f\"{audio_path.stem}.json\"\n",
        "\n",
        "def load_cached(audio_path: Path):\n",
        "    p = cache_path(audio_path)\n",
        "    if not p.exists():\n",
        "        return None\n",
        "    try:\n",
        "        return json.loads(p.read_text())\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def save_cached(audio_path: Path, data: dict):\n",
        "    cache_path(audio_path).write_text(json.dumps(data, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "guided_CACHE_DIR = Path(\"cache/guided\")\n",
        "guided_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def guided_cache_path(audio_path: Path) -> Path:\n",
        "    return guided_CACHE_DIR / f\"{audio_path.stem}.guided.json\"\n",
        "\n",
        "def load_cached_guided(audio_path: Path) -> str | None:\n",
        "    p = guided_cache_path(audio_path)\n",
        "    if not p.exists():\n",
        "        return None\n",
        "    try:\n",
        "        data = json.loads(p.read_text())\n",
        "        return data.get(\"guided_ipa\")\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def save_cached_guided(audio_path: Path, guided_ipa: str):\n",
        "    guided_cache_path(audio_path).write_text(json.dumps({\"guided_ipa\": guided_ipa}, ensure_ascii=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_ipa = cmu_target_ipa(TARGET_TEXT)\n",
        "\n",
        "cached = load_cached(AUDIO_PATH)\n",
        "\n",
        "if cached and \"actual_ipa\" in cached:\n",
        "    actual_ipa = cached[\"actual_ipa\"]\n",
        "else:\n",
        "    actual_ipa = run_pr(speech)\n",
        "\n",
        "if cached and \"guided_ipa\" in cached:\n",
        "    guided_ipa = cached[\"guided_ipa\"]\n",
        "else:\n",
        "    guided_ipa = run_g2p(TARGET_TEXT, speech)\n",
        "\n",
        "token_actual = tokenize_ipa(actual_ipa)\n",
        "token_guided = tokenize_ipa(guided_ipa)\n",
        "token_target = tokenize_ipa(target_ipa)\n",
        "\n",
        "if not cached or (\"actual_ipa\" not in cached or \"guided_ipa\" not in cached):\n",
        "    save_cached(AUDIO_PATH, {\n",
        "        \"actual_ipa\": actual_ipa,\n",
        "        \"guided_ipa\": guided_ipa,\n",
        "        \"token_actual\": token_actual,\n",
        "        \"token_guided\": token_guided,\n",
        "        \"token_target\": token_target,\n",
        "    })\n",
        "\n",
        "ops = edit_operations(token_actual, token_target)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "summary = {\n",
        "    \"target_text\": TARGET_TEXT,\n",
        "    \"target_ipa\": token_target,\n",
        "    \"actual_ipa\": token_actual,\n",
        "    \"guided_ipa\": token_guided,\n",
        "    \"ops\": ops,\n",
        "    \"ops_len\": len(ops),\n",
        "}\n",
        "print(summary)\n",
        "# save summary to json\n",
        "with open(\"powsm_minimal.json\", \"w\") as f:\n",
        "    json.dump(summary, f, ensure_ascii=False, indent=4)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
