{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pronunciation Assessment with Timestamped Feedback\n",
        "\n",
        "This notebook demonstrates the complete workflow for pronunciation assessment:\n",
        "\n",
        "1. **POWSM Phone Recognition (PR)** - Extract actual IPA phones from audio\n",
        "2. **POWSM G2P** - Generate target IPA from English text\n",
        "3. **MFA Alignment** - Align phones to timestamps in audio\n",
        "4. **Error Detection** - Compare actual vs target IPA\n",
        "5. **Timestamp Mapping** - Map errors to audio timestamps\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking for MFA availability...\n",
            "======================================================================\n",
            "MFA Setup: Hybrid Conda/Venv Configuration\n",
            "======================================================================\n",
            "This notebook runs in a Python venv but uses MFA from a conda environment.\n",
            "MFA requires Kaldi, kalpy, and OpenFST which are conda-only packages.\n",
            "======================================================================\n",
            "\n",
            "âœ“ Found conda MFA at: /Users/umitcanevleksiz/miniconda3/envs/aligner/bin/mfa\n",
            "  Conda environment: /Users/umitcanevleksiz/miniconda3/envs/aligner\n",
            "  âœ“ Dependencies check passed (OpenFST, Kaldi found)\n",
            "\n",
            "âœ“ MFA is available and ready to use!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import json\n",
        "import shutil\n",
        "from typing import Dict, List\n",
        "\n",
        "# Add mod directory to path for imports\n",
        "mod_path = Path(\"../../mod\")\n",
        "sys.path.insert(0, str(mod_path.absolute()))\n",
        "\n",
        "# POWSM imports\n",
        "from espnet2.bin.s2t_inference import Speech2Text\n",
        "from espnet2.bin.s2t_inference_language import Speech2Language\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# MFA availability check\n",
        "# MFA requires Kaldi/kalpy which are conda packages\n",
        "# We need to find the conda MFA, not the venv one (which lacks kalpy)\n",
        "import subprocess\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "MFA_AVAILABLE = False\n",
        "MFA_CMD = None\n",
        "\n",
        "def find_conda_mfa():\n",
        "    \"\"\"Try to find MFA in conda environments.\"\"\"\n",
        "    # Common conda installation paths\n",
        "    conda_bases = [\n",
        "        os.path.expanduser(\"~/miniconda3\"),\n",
        "        os.path.expanduser(\"~/anaconda3\"),\n",
        "        os.path.expanduser(\"~/opt/anaconda3\"),\n",
        "        os.path.expanduser(\"~/conda\"),\n",
        "        \"/opt/anaconda3\",\n",
        "        \"/opt/miniconda3\",\n",
        "        \"/usr/local/anaconda3\",\n",
        "        \"/usr/local/miniconda3\",\n",
        "    ]\n",
        "    \n",
        "    # Check CONDA_PREFIX environment variable (current conda env)\n",
        "    if \"CONDA_PREFIX\" in os.environ:\n",
        "        conda_bases.insert(0, os.environ[\"CONDA_PREFIX\"])\n",
        "    \n",
        "    # Check CONDA_DEFAULT_ENV to see if we're in a conda env\n",
        "    if \"CONDA_DEFAULT_ENV\" in os.environ:\n",
        "        env_name = os.environ[\"CONDA_DEFAULT_ENV\"]\n",
        "        if \"CONDA_PREFIX\" in os.environ:\n",
        "            mfa_path = os.path.join(os.environ[\"CONDA_PREFIX\"], \"bin\", \"mfa\")\n",
        "            if os.path.exists(mfa_path):\n",
        "                return mfa_path, os.environ[\"CONDA_PREFIX\"]\n",
        "    \n",
        "    # Check common environment names\n",
        "    env_names = [\"aligner\", \"mfa\", \"pronunciation\", \"base\"]\n",
        "    \n",
        "    for conda_base in conda_bases:\n",
        "        if os.path.exists(conda_base):\n",
        "            # Check if it's a conda base or envs directory\n",
        "            envs_dir = os.path.join(conda_base, \"envs\")\n",
        "            if os.path.exists(envs_dir):\n",
        "                # It's a conda base, check envs\n",
        "                for env_name in env_names:\n",
        "                    env_path = os.path.join(envs_dir, env_name)\n",
        "                    mfa_path = os.path.join(env_path, \"bin\", \"mfa\")\n",
        "                    if os.path.exists(mfa_path):\n",
        "                        return mfa_path, env_path\n",
        "            else:\n",
        "                # Might be a direct environment\n",
        "                mfa_path = os.path.join(conda_base, \"bin\", \"mfa\")\n",
        "                if os.path.exists(mfa_path):\n",
        "                    return mfa_path, conda_base\n",
        "    \n",
        "    return None, None\n",
        "\n",
        "def check_mfa_dependencies(conda_env_path):\n",
        "    \"\"\"Check if MFA dependencies (openfst, kaldi, kalpy) are available.\"\"\"\n",
        "    if not conda_env_path:\n",
        "        return False, []\n",
        "    \n",
        "    bin_dir = os.path.join(conda_env_path, \"bin\")\n",
        "    missing = []\n",
        "    \n",
        "    # Check for fstcompile (OpenFST)\n",
        "    fstcompile = os.path.join(bin_dir, \"fstcompile\")\n",
        "    if not os.path.exists(fstcompile):\n",
        "        missing.append(\"openfst (fstcompile)\")\n",
        "    \n",
        "    # Check for kaldi binaries (at least one)\n",
        "    kaldi_bins = [\"gmm-align-compiled\", \"gmm-latgen-faster\", \"fstcompile\"]\n",
        "    has_kaldi = any(os.path.exists(os.path.join(bin_dir, bin_name)) for bin_name in kaldi_bins)\n",
        "    if not has_kaldi:\n",
        "        missing.append(\"kaldi\")\n",
        "    \n",
        "    # Check for kalpy (Python module - harder to check, but we'll try)\n",
        "    # We can't easily check Python modules from here, but we'll catch it at runtime\n",
        "    \n",
        "    return len(missing) == 0, missing\n",
        "\n",
        "# Strategy: Try conda MFA first, then check PATH\n",
        "print(\"Checking for MFA availability...\")\n",
        "print(\"=\"*70)\n",
        "print(\"MFA Setup: Hybrid Conda/Venv Configuration\")\n",
        "print(\"=\"*70)\n",
        "print(\"This notebook runs in a Python venv but uses MFA from a conda environment.\")\n",
        "print(\"MFA requires Kaldi, kalpy, and OpenFST which are conda-only packages.\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# First, try to find conda MFA\n",
        "conda_mfa, conda_env_path = find_conda_mfa()\n",
        "if conda_mfa:\n",
        "    print(f\"\\nâœ“ Found conda MFA at: {conda_mfa}\")\n",
        "    if conda_env_path:\n",
        "        print(f\"  Conda environment: {conda_env_path}\")\n",
        "    \n",
        "    # Check for required dependencies\n",
        "    deps_ok, missing_deps = check_mfa_dependencies(conda_env_path)\n",
        "    if not deps_ok:\n",
        "        print(f\"\\nâš ï¸  Missing MFA dependencies: {', '.join(missing_deps)}\")\n",
        "        print(\"\\nTo fix, run in your terminal:\")\n",
        "        print(f\"  conda activate {os.path.basename(conda_env_path) if conda_env_path else 'aligner'}\")\n",
        "        print(\"  conda install -c conda-forge openfst kaldi kalpy\")\n",
        "        print(\"\\nOr reinstall MFA with all dependencies:\")\n",
        "        print(\"  conda install -c conda-forge montreal-forced-aligner --force-reinstall\")\n",
        "    else:\n",
        "        print(\"  âœ“ Dependencies check passed (OpenFST, Kaldi found)\")\n",
        "    \n",
        "    MFA_CMD = conda_mfa\n",
        "    \n",
        "    # Test if MFA works - check if it's executable and doesn't have kalpy errors\n",
        "    mfa_works = False\n",
        "    \n",
        "    # Simple test: try any MFA command and check for errors\n",
        "    test_commands = [\n",
        "        [\"--help\"],\n",
        "        [\"version\"],\n",
        "    ]\n",
        "    \n",
        "    for test_cmd in test_commands:\n",
        "        try:\n",
        "            # Use conda run to ensure proper environment\n",
        "            if conda_env_path:\n",
        "                # Try using conda run to execute in the right environment\n",
        "                env_name = os.path.basename(conda_env_path)\n",
        "                result = subprocess.run(\n",
        "                    [\"conda\", \"run\", \"-n\", env_name, \"mfa\"] + test_cmd,\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=5,\n",
        "                    env=os.environ.copy()\n",
        "                )\n",
        "            else:\n",
        "                result = subprocess.run(\n",
        "                    [conda_mfa] + test_cmd,\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=5,\n",
        "                    env=os.environ.copy()\n",
        "                )\n",
        "            \n",
        "            # Check for common errors\n",
        "            error_output = (result.stderr + result.stdout).lower()\n",
        "            \n",
        "            # Check for kalpy error\n",
        "            if \"kalpy\" in error_output or \"_kalpy\" in error_output or \"no module named '_kalpy'\" in error_output:\n",
        "                print(f\"\\nâš ï¸  MFA found but missing kalpy (Kaldi Python bindings)\")\n",
        "                print(\"   Run: conda install -c conda-forge kalpy\")\n",
        "                break\n",
        "            \n",
        "            # Check for openfst/fstcompile error\n",
        "            if \"fstcompile\" in error_output or \"openfst\" in error_output or \"thirdparty\" in error_output:\n",
        "                print(f\"\\nâš ï¸  MFA found but missing OpenFST (fstcompile)\")\n",
        "                print(\"   Run: conda install -c conda-forge openfst\")\n",
        "                break\n",
        "            \n",
        "            # If we get here and no errors, MFA should work\n",
        "            if \"usage\" in error_output or \"command\" in error_output or result.returncode == 0:\n",
        "                mfa_works = True\n",
        "                if \"version\" in test_cmd and result.returncode == 0:\n",
        "                    version_info = (result.stdout + result.stderr).strip()\n",
        "                    if version_info:\n",
        "                        print(f\"\\nâœ“ MFA version: {version_info}\")\n",
        "                break\n",
        "        except FileNotFoundError:\n",
        "            # conda command not found - try direct execution\n",
        "            try:\n",
        "                result = subprocess.run(\n",
        "                    [conda_mfa] + test_cmd,\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=5,\n",
        "                    env=os.environ.copy()\n",
        "                )\n",
        "                error_output = (result.stderr + result.stdout).lower()\n",
        "                if \"kalpy\" not in error_output and \"fstcompile\" not in error_output:\n",
        "                    if \"usage\" in error_output or \"command\" in error_output or result.returncode == 0:\n",
        "                        mfa_works = True\n",
        "                        break\n",
        "            except:\n",
        "                pass\n",
        "        except Exception as e:\n",
        "            continue\n",
        "    \n",
        "    if mfa_works:\n",
        "        MFA_AVAILABLE = True\n",
        "        print(\"\\nâœ“ MFA is available and ready to use!\")\n",
        "        # Store conda env info for later use\n",
        "        if conda_env_path:\n",
        "            MFA_CONDA_ENV = os.path.basename(conda_env_path)\n",
        "            MFA_CONDA_ENV_PATH = conda_env_path  # Store full path for PATH manipulation\n",
        "        else:\n",
        "            MFA_CONDA_ENV = None\n",
        "            MFA_CONDA_ENV_PATH = None\n",
        "    else:\n",
        "        print(\"\\nâš ï¸  MFA found but may not work properly. Check dependencies above.\")\n",
        "        # Still store the path even if test failed, in case dependencies are installed later\n",
        "        if conda_env_path:\n",
        "            MFA_CONDA_ENV = os.path.basename(conda_env_path)\n",
        "            MFA_CONDA_ENV_PATH = conda_env_path\n",
        "        else:\n",
        "            MFA_CONDA_ENV = None\n",
        "            MFA_CONDA_ENV_PATH = None\n",
        "\n",
        "# If conda MFA not found or not working, check PATH\n",
        "if not MFA_AVAILABLE:\n",
        "    mfa_path = shutil.which(\"mfa\")\n",
        "    if mfa_path:\n",
        "        # Check if it's the venv one (which won't work)\n",
        "        if \".venv\" in mfa_path or \"venv\" in mfa_path:\n",
        "            print(f\"âš ï¸  Found MFA in venv ({mfa_path}), but it requires kalpy (conda-only)\")\n",
        "            print(\"   The venv MFA package is installed but cannot run without Kaldi/kalpy.\")\n",
        "            print(\"   \")\n",
        "            print(\"   To use MFA, you need to:\")\n",
        "            print(\"   1. Activate your conda environment: conda activate aligner\")\n",
        "            print(\"   2. Make sure conda's bin directory is in PATH\")\n",
        "            print(\"   3. Restart this notebook\")\n",
        "        else:\n",
        "            print(f\"âœ“ Found MFA command at: {mfa_path}\")\n",
        "            MFA_CMD = mfa_path\n",
        "            try:\n",
        "                result = subprocess.run(\n",
        "                    [\"mfa\", \"--version\"],\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=5\n",
        "                )\n",
        "                if result.returncode == 0:\n",
        "                    MFA_AVAILABLE = True\n",
        "                    print(f\"âœ“ MFA available: {result.stdout.strip()}\")\n",
        "                else:\n",
        "                    print(f\"âš ï¸  MFA command found but returned error\")\n",
        "                    print(f\"   Error: {result.stderr if result.stderr else 'Unknown error'}\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  Error running MFA: {e}\")\n",
        "\n",
        "if not MFA_AVAILABLE:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"âš ï¸  MFA not available or not working\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nMFA requires conda installation (Kaldi, kalpy, OpenFST are conda-only packages)\")\n",
        "    print(\"\\nğŸ“‹ Installation Instructions:\")\n",
        "    print(\"\\n1. Create conda environment with MFA:\")\n",
        "    print(\"   conda create -n aligner -c conda-forge montreal-forced-aligner\")\n",
        "    print(\"\\n2. Activate the environment:\")\n",
        "    print(\"   conda activate aligner\")\n",
        "    print(\"\\n3. Verify installation:\")\n",
        "    print(\"   mfa --version\")\n",
        "    print(\"   # Should show MFA version without errors\")\n",
        "    print(\"\\n4. Download required models:\")\n",
        "    print(\"   mfa model download dictionary english_us_mfa\")\n",
        "    print(\"   mfa model download acoustic english_mfa\")\n",
        "    print(\"\\n5. For Jupyter notebook:\")\n",
        "    print(\"   Option A: Install ipykernel in conda env and use it as kernel:\")\n",
        "    print(\"     conda activate aligner\")\n",
        "    print(\"     conda install ipykernel\")\n",
        "    print(\"     python -m ipykernel install --user --name aligner --display-name 'Python (aligner)'\")\n",
        "    print(\"     # Then select 'Python (aligner)' kernel in Jupyter\")\n",
        "    print(\"\\n   Option B: Keep using venv kernel, MFA will be called via subprocess\")\n",
        "    print(\"     (Current setup - should work if conda MFA is found)\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ğŸ“ Note: The notebook will still work without MFA, but timestamp alignment\")\n",
        "    print(\"   will use dummy/estimated timestamps instead of precise MFA alignments.\")\n",
        "    print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IPA Format Conversion Utilities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration: Input Audio and Target Text\n",
        "\n",
        "**Configure your assessment here:**\n",
        "\n",
        "Set the audio file path and the target text (what the speaker should say).\n",
        "The notebook will:\n",
        "- Extract actual pronunciation from the audio\n",
        "- Generate target pronunciation from the text\n",
        "- Compare and identify errors with timestamps\n",
        "- Save results to `results/` directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_powsm_phones(powsm_ipa: str) -> List[str]:\n",
        "    \"\"\"Parse IPA phonemes from POWSM format.\"\"\"\n",
        "    cleaned = powsm_ipa.strip().strip('/')\n",
        "    if not cleaned:\n",
        "        return []\n",
        "    phonemes = [p.strip('/') for p in cleaned.split('//') if p.strip('/')]\n",
        "    return phonemes\n",
        "\n",
        "\n",
        "def powsm_to_mfa_format(powsm_ipa: str) -> str:\n",
        "    \"\"\"Convert POWSM format to MFA space-separated format.\"\"\"\n",
        "    phones = parse_powsm_phones(powsm_ipa)\n",
        "    return ' '.join(phones)\n",
        "\n",
        "\n",
        "def mfa_to_powsm_format(mfa_ipa: str) -> str:\n",
        "    \"\"\"Convert MFA format to POWSM format.\"\"\"\n",
        "    if not mfa_ipa:\n",
        "        return \"\"\n",
        "    phones = mfa_ipa.strip().split()\n",
        "    return '//'.join(['/' + p + '/' for p in phones])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize POWSM Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading POWSM models...\n",
            "  - Loading language detection model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 77878.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - Loading Phone Recognition (PR) model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 64669.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - Loading ASR model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 68598.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - Loading G2P model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 73769.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ All POWSM models loaded!\n"
          ]
        }
      ],
      "source": [
        "device = \"cpu\"  # Change to \"cuda\" if GPU available\n",
        "\n",
        "print(\"Loading POWSM models...\")\n",
        "\n",
        "# Language detection model\n",
        "print(\"  - Loading language detection model...\")\n",
        "s2lang = Speech2Language.from_pretrained(\n",
        "    \"espnet/powsm\",\n",
        "    device=device,\n",
        "    nbest=1,\n",
        "    first_lang_sym=\"<afr>\",\n",
        "    last_lang_sym=\"<zul>\"\n",
        ")\n",
        "\n",
        "# Phone Recognition model\n",
        "print(\"  - Loading Phone Recognition (PR) model...\")\n",
        "s2t_pr = Speech2Text.from_pretrained(\n",
        "    \"espnet/powsm\",\n",
        "    device=device,\n",
        "    lang_sym=\"<eng>\",\n",
        "    task_sym=\"<pr>\",\n",
        ")\n",
        "\n",
        "# ASR model (for G2P)\n",
        "print(\"  - Loading ASR model...\")\n",
        "s2t_asr = Speech2Text.from_pretrained(\n",
        "    \"espnet/powsm\",\n",
        "    device=device,\n",
        "    lang_sym=\"<eng>\",\n",
        "    task_sym=\"<asr>\",\n",
        ")\n",
        "\n",
        "# G2P model\n",
        "print(\"  - Loading G2P model...\")\n",
        "s2t_g2p = Speech2Text.from_pretrained(\n",
        "    \"espnet/powsm\",\n",
        "    device=device,\n",
        "    lang_sym=\"<eng>\",\n",
        "    task_sym=\"<g2p>\",\n",
        ")\n",
        "\n",
        "print(\"âœ“ All POWSM models loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo: Pronunciation Assessment Workflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CONFIGURATION\n",
            "======================================================================\n",
            "Selected config: Sentence 12 (Yusuf) (index 2)\n",
            "Sentence ID: 12\n",
            "Audio file: audio/powsm/12/yusuf12-r.wav\n",
            "\n",
            "âœ“ Audio File: audio/powsm/12/yusuf12-r.wav\n",
            "  Duration: 20.00s\n",
            "  Sample Rate: 16000Hz\n",
            "\n",
            "âœ“ Target Text:\n",
            "  The weather is rather warm this Thursday. I think we should go to the theater together. Thank you for thinking about this thoroughly.\n",
            "\n",
            "âœ“ Output will be saved to: results/pronunciation_assessment_yusuf12-r_<timestamp>.json\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION: Set your audio file and target text here\n",
        "# ============================================================================\n",
        "\n",
        "CONFIG_ROOT = Path(\"./audio/powsm\")\n",
        "\n",
        "CONFIGS = [\n",
        "    {\n",
        "        \"label\": \"Sentence 12 (Ãœmit)\",\n",
        "        \"sentence_id\": \"12\",\n",
        "        \"audio_filename\": \"umit12-r.wav\",\n",
        "        \"target_text\": \"The weather is rather warm this Thursday. I think we should go to the theater together. Thank you for thinking about this thoroughly.\"\n",
        "    },\n",
        "    {\n",
        "        \"label\": \"Sentence 14 (Ãœmit)\",\n",
        "        \"sentence_id\": \"14\",\n",
        "        \"audio_filename\": \"umit14-r.wav\",\n",
        "        \"target_text\": \"The red car arrived early in the morning. The driver parked near the restaurant and ordered breakfast. The fresh bread was really delicious.\"\n",
        "    },\n",
        "    {\n",
        "        \"label\": \"Sentence 12 (Yusuf)\",\n",
        "        \"sentence_id\": \"12\",\n",
        "        \"audio_filename\": \"yusuf12-r.wav\",\n",
        "        \"target_text\": \"The weather is rather warm this Thursday. I think we should go to the theater together. Thank you for thinking about this thoroughly.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Pick which configuration to run (set index to another entry to process a different file)\n",
        "selected_config_index = 2\n",
        "selected_config = CONFIGS[selected_config_index]\n",
        "\n",
        "# Derive runtime values from the selected configuration\n",
        "audio_file_path = CONFIG_ROOT / selected_config[\"sentence_id\"] / selected_config[\"audio_filename\"]\n",
        "audio_file = str(audio_file_path)\n",
        "target_text = selected_config[\"target_text\"]\n",
        "\n",
        "# ============================================================================\n",
        "# Validate configuration\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Selected config: {selected_config.get('label', selected_config['audio_filename'])} (index {selected_config_index})\")\n",
        "print(f\"Sentence ID: {selected_config['sentence_id']}\")\n",
        "print(f\"Audio file: {audio_file}\")\n",
        "\n",
        "# Check if audio file exists\n",
        "if not os.path.exists(audio_file):\n",
        "    print(f\"âš ï¸  ERROR: Audio file not found: {audio_file}\")\n",
        "    print(\"   Please update the selected configuration above.\")\n",
        "    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
        "\n",
        "# Get audio basename for output filename\n",
        "audio_basename = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "\n",
        "# Load audio to get duration\n",
        "speech, rate = sf.read(audio_file)\n",
        "audio_duration = len(speech) / rate\n",
        "\n",
        "print(f\"\\nâœ“ Audio File: {audio_file}\")\n",
        "print(f\"  Duration: {audio_duration:.2f}s\")\n",
        "print(f\"  Sample Rate: {rate}Hz\")\n",
        "print(f\"\\nâœ“ Target Text:\")\n",
        "print(f\"  {target_text}\")\n",
        "print(f\"\\nâœ“ Output will be saved to: results/pronunciation_assessment_{audio_basename}_<timestamp>.json\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Extract Actual IPA from Audio (POWSM Phone Recognition)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 1: Extract Actual Pronunciation from Audio\n",
            "======================================================================\n",
            "\n",
            "Detecting language...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/espnet2/s2t/espnet_model.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Detected language: <eng>\n",
            "\n",
            "Running POWSM Phone Recognition...\n",
            "\n",
            "âœ“ Phone Recognition Complete\n",
            "  Total phones detected: 82\n",
            "\n",
            "ğŸ“ Actual IPA (POWSM format):\n",
            "   /Ã°//É™//w//É›//Ã°//ÉœË//Éª//z//É¹//É™//Ã°//ÉœË//w//É”//É¹//m//Ã°//Éª//s//Î¸//ÉœË//d//z//d//e//Éª//a//Éª//Î¸//ÉªÌƒ//Å‹//k//w//i//Êƒ//i//kÊ°//É”//z//Éª//t//Î¸//i//É™//t//ÉœË//tÊ°//É™//É¡//É›//Ã°//ÉœË//Î¸//Ã¦Ìƒ//Å‹//k//j//u//f//É¹//ÉœË//Î¸//ÉªÌƒ//Å‹//k//ÉªÌƒ//Å‹//É™//b//a//ÊŠ//t//Éª//z//É™//Î¸//É”//É¹//o//ÊŠ//lÌ´//i/\n",
            "\n",
            "ğŸ“ Actual IPA (clean, no separators):\n",
            "   Ã°É™wÉ›Ã°ÉœËÉªzÉ¹É™Ã°ÉœËwÉ”É¹mÃ°ÉªsÎ¸ÉœËdzdeÉªaÉªÎ¸ÉªÌƒÅ‹kwiÊƒikÊ°É”zÉªtÎ¸iÉ™tÉœËtÊ°É™É¡É›Ã°ÉœËÎ¸Ã¦ÌƒÅ‹kjufÉ¹ÉœËÎ¸ÉªÌƒÅ‹kÉªÌƒÅ‹É™baÊŠtÉªzÉ™Î¸É”É¹oÊŠlÌ´i\n",
            "\n",
            "ğŸ“ Actual phones (full list, 82 phones):\n",
            "     1. Ã°\n",
            "     2. É™\n",
            "     3. w\n",
            "     4. É›\n",
            "     5. Ã°\n",
            "     6. ÉœË\n",
            "     7. Éª\n",
            "     8. z\n",
            "     9. É¹\n",
            "    10. É™\n",
            "    11. Ã°\n",
            "    12. ÉœË\n",
            "    13. w\n",
            "    14. É”\n",
            "    15. É¹\n",
            "    16. m\n",
            "    17. Ã°\n",
            "    18. Éª\n",
            "    19. s\n",
            "    20. Î¸\n",
            "    21. ÉœË\n",
            "    22. d\n",
            "    23. z\n",
            "    24. d\n",
            "    25. e\n",
            "    26. Éª\n",
            "    27. a\n",
            "    28. Éª\n",
            "    29. Î¸\n",
            "    30. ÉªÌƒ\n",
            "    31. Å‹\n",
            "    32. k\n",
            "    33. w\n",
            "    34. i\n",
            "    35. Êƒ\n",
            "    36. i\n",
            "    37. kÊ°\n",
            "    38. É”\n",
            "    39. z\n",
            "    40. Éª\n",
            "    41. t\n",
            "    42. Î¸\n",
            "    43. i\n",
            "    44. É™\n",
            "    45. t\n",
            "    46. ÉœË\n",
            "    47. tÊ°\n",
            "    48. É™\n",
            "    49. É¡\n",
            "    50. É›\n",
            "    51. Ã°\n",
            "    52. ÉœË\n",
            "    53. Î¸\n",
            "    54. Ã¦Ìƒ\n",
            "    55. Å‹\n",
            "    56. k\n",
            "    57. j\n",
            "    58. u\n",
            "    59. f\n",
            "    60. É¹\n",
            "    61. ÉœË\n",
            "    62. Î¸\n",
            "    63. ÉªÌƒ\n",
            "    64. Å‹\n",
            "    65. k\n",
            "    66. ÉªÌƒ\n",
            "    67. Å‹\n",
            "    68. É™\n",
            "    69. b\n",
            "    70. a\n",
            "    71. ÊŠ\n",
            "    72. t\n",
            "    73. Éª\n",
            "    74. z\n",
            "    75. É™\n",
            "    76. Î¸\n",
            "    77. É”\n",
            "    78. É¹\n",
            "    79. o\n",
            "    80. ÊŠ\n",
            "    81. lÌ´\n",
            "    82. i\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Step 1: Extract Actual IPA from Audio (POWSM Phone Recognition)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 1: Extract Actual Pronunciation from Audio\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Detect language (optional)\n",
        "print(\"\\nDetecting language...\")\n",
        "try:\n",
        "    lang_pred = s2lang(speech)[0]\n",
        "    detected_lang = lang_pred[0] if lang_pred else \"<eng>\"\n",
        "    print(f\"âœ“ Detected language: {detected_lang}\")\n",
        "except:\n",
        "    detected_lang = \"<eng>\"\n",
        "    print(f\"âœ“ Using default language: {detected_lang}\")\n",
        "\n",
        "# Phone Recognition\n",
        "print(\"\\nRunning POWSM Phone Recognition...\")\n",
        "result_pr = s2t_pr(speech, text_prev=\"<na>\")\n",
        "pred_pr = result_pr[0][0]\n",
        "\n",
        "# Post-processing\n",
        "if \"<notimestamps>\" in pred_pr:\n",
        "    pred_pr = pred_pr.split(\"<notimestamps>\")[1].strip()\n",
        "else:\n",
        "    pred_pr = pred_pr.strip()\n",
        "\n",
        "# Clean version (without slashes)\n",
        "pred_pr_clean = pred_pr.replace(\"/\", \"\")\n",
        "\n",
        "# Parse into list\n",
        "actual_phones = parse_powsm_phones(pred_pr)\n",
        "\n",
        "print(f\"\\nâœ“ Phone Recognition Complete\")\n",
        "print(f\"  Total phones detected: {len(actual_phones)}\")\n",
        "print(f\"\\nğŸ“ Actual IPA (POWSM format):\")\n",
        "print(f\"   {pred_pr}\")\n",
        "print(f\"\\nğŸ“ Actual IPA (clean, no separators):\")\n",
        "print(f\"   {pred_pr_clean}\")\n",
        "print(f\"\\nğŸ“ Actual phones (full list, {len(actual_phones)} phones):\")\n",
        "for i, phone in enumerate(actual_phones, 1):\n",
        "    print(f\"   {i:3d}. {phone}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Generate Target IPA from Text (POWSM G2P)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 2: Generate Target Pronunciation from Text\n",
            "======================================================================\n",
            "\n",
            "2a. Getting ASR transcript (for comparison)...\n",
            "   âœ“ ASR Result: the weather is rather warm this Thursday  â‡  think we she cause it the theater together think you for thinking about is authority\n",
            "\n",
            "2b. Audio-guided G2P using ORIGINAL TRANSCRIPT (ground truth)...\n",
            "   Using transcript: The weather is rather warm this Thursday. I think we should go to the theater together. Thank you for thinking about this thoroughly.\n",
            "\n",
            "âœ“ Target IPA Generated (from original transcript)\n",
            "  Total phones: 86\n",
            "\n",
            "ğŸ”¤ Target IPA (POWSM format):\n",
            "   /Ã°//É™//w//É›//Ã°//ÉœË//Éª//z//É¹//É™//Ã°//ÉœË//w//É”//É¹//m//Ã°//Éª//s//Î¸//ÉœË//z//d//e//Éª//a//Éª//Î¸//ÉªÌƒ//Å‹//k//w//i//Êƒ//ÊŠ//d//k//o//ÊŠ//tÊ°//u//Ã°//É™//Î¸//i//É™//t//ÉœË//tÊ°//É™//É¡//É›//Ã°//ÉœË//a//Éª//Î¸//Ã¦Ìƒ//Å‹//k//j//u//f//É¹//ÉœË//Î¸//ÉªÌƒ//Å‹//k//ÉªÌƒ//Å‹//É™//b//a//ÊŠ//t//Ã°//Éª//s//Î¸//É”//É¹//o//ÊŠ//lÌ´//i/\n",
            "\n",
            "ğŸ”¤ Target IPA (clean, no separators):\n",
            "   Ã°É™wÉ›Ã°ÉœËÉªzÉ¹É™Ã°ÉœËwÉ”É¹mÃ°ÉªsÎ¸ÉœËzdeÉªaÉªÎ¸ÉªÌƒÅ‹kwiÊƒÊŠdkoÊŠtÊ°uÃ°É™Î¸iÉ™tÉœËtÊ°É™É¡É›Ã°ÉœËaÉªÎ¸Ã¦ÌƒÅ‹kjufÉ¹ÉœËÎ¸ÉªÌƒÅ‹kÉªÌƒÅ‹É™baÊŠtÃ°ÉªsÎ¸É”É¹oÊŠlÌ´i\n",
            "\n",
            "ğŸ”¤ Target phones (full list, 86 phones):\n",
            "     1. Ã°\n",
            "     2. É™\n",
            "     3. w\n",
            "     4. É›\n",
            "     5. Ã°\n",
            "     6. ÉœË\n",
            "     7. Éª\n",
            "     8. z\n",
            "     9. É¹\n",
            "    10. É™\n",
            "    11. Ã°\n",
            "    12. ÉœË\n",
            "    13. w\n",
            "    14. É”\n",
            "    15. É¹\n",
            "    16. m\n",
            "    17. Ã°\n",
            "    18. Éª\n",
            "    19. s\n",
            "    20. Î¸\n",
            "    21. ÉœË\n",
            "    22. z\n",
            "    23. d\n",
            "    24. e\n",
            "    25. Éª\n",
            "    26. a\n",
            "    27. Éª\n",
            "    28. Î¸\n",
            "    29. ÉªÌƒ\n",
            "    30. Å‹\n",
            "    31. k\n",
            "    32. w\n",
            "    33. i\n",
            "    34. Êƒ\n",
            "    35. ÊŠ\n",
            "    36. d\n",
            "    37. k\n",
            "    38. o\n",
            "    39. ÊŠ\n",
            "    40. tÊ°\n",
            "    41. u\n",
            "    42. Ã°\n",
            "    43. É™\n",
            "    44. Î¸\n",
            "    45. i\n",
            "    46. É™\n",
            "    47. t\n",
            "    48. ÉœË\n",
            "    49. tÊ°\n",
            "    50. É™\n",
            "    51. É¡\n",
            "    52. É›\n",
            "    53. Ã°\n",
            "    54. ÉœË\n",
            "    55. a\n",
            "    56. Éª\n",
            "    57. Î¸\n",
            "    58. Ã¦Ìƒ\n",
            "    59. Å‹\n",
            "    60. k\n",
            "    61. j\n",
            "    62. u\n",
            "    63. f\n",
            "    64. É¹\n",
            "    65. ÉœË\n",
            "    66. Î¸\n",
            "    67. ÉªÌƒ\n",
            "    68. Å‹\n",
            "    69. k\n",
            "    70. ÉªÌƒ\n",
            "    71. Å‹\n",
            "    72. É™\n",
            "    73. b\n",
            "    74. a\n",
            "    75. ÊŠ\n",
            "    76. t\n",
            "    77. Ã°\n",
            "    78. Éª\n",
            "    79. s\n",
            "    80. Î¸\n",
            "    81. É”\n",
            "    82. É¹\n",
            "    83. o\n",
            "    84. ÊŠ\n",
            "    85. lÌ´\n",
            "    86. i\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "2c. Audio-guided G2P using ASR TRANSCRIPT (for comparison)...\n",
            "   Using ASR transcript: the weather is rather warm this Thursday  â‡  think we she cause it the theater together think you for thinking about is authority\n",
            "\n",
            "âœ“ Target IPA Generated (from ASR transcript)\n",
            "  Total phones: 80\n",
            "\n",
            "ğŸ”¤ Target IPA from ASR (POWSM format):\n",
            "   /Ã°//É™//w//É›//Ã°//ÉœË//Éª//z//É¹//É™//Ã°//ÉœË//w//É”//É¹//m//Ã°//Éª//s//Î¸//ÉœË//z//d//e//Éª//a//Éª//Î¸//ÉªÌƒ//Å‹//k//w//i//Êƒ//i//kÊ°//É”//z//Éª//t//Î¸//i//É™//t//ÉœË//tÊ°//É™//É¡//É›//Ã°//ÉœË//Î¸//ÉªÌƒ//Å‹//k//j//u//f//É¹//ÉœË//Î¸//ÉªÌƒ//Å‹//k//ÉªÌƒ//Å‹//É™//b//a//ÊŠ//t//Éª//z//É™//Î¸//É”//É¹//É™//t//i/\n",
            "\n",
            "ğŸ”¤ Target IPA from ASR (clean, no separators):\n",
            "   Ã°É™wÉ›Ã°ÉœËÉªzÉ¹É™Ã°ÉœËwÉ”É¹mÃ°ÉªsÎ¸ÉœËzdeÉªaÉªÎ¸ÉªÌƒÅ‹kwiÊƒikÊ°É”zÉªtÎ¸iÉ™tÉœËtÊ°É™É¡É›Ã°ÉœËÎ¸ÉªÌƒÅ‹kjufÉ¹ÉœËÎ¸ÉªÌƒÅ‹kÉªÌƒÅ‹É™baÊŠtÉªzÉ™Î¸É”É¹É™ti\n",
            "\n",
            "ğŸ”¤ Target phones from ASR (full list, 80 phones):\n",
            "     1. Ã°\n",
            "     2. É™\n",
            "     3. w\n",
            "     4. É›\n",
            "     5. Ã°\n",
            "     6. ÉœË\n",
            "     7. Éª\n",
            "     8. z\n",
            "     9. É¹\n",
            "    10. É™\n",
            "    11. Ã°\n",
            "    12. ÉœË\n",
            "    13. w\n",
            "    14. É”\n",
            "    15. É¹\n",
            "    16. m\n",
            "    17. Ã°\n",
            "    18. Éª\n",
            "    19. s\n",
            "    20. Î¸\n",
            "    21. ÉœË\n",
            "    22. z\n",
            "    23. d\n",
            "    24. e\n",
            "    25. Éª\n",
            "    26. a\n",
            "    27. Éª\n",
            "    28. Î¸\n",
            "    29. ÉªÌƒ\n",
            "    30. Å‹\n",
            "    31. k\n",
            "    32. w\n",
            "    33. i\n",
            "    34. Êƒ\n",
            "    35. i\n",
            "    36. kÊ°\n",
            "    37. É”\n",
            "    38. z\n",
            "    39. Éª\n",
            "    40. t\n",
            "    41. Î¸\n",
            "    42. i\n",
            "    43. É™\n",
            "    44. t\n",
            "    45. ÉœË\n",
            "    46. tÊ°\n",
            "    47. É™\n",
            "    48. É¡\n",
            "    49. É›\n",
            "    50. Ã°\n",
            "    51. ÉœË\n",
            "    52. Î¸\n",
            "    53. ÉªÌƒ\n",
            "    54. Å‹\n",
            "    55. k\n",
            "    56. j\n",
            "    57. u\n",
            "    58. f\n",
            "    59. É¹\n",
            "    60. ÉœË\n",
            "    61. Î¸\n",
            "    62. ÉªÌƒ\n",
            "    63. Å‹\n",
            "    64. k\n",
            "    65. ÉªÌƒ\n",
            "    66. Å‹\n",
            "    67. É™\n",
            "    68. b\n",
            "    69. a\n",
            "    70. ÊŠ\n",
            "    71. t\n",
            "    72. Éª\n",
            "    73. z\n",
            "    74. É™\n",
            "    75. Î¸\n",
            "    76. É”\n",
            "    77. É¹\n",
            "    78. É™\n",
            "    79. t\n",
            "    80. i\n",
            "\n",
            "======================================================================\n",
            "ğŸ“Š Summary:\n",
            "======================================================================\n",
            "  Primary (Original transcript): 86 phones\n",
            "  Comparison (ASR transcript):  80 phones\n",
            "  Difference: 6 phones\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Step 2: Generate Target IPA from Text (POWSM G2P)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 2: Generate Target Pronunciation from Text\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Step 2a: Get ASR transcript (for comparison)\n",
        "print(\"\\n2a. Getting ASR transcript (for comparison)...\")\n",
        "result_asr = s2t_asr(speech, text_prev=\"<na>\")\n",
        "pred_asr = result_asr[0][0]\n",
        "\n",
        "if \"<notimestamps>\" in pred_asr:\n",
        "    pred_asr = pred_asr.split(\"<notimestamps>\")[1].strip()\n",
        "else:\n",
        "    pred_asr = pred_asr.strip()\n",
        "\n",
        "print(f\"   âœ“ ASR Result: {pred_asr}\")\n",
        "\n",
        "# Step 2b: Audio-guided G2P using ORIGINAL TRANSCRIPT (ground truth)\n",
        "print(\"\\n2b. Audio-guided G2P using ORIGINAL TRANSCRIPT (ground truth)...\")\n",
        "print(f\"   Using transcript: {target_text}\")\n",
        "result_g2p_original = s2t_g2p(speech, text_prev=target_text)\n",
        "pred_g2p_original = result_g2p_original[0][0]\n",
        "\n",
        "if \"<notimestamps>\" in pred_g2p_original:\n",
        "    pred_g2p_original = pred_g2p_original.split(\"<notimestamps>\")[1].strip()\n",
        "else:\n",
        "    pred_g2p_original = pred_g2p_original.strip()\n",
        "\n",
        "pred_g2p_original_clean = pred_g2p_original.replace(\"/\", \"\")\n",
        "\n",
        "# Parse into list (use original transcript version as primary)\n",
        "target_phones = parse_powsm_phones(pred_g2p_original)\n",
        "\n",
        "print(f\"\\nâœ“ Target IPA Generated (from original transcript)\")\n",
        "print(f\"  Total phones: {len(target_phones)}\")\n",
        "print(f\"\\nğŸ”¤ Target IPA (POWSM format):\")\n",
        "print(f\"   {pred_g2p_original}\")\n",
        "print(f\"\\nğŸ”¤ Target IPA (clean, no separators):\")\n",
        "print(f\"   {pred_g2p_original_clean}\")\n",
        "print(f\"\\nğŸ”¤ Target phones (full list, {len(target_phones)} phones):\")\n",
        "for i, phone in enumerate(target_phones, 1):\n",
        "    print(f\"   {i:3d}. {phone}\")\n",
        "\n",
        "# Step 2c: Audio-guided G2P using ASR transcript (for comparison)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"2c. Audio-guided G2P using ASR TRANSCRIPT (for comparison)...\")\n",
        "print(f\"   Using ASR transcript: {pred_asr}\")\n",
        "result_g2p_asr = s2t_g2p(speech, text_prev=pred_asr)\n",
        "pred_g2p_asr = result_g2p_asr[0][0]\n",
        "\n",
        "if \"<notimestamps>\" in pred_g2p_asr:\n",
        "    pred_g2p_asr = pred_g2p_asr.split(\"<notimestamps>\")[1].strip()\n",
        "else:\n",
        "    pred_g2p_asr = pred_g2p_asr.strip()\n",
        "\n",
        "pred_g2p_asr_clean = pred_g2p_asr.replace(\"/\", \"\")\n",
        "\n",
        "# Parse into list for comparison\n",
        "target_phones_asr = parse_powsm_phones(pred_g2p_asr)\n",
        "\n",
        "print(f\"\\nâœ“ Target IPA Generated (from ASR transcript)\")\n",
        "print(f\"  Total phones: {len(target_phones_asr)}\")\n",
        "print(f\"\\nğŸ”¤ Target IPA from ASR (POWSM format):\")\n",
        "print(f\"   {pred_g2p_asr}\")\n",
        "print(f\"\\nğŸ”¤ Target IPA from ASR (clean, no separators):\")\n",
        "print(f\"   {pred_g2p_asr_clean}\")\n",
        "print(f\"\\nğŸ”¤ Target phones from ASR (full list, {len(target_phones_asr)} phones):\")\n",
        "for i, phone in enumerate(target_phones_asr, 1):\n",
        "    print(f\"   {i:3d}. {phone}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“Š Summary:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"  Primary (Original transcript): {len(target_phones)} phones\")\n",
        "print(f\"  Comparison (ASR transcript):  {len(target_phones_asr)} phones\")\n",
        "print(f\"  Difference: {abs(len(target_phones) - len(target_phones_asr))} phones\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: MFA Alignment (Align Phones to Timestamps)\n",
        "\n",
        "Aligns phones from the target text to timestamps in the audio using Montreal Forced Aligner (MFA).\n",
        "\n",
        "**Note:** MFA requires installation and model downloads. See instructions in the setup cell if not available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 3: Align Phones to Audio Timestamps (MFA)\n",
            "======================================================================\n",
            "\n",
            "Running MFA alignment...\n",
            "  Aligning: audio/powsm/12/yusuf12-r.wav with text: The weather is rather warm this Thursday. I think ...\n",
            "  Corpus dir: /var/folders/qk/0bk8sm9136q_16hvc9hdhr6m0000gn/T/tmpdqzkghrd/corpus\n",
            "  Output dir: /var/folders/qk/0bk8sm9136q_16hvc9hdhr6m0000gn/T/tmpdqzkghrd/output\n",
            "  Using conda environment PATH: /Users/umitcanevleksiz/miniconda3/envs/aligner/bin\n",
            "  Trying alignment with beam=10, retry_beam=40...\n",
            "  âš ï¸  No alignments with beam=10, retry_beam=40, trying larger beam...\n",
            "  Trying alignment with beam=100, retry_beam=400...\n",
            "  âœ“ Alignment successful with beam=100, retry_beam=400\n",
            "\n",
            "âœ“ MFA alignment complete: 68 phones aligned\n",
            "\n",
            "ğŸ“Š All alignments (68 phones):\n",
            "     1. É™     [ 0.000s -  0.010s]\n",
            "     2. w     [ 0.010s -  0.040s]\n",
            "     3. É›     [ 0.040s -  0.050s]\n",
            "     4. Ã°     [ 0.050s -  0.080s]\n",
            "     5. Éš     [ 0.080s -  0.110s]\n",
            "     6. z     [ 0.110s -  0.140s]\n",
            "     7. É¹     [ 0.140s -  0.170s]\n",
            "     8. Ã¦     [ 0.170s -  0.200s]\n",
            "     9. Ã°     [ 0.200s -  0.230s]\n",
            "    10. Éš     [ 0.230s -  0.260s]\n",
            "    11. w     [ 0.260s -  0.290s]\n",
            "    12. É’     [ 0.290s -  0.320s]\n",
            "    13. É¹     [ 0.320s -  0.350s]\n",
            "    14. m     [ 0.350s -  0.380s]\n",
            "    15. Ã°     [ 0.380s -  0.430s]\n",
            "    16. Éª     [ 0.430s -  0.460s]\n",
            "    17. s     [ 0.460s -  0.490s]\n",
            "    18. Î¸     [ 0.490s -  0.520s]\n",
            "    19. É     [ 0.520s -  0.550s]\n",
            "    20. z     [ 0.550s -  0.580s]\n",
            "    21. d     [ 0.580s -  0.610s]\n",
            "    22. ej    [ 0.610s -  0.640s]\n",
            "    23. aj    [ 0.640s -  7.720s]\n",
            "    24. tÌª    [ 7.720s -  7.750s]\n",
            "    25. Éª     [ 7.750s -  7.780s]\n",
            "    26. n     [ 7.780s -  7.810s]\n",
            "    27. w     [ 7.810s -  7.820s]\n",
            "    28. iË    [ 7.820s -  7.850s]\n",
            "    29. Êƒ     [ 7.850s -  7.880s]\n",
            "    30. ÊŠ     [ 7.880s -  7.900s]\n",
            "    31. É¾     [ 7.900s -  7.910s]\n",
            "    32. É¡     [ 7.910s -  7.940s]\n",
            "    33. ow    [ 7.940s -  7.970s]\n",
            "    34. É™     [ 7.970s -  8.000s]\n",
            "    35. É™     [ 8.000s -  8.030s]\n",
            "    36. tÌª    [ 8.030s -  8.060s]\n",
            "    37. iË    [ 8.060s -  8.090s]\n",
            "    38. É¾     [ 8.090s -  8.100s]\n",
            "    39. Éš     [ 8.100s -  8.130s]\n",
            "    40. tÊ°    [ 8.130s -  8.160s]\n",
            "    41. ÊŠ     [ 8.160s -  8.180s]\n",
            "    42. É¡     [ 8.180s -  8.210s]\n",
            "    43. É›     [ 8.210s -  8.240s]\n",
            "    44. Ã°     [ 8.240s -  8.270s]\n",
            "    45. Éš     [ 8.270s -  8.300s]\n",
            "    46. tÌª    [ 8.300s -  8.330s]\n",
            "    47. Ã¦     [ 8.330s -  8.360s]\n",
            "    48. Å‹     [ 8.360s -  8.390s]\n",
            "    49. k     [ 8.390s -  8.420s]\n",
            "    50. j     [ 8.420s -  8.450s]\n",
            "    51. É™     [ 8.450s -  8.460s]\n",
            "    52. f     [ 8.460s -  8.490s]\n",
            "    53. Éš     [ 8.490s -  8.520s]\n",
            "    54. tÌª    [ 8.520s -  8.550s]\n",
            "    55. Éª     [ 8.550s -  8.580s]\n",
            "    56. É¾Ìƒ    [ 8.580s -  8.590s]\n",
            "    57. Éª     [ 8.590s -  8.620s]\n",
            "    58. Å‹     [ 8.620s -  8.650s]\n",
            "    59. b     [ 8.650s -  8.680s]\n",
            "    60. aw    [ 8.680s -  8.690s]\n",
            "    61. dÌª    [ 8.690s -  8.720s]\n",
            "    62. Éª     [ 8.720s -  8.750s]\n",
            "    63. s     [ 8.750s -  8.780s]\n",
            "    64. Î¸     [ 8.780s -  8.810s]\n",
            "    65. É     [ 8.810s -  8.840s]\n",
            "    66. É™     [ 8.840s -  8.870s]\n",
            "    67. Ê     [ 8.870s -  8.900s]\n",
            "    68. i     [ 8.900s -  8.930s]\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Step 3: MFA Alignment (Align Phones to Timestamps)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 3: Align Phones to Audio Timestamps (MFA)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if not MFA_AVAILABLE:\n",
        "    print(\"\\nâš ï¸  MFA not available. Skipping alignment.\")\n",
        "    print(\"\\nTo use MFA alignment:\")\n",
        "    print(\"  1. Install MFA via conda: conda create -n aligner -c conda-forge montreal-forced-aligner\")\n",
        "    print(\"  2. Activate conda environment: conda activate aligner\")\n",
        "    print(\"  3. Download models:\")\n",
        "    print(\"     mfa model download dictionary english_us_mfa\")\n",
        "    print(\"     mfa model download acoustic english_mfa\")\n",
        "    print(\"  4. Restart this notebook with conda environment activated\")\n",
        "    print(\"\\nNote: The notebook will continue with estimated timestamps.\")\n",
        "    mfa_alignments = []\n",
        "else:\n",
        "    print(\"\\nRunning MFA alignment...\")\n",
        "    \n",
        "    # Use corpus-based alignment (more reliable than align_one)\n",
        "    # Create temporary corpus directory structure\n",
        "    with tempfile.TemporaryDirectory() as temp_base:\n",
        "        corpus_dir = os.path.join(temp_base, \"corpus\")\n",
        "        output_dir = os.path.join(temp_base, \"output\")\n",
        "        os.makedirs(corpus_dir, exist_ok=True)\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        \n",
        "        # Get audio basename\n",
        "        audio_basename = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "        \n",
        "        # Copy audio file to corpus directory\n",
        "        audio_in_corpus = os.path.join(corpus_dir, f\"{audio_basename}.wav\")\n",
        "        shutil.copy2(audio_file, audio_in_corpus)\n",
        "        \n",
        "        # Create .lab file (MFA expects .lab files for text)\n",
        "        lab_file = os.path.join(corpus_dir, f\"{audio_basename}.lab\")\n",
        "        with open(lab_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(target_text)\n",
        "        \n",
        "        try:\n",
        "            # Use MFA_CMD if available, otherwise use \"mfa\"\n",
        "            mfa_command = MFA_CMD if MFA_CMD else \"mfa\"\n",
        "            \n",
        "            print(f\"  Aligning: {audio_file} with text: {target_text[:50]}...\")\n",
        "            print(f\"  Corpus dir: {corpus_dir}\")\n",
        "            print(f\"  Output dir: {output_dir}\")\n",
        "            \n",
        "            # Prepare environment with conda bin directory in PATH\n",
        "            env = os.environ.copy()\n",
        "            if 'MFA_CONDA_ENV_PATH' in globals() and MFA_CONDA_ENV_PATH:\n",
        "                conda_bin = os.path.join(MFA_CONDA_ENV_PATH, \"bin\")\n",
        "                # Prepend conda bin to PATH so fstcompile and other tools are found\n",
        "                env[\"PATH\"] = conda_bin + os.pathsep + env.get(\"PATH\", \"\")\n",
        "                print(f\"  Using conda environment PATH: {conda_bin}\")\n",
        "            \n",
        "            # Try alignment with increasing beam sizes if needed\n",
        "            beam_sizes = [\n",
        "                (10, 40),   # Default\n",
        "                (100, 400), # Large (as suggested by error)\n",
        "                (200, 800), # Larger\n",
        "                (400, 1600) # Huge (for longer sequences)\n",
        "            ]\n",
        "            \n",
        "            result = None\n",
        "            alignment_successful = False\n",
        "            \n",
        "            for beam, retry_beam in beam_sizes:\n",
        "                if alignment_successful:\n",
        "                    break\n",
        "                    \n",
        "                print(f\"  Trying alignment with beam={beam}, retry_beam={retry_beam}...\")\n",
        "                \n",
        "                # Try to use conda run if we have the env name, otherwise use direct command\n",
        "                if 'MFA_CONDA_ENV' in globals() and MFA_CONDA_ENV:\n",
        "                    try:\n",
        "                        # Use conda run to ensure proper environment\n",
        "                        cmd = [\"conda\", \"run\", \"-n\", MFA_CONDA_ENV, \"mfa\", \"align\", \n",
        "                               corpus_dir, \"english_us_mfa\", \"english_mfa\", output_dir, \n",
        "                               \"--clean\", \"--beam\", str(beam), \"--retry_beam\", str(retry_beam)]\n",
        "                        result = subprocess.run(\n",
        "                            cmd,\n",
        "                            capture_output=True,\n",
        "                            text=True,\n",
        "                            timeout=300,\n",
        "                            env=env  # Use modified environment with conda bin in PATH\n",
        "                        )\n",
        "                    except FileNotFoundError:\n",
        "                        # conda command not in PATH, fall back to direct MFA command\n",
        "                        cmd = [mfa_command, \"align\", corpus_dir, \"english_us_mfa\", \"english_mfa\", output_dir, \n",
        "                               \"--clean\", \"--beam\", str(beam), \"--retry_beam\", str(retry_beam)]\n",
        "                        result = subprocess.run(\n",
        "                            cmd,\n",
        "                            capture_output=True,\n",
        "                            text=True,\n",
        "                            timeout=300,\n",
        "                            env=env  # Use modified environment with conda bin in PATH\n",
        "                        )\n",
        "                else:\n",
        "                    # Direct MFA command with modified PATH\n",
        "                    cmd = [mfa_command, \"align\", corpus_dir, \"english_us_mfa\", \"english_mfa\", output_dir, \n",
        "                           \"--clean\", \"--beam\", str(beam), \"--retry_beam\", str(retry_beam)]\n",
        "                    result = subprocess.run(\n",
        "                        cmd,\n",
        "                        capture_output=True,\n",
        "                        text=True,\n",
        "                        timeout=300,\n",
        "                        env=env  # Use modified environment with conda bin in PATH\n",
        "                    )\n",
        "                \n",
        "                # Check if alignment was successful\n",
        "                if result.returncode == 0:\n",
        "                    alignment_successful = True\n",
        "                    print(f\"  âœ“ Alignment successful with beam={beam}, retry_beam={retry_beam}\")\n",
        "                    break\n",
        "                elif \"noalignmentserror\" in result.stderr.lower() or \"no successful alignments\" in result.stderr.lower():\n",
        "                    # Try next beam size\n",
        "                    print(f\"  âš ï¸  No alignments with beam={beam}, retry_beam={retry_beam}, trying larger beam...\")\n",
        "                    continue\n",
        "                else:\n",
        "                    # Different error, break and show it\n",
        "                    break\n",
        "            \n",
        "            if result.returncode == 0:\n",
        "                # Parse TextGrid output\n",
        "                textgrid_path = os.path.join(output_dir, f\"{audio_basename}.TextGrid\")\n",
        "                \n",
        "                if os.path.exists(textgrid_path):\n",
        "                    # Parse TextGrid\n",
        "                    try:\n",
        "                        from textgrid import TextGrid\n",
        "                        tg = TextGrid.fromFile(textgrid_path)\n",
        "                        \n",
        "                        mfa_alignments = []\n",
        "                        # Find phone tier\n",
        "                        for tier in tg.tiers:\n",
        "                            if tier.name.lower() in ['phones', 'phone']:\n",
        "                                for interval in tier:\n",
        "                                    if interval.mark.strip():\n",
        "                                        mfa_alignments.append({\n",
        "                                            \"phoneme\": interval.mark.strip(),\n",
        "                                            \"start\": interval.minTime,\n",
        "                                            \"end\": interval.maxTime\n",
        "                                        })\n",
        "                                break\n",
        "                        \n",
        "                        print(f\"\\nâœ“ MFA alignment complete: {len(mfa_alignments)} phones aligned\")\n",
        "                        print(f\"\\nğŸ“Š All alignments ({len(mfa_alignments)} phones):\")\n",
        "                        for i, align in enumerate(mfa_alignments, 1):\n",
        "                            print(f\"   {i:3d}. {align['phoneme']:5s} [{align['start']:6.3f}s - {align['end']:6.3f}s]\")\n",
        "                    except ImportError:\n",
        "                        print(\"âš ï¸  textgrid library not available. Install with: pip install textgrid\")\n",
        "                        print(\"   Trying manual TextGrid parsing...\")\n",
        "                        # Try manual parsing as fallback\n",
        "                        mfa_alignments = parse_textgrid_manual(textgrid_path)\n",
        "                        if mfa_alignments:\n",
        "                            print(f\"âœ“ Parsed {len(mfa_alignments)} alignments manually\")\n",
        "                        else:\n",
        "                            mfa_alignments = []\n",
        "                else:\n",
        "                    # Check for any TextGrid files\n",
        "                    textgrid_files = [f for f in os.listdir(output_dir) if f.endswith('.TextGrid')]\n",
        "                    if textgrid_files:\n",
        "                        textgrid_path = os.path.join(output_dir, textgrid_files[0])\n",
        "                        try:\n",
        "                            from textgrid import TextGrid\n",
        "                            tg = TextGrid.fromFile(textgrid_path)\n",
        "                            mfa_alignments = []\n",
        "                            for tier in tg.tiers:\n",
        "                                if tier.name.lower() in ['phones', 'phone']:\n",
        "                                    for interval in tier:\n",
        "                                        if interval.mark.strip():\n",
        "                                            mfa_alignments.append({\n",
        "                                                \"phoneme\": interval.mark.strip(),\n",
        "                                                \"start\": interval.minTime,\n",
        "                                                \"end\": interval.maxTime\n",
        "                                            })\n",
        "                                    break\n",
        "                            print(f\"\\nâœ“ MFA alignment complete: {len(mfa_alignments)} phones aligned\")\n",
        "                        except:\n",
        "                            mfa_alignments = []\n",
        "                    else:\n",
        "                        print(f\"âš ï¸  TextGrid file not found in {output_dir}\")\n",
        "                        print(f\"   MFA output: {result.stdout[:200] if result.stdout else 'No output'}\")\n",
        "                        mfa_alignments = []\n",
        "            else:\n",
        "                print(f\"âš ï¸  MFA alignment failed (return code: {result.returncode})\")\n",
        "                print(\"\\n\" + \"=\"*70)\n",
        "                print(\"FULL ERROR OUTPUT:\")\n",
        "                print(\"=\"*70)\n",
        "                if result.stderr:\n",
        "                    error_msg = result.stderr.strip()\n",
        "                    print(\"STDERR:\")\n",
        "                    print(error_msg)  # Show full error, not truncated\n",
        "                    print(\"\\n\" + \"=\"*70)\n",
        "                    # Check for common issues\n",
        "                    if \"fstcompile\" in error_msg.lower() or \"openfst\" in error_msg.lower() or \"thirdparty\" in error_msg.lower():\n",
        "                        print(\"\\n\" + \"=\"*70)\n",
        "                        print(\"âŒ MISSING DEPENDENCY: OpenFST (fstcompile)\")\n",
        "                        print(\"=\"*70)\n",
        "                        print(\"\\nMFA requires OpenFST to be installed in the conda environment.\")\n",
        "                        print(\"\\nTo fix this, run the following commands in your terminal:\")\n",
        "                        print(\"\\n  1. Activate your conda environment:\")\n",
        "                        print(\"     conda activate aligner\")\n",
        "                        print(\"\\n  2. Install OpenFST:\")\n",
        "                        print(\"     conda install -c conda-forge openfst\")\n",
        "                        print(\"\\n  3. Verify installation:\")\n",
        "                        print(\"     which fstcompile\")\n",
        "                        print(\"     # Should show: <conda_env_path>/bin/fstcompile\")\n",
        "                        print(\"\\n  4. Restart this notebook after installation.\")\n",
        "                        print(\"\\nAlternative: Reinstall MFA with all dependencies:\")\n",
        "                        print(\"  conda install -c conda-forge montreal-forced-aligner --force-reinstall\")\n",
        "                        print(\"=\"*70)\n",
        "                    elif \"not found\" in error_msg.lower() or \"does not exist\" in error_msg.lower():\n",
        "                        print(\"\\n   ğŸ’¡ Tip: Make sure the audio file exists and is accessible\")\n",
        "                    elif \"noalignmentserror\" in error_msg.lower() or \"no successful alignments\" in error_msg.lower():\n",
        "                        print(\"\\n\" + \"=\"*70)\n",
        "                        print(\"âŒ ALIGNMENT FAILED: No successful alignments found\")\n",
        "                        print(\"=\"*70)\n",
        "                        print(\"\\nThis usually means:\")\n",
        "                        print(\"  1. The text doesn't match what's in the audio\")\n",
        "                        print(\"  2. The audio quality is too poor\")\n",
        "                        print(\"  3. The text contains words not in the dictionary\")\n",
        "                        print(\"  4. The beam size was too small (already tried larger beams)\")\n",
        "                        print(\"\\nğŸ’¡ Suggestions:\")\n",
        "                        print(\"  1. Check if the transcript matches the audio content\")\n",
        "                        print(\"  2. Verify audio quality (clear speech, not too noisy)\")\n",
        "                        print(\"  3. Try validating the corpus:\")\n",
        "                        print(f\"     mfa validate {corpus_dir} english_us_mfa\")\n",
        "                        print(\"  4. Check if all words in the text are in the dictionary\")\n",
        "                        print(\"  5. Try with a shorter or simpler text\")\n",
        "                        print(\"=\"*70)\n",
        "                    elif \"dictionary\" in error_msg.lower() or \"model\" in error_msg.lower():\n",
        "                        print(\"\\n   ğŸ’¡ Tip: Make sure MFA models are downloaded:\")\n",
        "                        print(\"      mfa model download dictionary english_us_mfa\")\n",
        "                        print(\"      mfa model download acoustic english_mfa\")\n",
        "                    elif \"usage\" in error_msg.lower() or \"error\" in error_msg.lower():\n",
        "                        print(\"\\n   ğŸ’¡ Tip: The MFA command syntax might be incorrect.\")\n",
        "                        print(\"      Try running manually to see the correct syntax:\")\n",
        "                        print(f\"      {mfa_command} align --help\")\n",
        "                if result.stdout:\n",
        "                    stdout_msg = result.stdout.strip()\n",
        "                    print(\"STDOUT:\")\n",
        "                    print(stdout_msg)  # Show full output\n",
        "                    print(\"=\"*70)\n",
        "                mfa_alignments = []\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  MFA alignment error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            mfa_alignments = []\n",
        "\n",
        "\n",
        "# Helper function for manual TextGrid parsing (fallback)\n",
        "def parse_textgrid_manual(textgrid_path: str) -> List[Dict]:\n",
        "    \"\"\"Manually parse TextGrid file if textgrid library not available.\"\"\"\n",
        "    alignments = []\n",
        "    try:\n",
        "        with open(textgrid_path, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "        \n",
        "        # Simple TextGrid parser - look for intervals with xmin, xmax, and text\n",
        "        i = 0\n",
        "        in_phone_tier = False\n",
        "        while i < len(lines):\n",
        "            line = lines[i].strip()\n",
        "            if 'item [2]' in line or 'name = \"phones\"' in line.lower() or 'name = \"phone\"' in line.lower():\n",
        "                in_phone_tier = True\n",
        "                i += 1\n",
        "                continue\n",
        "            \n",
        "            if in_phone_tier and 'intervals [' in line:\n",
        "                # Found an interval\n",
        "                i += 1\n",
        "                xmin = None\n",
        "                xmax = None\n",
        "                text = \"\"\n",
        "                \n",
        "                while i < len(lines) and ('intervals [' not in lines[i] or i == len(lines) - 1):\n",
        "                    if 'xmin =' in lines[i]:\n",
        "                        xmin = float(lines[i].split('=')[1].strip())\n",
        "                    elif 'xmax =' in lines[i]:\n",
        "                        xmax = float(lines[i].split('=')[1].strip())\n",
        "                    elif 'text =' in lines[i]:\n",
        "                        text = lines[i].split('=')[1].strip().strip('\"')\n",
        "                    i += 1\n",
        "                    if i >= len(lines):\n",
        "                        break\n",
        "                \n",
        "                if xmin is not None and xmax is not None and text.strip():\n",
        "                    alignments.append({\n",
        "                        \"phoneme\": text.strip(),\n",
        "                        \"start\": xmin,\n",
        "                        \"end\": xmax\n",
        "                    })\n",
        "                continue\n",
        "            i += 1\n",
        "        \n",
        "        return alignments\n",
        "    except Exception as e:\n",
        "        print(f\"   Manual parsing failed: {e}\")\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Compare Actual vs Target IPA (Error Detection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 4: Compare Actual vs Target Pronunciation\n",
            "======================================================================\n",
            "\n",
            "Comparing pronunciation...\n",
            "  Actual phones:  82 phones\n",
            "  Target phones:  86 phones\n",
            "\n",
            "âœ“ Error Detection Complete\n",
            "\n",
            "ğŸ“Š Edit Operations Summary:\n",
            "   Total errors:     15\n",
            "   Substitutions:    7\n",
            "   Insertions:       6\n",
            "   Deletions:        2\n",
            "\n",
            "ğŸ“‹ All Errors Detected (15 total):\n",
            "     1. delete       @ pos  21: extra 'd'\n",
            "     2. insert       @ pos  35: missing 'ÊŠ'\n",
            "     3. insert       @ pos  35: missing 'd'\n",
            "     4. insert       @ pos  35: missing 'k'\n",
            "     5. substitute   @ pos  35: expected 'o' but got 'i'\n",
            "     6. substitute   @ pos  36: expected 'ÊŠ' but got 'kÊ°'\n",
            "     7. substitute   @ pos  37: expected 'tÊ°' but got 'É”'\n",
            "     8. substitute   @ pos  38: expected 'u' but got 'z'\n",
            "     9. substitute   @ pos  39: expected 'Ã°' but got 'Éª'\n",
            "    10. substitute   @ pos  40: expected 'É™' but got 't'\n",
            "    11. insert       @ pos  52: missing 'a'\n",
            "    12. insert       @ pos  52: missing 'Éª'\n",
            "    13. insert       @ pos  72: missing 'Ã°'\n",
            "    14. delete       @ pos  73: extra 'z'\n",
            "    15. substitute   @ pos  74: expected 's' but got 'É™'\n",
            "\n",
            "ğŸ“ˆ Pronunciation Score: 87.21%\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Step 4: Compare Actual vs Target IPA (Error Detection)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 4: Compare Actual vs Target Pronunciation\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import edit distance function\n",
        "sys.path.insert(0, str(mod_path / \"assessment\"))\n",
        "from edit_distance import edit_operations\n",
        "\n",
        "print(f\"\\nComparing pronunciation...\")\n",
        "print(f\"  Actual phones:  {len(actual_phones)} phones\")\n",
        "print(f\"  Target phones:  {len(target_phones)} phones\")\n",
        "\n",
        "# Run edit distance\n",
        "operations = edit_operations(actual_phones, target_phones)\n",
        "\n",
        "# Count operation types\n",
        "substitutes = [op for op in operations if op[0] == \"substitute\"]\n",
        "inserts = [op for op in operations if op[0] == \"insert\"]\n",
        "deletes = [op for op in operations if op[0] == \"delete\"]\n",
        "\n",
        "print(f\"\\nâœ“ Error Detection Complete\")\n",
        "print(f\"\\nğŸ“Š Edit Operations Summary:\")\n",
        "print(f\"   Total errors:     {len(operations)}\")\n",
        "print(f\"   Substitutions:    {len(substitutes)}\")\n",
        "print(f\"   Insertions:       {len(inserts)}\")\n",
        "print(f\"   Deletions:        {len(deletes)}\")\n",
        "\n",
        "# Show ALL errors (not truncated)\n",
        "if len(operations) > 0:\n",
        "    print(f\"\\nğŸ“‹ All Errors Detected ({len(operations)} total):\")\n",
        "    for i, op in enumerate(operations, 1):\n",
        "        op_type = op[0]\n",
        "        pos = op[1]\n",
        "        \n",
        "        if op_type == \"substitute\":\n",
        "            expected = op[2] if len(op) > 2 else \"?\"\n",
        "            actual = actual_phones[pos] if pos < len(actual_phones) else \"?\"\n",
        "            print(f\"   {i:3d}. {op_type:12s} @ pos {pos:3d}: expected '{expected}' but got '{actual}'\")\n",
        "        elif op_type == \"insert\":\n",
        "            expected = op[2] if len(op) > 2 else \"?\"\n",
        "            print(f\"   {i:3d}. {op_type:12s} @ pos {pos:3d}: missing '{expected}'\")\n",
        "        elif op_type == \"delete\":\n",
        "            actual = actual_phones[pos] if pos < len(actual_phones) else \"?\"\n",
        "            print(f\"   {i:3d}. {op_type:12s} @ pos {pos:3d}: extra '{actual}'\")\n",
        "else:\n",
        "    print(f\"\\nâœ“ No errors detected! Perfect pronunciation!\")\n",
        "\n",
        "# Calculate score\n",
        "total_phonemes = len(target_phones)\n",
        "if total_phonemes == 0:\n",
        "    score = 1.0 if len(actual_phones) == 0 else 0.0\n",
        "else:\n",
        "    error_cost = sum(\n",
        "        1 if op[0] == \"delete\" else\n",
        "        1 if op[0] == \"insert\" else\n",
        "        2 if op[0] == \"substitute\" else 0\n",
        "        for op in operations\n",
        "    )\n",
        "    max_cost = total_phonemes * 2\n",
        "    score = max(0.0, 1.0 - (error_cost / max_cost))\n",
        "\n",
        "print(f\"\\nğŸ“ˆ Pronunciation Score: {score:.2%}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Map Errors to Timestamps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 5: Map Errors to Audio Timestamps\n",
            "======================================================================\n",
            "\n",
            "Mapping errors to timestamps...\n",
            "\n",
            "âœ“ Mapped 15 errors to timestamps\n",
            "\n",
            "ğŸ“‹ All Errors with Timestamps (15 total):\n",
            "     1. delete       @ [ 0.610s -  0.640s]: extra 'd'\n",
            "     2. insert       @ [ 7.980s -  8.080s]: missing 'ÊŠ'\n",
            "     3. insert       @ [ 7.980s -  8.080s]: missing 'd'\n",
            "     4. insert       @ [ 7.980s -  8.080s]: missing 'k'\n",
            "     5. substitute   @ [ 8.030s -  8.060s]: expected 'o' but got 'i'\n",
            "     6. substitute   @ [ 8.060s -  8.090s]: expected 'ÊŠ' but got 'kÊ°'\n",
            "     7. substitute   @ [ 8.090s -  8.100s]: expected 'tÊ°' but got 'É”'\n",
            "     8. substitute   @ [ 8.100s -  8.130s]: expected 'u' but got 'z'\n",
            "     9. substitute   @ [ 8.130s -  8.160s]: expected 'Ã°' but got 'Éª'\n",
            "    10. substitute   @ [ 8.160s -  8.180s]: expected 'É™' but got 't'\n",
            "    11. insert       @ [ 8.440s -  8.540s]: missing 'a'\n",
            "    12. insert       @ [ 8.440s -  8.540s]: missing 'Éª'\n",
            "    13. insert       @ [ 0.000s -  0.100s]: missing 'Ã°'\n",
            "    14. delete       @ [ 0.000s -  0.100s]: extra 'z'\n",
            "    15. substitute   @ [ 0.000s -  0.100s]: expected 's' but got 'É™'\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "def map_errors_to_timestamps(\n",
        "    operations: List,\n",
        "    actual_phones: List[str],\n",
        "    target_phones: List[str],\n",
        "    mfa_alignments: List[Dict],\n",
        "    sample_rate: int\n",
        ") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Map edit operations to timestamps from MFA alignment.\n",
        "    \n",
        "    MFA alignments provide timestamps for phones aligned from target text.\n",
        "    We map errors based on their position in the target sequence.\n",
        "    \"\"\"\n",
        "    errors_with_timestamps = []\n",
        "    \n",
        "    if not mfa_alignments:\n",
        "        # Fallback: evenly distribute timestamps\n",
        "        total_duration = len(actual_phones) * 0.1  # Assume ~100ms per phone\n",
        "        for op in operations:\n",
        "            op_type = op[0]\n",
        "            pos = op[1]\n",
        "            \n",
        "            error_dict = {\"type\": op_type, \"position\": pos}\n",
        "            \n",
        "            if op_type == \"substitute\":\n",
        "                error_dict[\"expected\"] = op[2] if len(op) > 2 else None\n",
        "                error_dict[\"actual\"] = actual_phones[pos] if pos < len(actual_phones) else None\n",
        "            elif op_type == \"insert\":\n",
        "                error_dict[\"expected\"] = op[2] if len(op) > 2 else None\n",
        "            elif op_type == \"delete\":\n",
        "                error_dict[\"actual\"] = actual_phones[pos] if pos < len(actual_phones) else None\n",
        "            \n",
        "            # Dummy timestamps\n",
        "            start_time = pos * 0.1\n",
        "            end_time = (pos + 1) * 0.1\n",
        "            error_dict[\"timestamp_seconds\"] = {\"start\": start_time, \"end\": end_time}\n",
        "            error_dict[\"timestamp_samples\"] = {\n",
        "                \"start\": int(start_time * sample_rate),\n",
        "                \"end\": int(end_time * sample_rate)\n",
        "            }\n",
        "            \n",
        "            errors_with_timestamps.append(error_dict)\n",
        "        return errors_with_timestamps\n",
        "    \n",
        "    # Map operations to MFA timestamps\n",
        "    for op in operations:\n",
        "        op_type = op[0]\n",
        "        pos = op[1]\n",
        "        \n",
        "        error_dict = {\"type\": op_type, \"position\": pos}\n",
        "        \n",
        "        if op_type == \"substitute\":\n",
        "            error_dict[\"expected\"] = op[2] if len(op) > 2 else None\n",
        "            error_dict[\"actual\"] = actual_phones[pos] if pos < len(actual_phones) else None\n",
        "            \n",
        "            # Use timestamp from target position\n",
        "            if pos < len(mfa_alignments):\n",
        "                align = mfa_alignments[pos]\n",
        "                error_dict[\"timestamp_seconds\"] = {\"start\": align[\"start\"], \"end\": align[\"end\"]}\n",
        "                error_dict[\"timestamp_samples\"] = {\n",
        "                    \"start\": int(align[\"start\"] * sample_rate),\n",
        "                    \"end\": int(align[\"end\"] * sample_rate)\n",
        "                }\n",
        "            else:\n",
        "                # Fallback for out-of-bounds\n",
        "                error_dict[\"timestamp_seconds\"] = {\"start\": 0.0, \"end\": 0.1}\n",
        "                error_dict[\"timestamp_samples\"] = {\"start\": 0, \"end\": int(0.1 * sample_rate)}\n",
        "                \n",
        "        elif op_type == \"insert\":\n",
        "            error_dict[\"expected\"] = op[2] if len(op) > 2 else None\n",
        "            \n",
        "            # Insertion: use timestamp between adjacent phones\n",
        "            if pos > 0 and pos <= len(mfa_alignments):\n",
        "                if pos < len(mfa_alignments):\n",
        "                    prev_end = mfa_alignments[pos-1][\"end\"]\n",
        "                    next_start = mfa_alignments[pos][\"start\"]\n",
        "                    mid_time = (prev_end + next_start) / 2\n",
        "                    error_dict[\"timestamp_seconds\"] = {\"start\": mid_time - 0.05, \"end\": mid_time + 0.05}\n",
        "                else:\n",
        "                    last_end = mfa_alignments[-1][\"end\"]\n",
        "                    error_dict[\"timestamp_seconds\"] = {\"start\": last_end, \"end\": last_end + 0.1}\n",
        "            else:\n",
        "                error_dict[\"timestamp_seconds\"] = {\"start\": 0.0, \"end\": 0.1}\n",
        "            \n",
        "            error_dict[\"timestamp_samples\"] = {\n",
        "                \"start\": int(error_dict[\"timestamp_seconds\"][\"start\"] * sample_rate),\n",
        "                \"end\": int(error_dict[\"timestamp_seconds\"][\"end\"] * sample_rate)\n",
        "            }\n",
        "            \n",
        "        elif op_type == \"delete\":\n",
        "            error_dict[\"actual\"] = actual_phones[pos] if pos < len(actual_phones) else None\n",
        "            \n",
        "            # Deletion: use timestamp from actual phone position\n",
        "            if pos < len(mfa_alignments):\n",
        "                align = mfa_alignments[pos]\n",
        "                error_dict[\"timestamp_seconds\"] = {\"start\": align[\"start\"], \"end\": align[\"end\"]}\n",
        "                error_dict[\"timestamp_samples\"] = {\n",
        "                    \"start\": int(align[\"start\"] * sample_rate),\n",
        "                    \"end\": int(align[\"end\"] * sample_rate)\n",
        "                }\n",
        "            else:\n",
        "                error_dict[\"timestamp_seconds\"] = {\"start\": 0.0, \"end\": 0.1}\n",
        "                error_dict[\"timestamp_samples\"] = {\"start\": 0, \"end\": int(0.1 * sample_rate)}\n",
        "        \n",
        "        errors_with_timestamps.append(error_dict)\n",
        "    \n",
        "    return errors_with_timestamps\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Step 5: Map Errors to Timestamps\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 5: Map Errors to Audio Timestamps\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Map errors to timestamps\n",
        "print(\"\\nMapping errors to timestamps...\")\n",
        "errors_with_timestamps = map_errors_to_timestamps(\n",
        "    operations,\n",
        "    actual_phones,\n",
        "    target_phones,\n",
        "    mfa_alignments if 'mfa_alignments' in locals() else [],\n",
        "    rate\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ“ Mapped {len(errors_with_timestamps)} errors to timestamps\")\n",
        "\n",
        "# Show ALL errors with timestamps (not truncated)\n",
        "if len(errors_with_timestamps) > 0:\n",
        "    print(f\"\\nğŸ“‹ All Errors with Timestamps ({len(errors_with_timestamps)} total):\")\n",
        "    for i, error in enumerate(errors_with_timestamps, 1):\n",
        "        op_type = error[\"type\"]\n",
        "        ts = error[\"timestamp_seconds\"]\n",
        "        \n",
        "        if op_type == \"substitute\":\n",
        "            print(f\"   {i:3d}. {op_type:12s} @ [{ts['start']:6.3f}s - {ts['end']:6.3f}s]: \"\n",
        "                  f\"expected '{error.get('expected', '?')}' but got '{error.get('actual', '?')}'\")\n",
        "        elif op_type == \"insert\":\n",
        "            print(f\"   {i:3d}. {op_type:12s} @ [{ts['start']:6.3f}s - {ts['end']:6.3f}s]: \"\n",
        "                  f\"missing '{error.get('expected', '?')}'\")\n",
        "        elif op_type == \"delete\":\n",
        "            print(f\"   {i:3d}. {op_type:12s} @ [{ts['start']:6.3f}s - {ts['end']:6.3f}s]: \"\n",
        "                  f\"extra '{error.get('actual', '?')}'\")\n",
        "else:\n",
        "    print(\"\\nâœ“ No errors to map (perfect pronunciation!)\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "FINAL RESULTS: Compiling Assessment\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "PRONUNCIATION ASSESSMENT SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Selected configuration: Sentence 12 (Yusuf) (index 2)\n",
            "Sentence ID: 12\n",
            "\n",
            "ğŸ“ Input:\n",
            "   Target Text: The weather is rather warm this Thursday. I think we should go to the theater together. Thank you for thinking about this thoroughly.\n",
            "   Actual Text (ASR): the weather is rather warm this Thursday  â‡  think we she cause it the theater together think you for thinking about is authority\n",
            "\n",
            "ğŸ“Š Results:\n",
            "   Pronunciation Score: 87.21%\n",
            "\n",
            "ğŸ“ˆ Statistics:\n",
            "   Total Errors: 15\n",
            "     - Substitutions: 7\n",
            "     - Insertions:    6\n",
            "     - Deletions:     2\n",
            "   Actual Phones: 82\n",
            "   Target Phones (Original): 86\n",
            "   Target Phones (ASR):    80\n",
            "   Difference:            6\n",
            "   MFA Alignments: 68\n",
            "\n",
            "ğŸ’¾ Output:\n",
            "   âœ“ Results saved to: results/pronunciation_assessment_yusuf12-r_20251209_224011.json\n",
            "   âœ“ Audio file: yusuf12-r.wav\n",
            "   âœ“ Timestamp: 20251209_224011\n",
            "\n",
            "ğŸ“ Note: Assessment uses target phones from ORIGINAL TRANSCRIPT (ground truth)\n",
            "   Both versions (original and ASR-based) are saved in the JSON output.\n",
            "\n",
            "Config index: 2\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Final Results: Compile and Save Assessment\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL RESULTS: Compiling Assessment\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Generate timestamp for output filename\n",
        "from datetime import datetime\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Compile final result (using original transcript G2P as primary)\n",
        "assessment_result = {\n",
        "    \"metadata\": {\n",
        "        \"config_label\": selected_config.get(\"label\"),\n",
        "        \"selected_config_index\": selected_config_index,\n",
        "        \"sentence_id\": selected_config[\"sentence_id\"],\n",
        "        \"audio_file\": os.path.basename(audio_file),\n",
        "        \"audio_path\": audio_file,\n",
        "        \"audio_basename\": audio_basename,\n",
        "        \"audio_duration_seconds\": audio_duration,\n",
        "        \"sample_rate\": rate,\n",
        "        \"timestamp\": timestamp,\n",
        "    },\n",
        "    \"target_text\": target_text,\n",
        "    \"actual_text\": pred_asr if 'pred_asr' in locals() else None,\n",
        "    \"actual_ipa_powsm\": pred_pr,\n",
        "    \"target_ipa_powsm\": {\n",
        "        \"from_original_transcript\": {\n",
        "            \"powsm_format\": pred_g2p_original if 'pred_g2p_original' in locals() else None,\n",
        "            \"clean\": pred_g2p_original_clean if 'pred_g2p_original_clean' in locals() else None,\n",
        "            \"phones\": target_phones\n",
        "        },\n",
        "        \"from_asr_transcript\": {\n",
        "            \"powsm_format\": pred_g2p_asr if 'pred_g2p_asr' in locals() else None,\n",
        "            \"clean\": pred_g2p_asr_clean if 'pred_g2p_asr_clean' in locals() else None,\n",
        "            \"phones\": target_phones_asr if 'target_phones_asr' in locals() else None\n",
        "        }\n",
        "    },\n",
        "    \"actual_phones\": actual_phones,\n",
        "    \"target_phones\": target_phones,  # Primary: from original transcript\n",
        "    \"target_phones_asr\": target_phones_asr if 'target_phones_asr' in locals() else None,  # Comparison: from ASR\n",
        "    \"score\": score,\n",
        "    \"errors\": errors_with_timestamps,\n",
        "    \"mfa_alignments\": mfa_alignments if 'mfa_alignments' in locals() else [],\n",
        "    \"statistics\": {\n",
        "        \"total_errors\": len(operations),\n",
        "        \"substitutions\": len(substitutes),\n",
        "        \"insertions\": len(inserts),\n",
        "        \"deletions\": len(deletes),\n",
        "        \"actual_phone_count\": len(actual_phones),\n",
        "        \"target_phone_count\": len(target_phones),\n",
        "        \"target_phone_count_asr\": len(target_phones_asr) if 'target_phones_asr' in locals() else None\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "output_dir = Path(\"results\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Generate output filename with audio basename and timestamp\n",
        "output_filename = f\"pronunciation_assessment_{audio_basename}_{timestamp}.json\"\n",
        "output_file = output_dir / output_filename\n",
        "\n",
        "# Add output file path to metadata\n",
        "assessment_result[\"metadata\"][\"output_file\"] = str(output_file)\n",
        "\n",
        "# Save to JSON\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(assessment_result, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PRONUNCIATION ASSESSMENT SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nSelected configuration: {selected_config.get('label', selected_config['audio_filename'])} (index {selected_config_index})\")\n",
        "print(f\"Sentence ID: {selected_config['sentence_id']}\")\n",
        "print(f\"\\nğŸ“ Input:\")\n",
        "print(f\"   Target Text: {target_text}\")\n",
        "print(f\"   Actual Text (ASR): {pred_asr if 'pred_asr' in locals() else 'N/A'}\")\n",
        "print(f\"\\nğŸ“Š Results:\")\n",
        "print(f\"   Pronunciation Score: {score:.2%}\")\n",
        "print(f\"\\nğŸ“ˆ Statistics:\")\n",
        "print(f\"   Total Errors: {len(operations)}\")\n",
        "print(f\"     - Substitutions: {len(substitutes)}\")\n",
        "print(f\"     - Insertions:    {len(inserts)}\")\n",
        "print(f\"     - Deletions:     {len(deletes)}\")\n",
        "print(f\"   Actual Phones: {len(actual_phones)}\")\n",
        "print(f\"   Target Phones (Original): {len(target_phones)}\")\n",
        "if 'target_phones_asr' in locals():\n",
        "    print(f\"   Target Phones (ASR):    {len(target_phones_asr)}\")\n",
        "    print(f\"   Difference:            {abs(len(target_phones) - len(target_phones_asr))}\")\n",
        "print(f\"   MFA Alignments: {len(mfa_alignments) if 'mfa_alignments' in locals() else 0}\")\n",
        "print(f\"\\nğŸ’¾ Output:\")\n",
        "print(f\"   âœ“ Results saved to: {output_file}\")\n",
        "print(f\"   âœ“ Audio file: {os.path.basename(audio_file)}\")\n",
        "print(f\"   âœ“ Timestamp: {timestamp}\")\n",
        "print(f\"\\nğŸ“ Note: Assessment uses target phones from ORIGINAL TRANSCRIPT (ground truth)\")\n",
        "if 'target_phones_asr' in locals():\n",
        "    print(f\"   Both versions (original and ASR-based) are saved in the JSON output.\")\n",
        "print(f\"\\nConfig index: {selected_config_index}\")\n",
        "print(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
