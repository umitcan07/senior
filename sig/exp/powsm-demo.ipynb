{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc4fc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the audio file 20s 16kHz mono (POWSM requirement: 16kHz, 20s fixed duration)\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def process_audio(input_file, output_file, target_sr=16000, target_duration=20):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(input_file, sr=None, mono=True)\n",
    "\n",
    "    # Resample to target sample rate if necessary\n",
    "    if sr != target_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "        sr = target_sr\n",
    "\n",
    "    # Calculate the target number of samples\n",
    "    target_length = target_duration * sr\n",
    "\n",
    "    # Pad or truncate the audio to the target length\n",
    "    if len(y) < target_length:\n",
    "        # Pad with zeros at the end\n",
    "        y = librosa.util.fix_length(y, size=target_length)\n",
    "    else:\n",
    "        # Truncate to the target length\n",
    "        y = y[:target_length]\n",
    "\n",
    "    # Save the processed audio file using soundfile (librosa.output was removed in newer versions)\n",
    "    sf.write(output_file, y, sr)\n",
    "\n",
    "process_audio(\"./audio/pi_mono_trimmed.wav\", \"./audio/pi_powsm.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11126da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 124936.71it/s]\n",
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/espnet2/s2t/espnet_model.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<eng>', 0.9905632734298706)\n"
     ]
    }
   ],
   "source": [
    "# Note: Make sure torchaudio is installed: pip install torchaudio\n",
    "from espnet2.bin.s2t_inference_language import \n",
    "import soundfile as sf      # or librosa\n",
    "\n",
    "s2t = Speech2Language.from_pretrained(\n",
    "    \"espnet/powsm\",\n",
    "    device=\"cpu\",\n",
    "    nbest=1,                # number of possible languages to return\n",
    "    first_lang_sym=\"<afr>\", # fixed; defined in vocab list\n",
    "    last_lang_sym=\"<zul>\"   # fixed; defined in vocab list\n",
    ")\n",
    "\n",
    "# Use the processed audio file (16kHz, 20s) from the previous cell\n",
    "speech, rate = sf.read(\"./audio/pi_powsm.wav\")\n",
    "pred = s2t(speech)[0]     # a list of lang-prob pair\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52b87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 158703.39it/s]\n",
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/espnet2/s2t/espnet_model.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone Recognition Result:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Phone Recognition (PR) with POWSM\n",
    "from espnet2.bin.s2t_inference import Speech2Text\n",
    "import soundfile as sf\n",
    "\n",
    "# Use the processed audio file (16kHz, 20s) from the preprocessing cell\n",
    "speech, rate = sf.read(\"./audio/pi_powsm.wav\")\n",
    "print(f\"Audio loaded: {len(speech)} samples at {rate} Hz ({len(speech)/rate:.2f} seconds)\")\n",
    "\n",
    "# Initialize model for Phone Recognition\n",
    "s2t_pr = Speech2Text.from_pretrained(\n",
    "    \"espnet/powsm\",\n",
    "    device=\"cpu\",  # Use \"cuda\" if you have GPU\n",
    "    lang_sym=\"<eng>\",   # ISO 639-3 language code; set to <unk> for unseen languages\n",
    "    task_sym=\"<pr>\",    # Phone Recognition task\n",
    ")\n",
    "\n",
    "# For PR, prompt should be \"<na>\" (not applicable)\n",
    "prompt = \"<na>\"\n",
    "\n",
    "# Get prediction\n",
    "try:\n",
    "    result = s2t_pr(speech, text_prev=prompt)\n",
    "    print(f\"Raw result type: {type(result)}\")\n",
    "    print(f\"Raw result: {result}\")\n",
    "    \n",
    "    # Handle the result - it might be a list or tuple\n",
    "    if isinstance(result, (list, tuple)) and len(result) > 0:\n",
    "        pred = result[0]\n",
    "        if isinstance(pred, (list, tuple)) and len(pred) > 0:\n",
    "            pred = pred[0]\n",
    "        \n",
    "        # Post-processing for better format\n",
    "        if isinstance(pred, str):\n",
    "            # Check if it contains <notimestamps>\n",
    "            if \"<notimestamps>\" in pred:\n",
    "                pred = pred.split(\"<notimestamps>\")[1].strip()\n",
    "            else:\n",
    "                pred = pred.strip()\n",
    "            \n",
    "            # Remove slashes for PR (phones are enclosed in slashes in the model output)\n",
    "            pred = pred.replace(\"/\", \"\")\n",
    "            \n",
    "            print(\"\\nPhone Recognition Result:\")\n",
    "            print(pred)\n",
    "        else:\n",
    "            print(f\"Unexpected prediction format: {type(pred)}\")\n",
    "            print(pred)\n",
    "    else:\n",
    "        print(\"Unexpected result format\")\n",
    "        print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Error during inference: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4b41f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio loaded: 320000 samples at 16000 Hz\n",
      "\n",
      "==================================================\n",
      "Phone Recognition (PR):\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 59796.59it/s]\n",
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/espnet2/s2t/espnet_model.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "Automatic Speech Recognition (ASR):\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 102657.79it/s]\n",
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/espnet2/s2t/espnet_model.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN ⁇  ANOT ⁇ ER C ⁇ A ⁇ ER  ⁇  FOR A ⁇ U ⁇ T ⁇ N ⁇  T ⁇ E FREQUENC ⁇  OF AFTE ⁇  CO ⁇ ONENT ⁇  E ⁇ T ⁇ ER  ⁇ A ⁇ E ⁇  OR  ⁇ UZZ ⁇ ER CURRENT ⁇   ⁇ AN ⁇ ER T ⁇ E ⁇ E  ⁇   ⁇ A ⁇  TO Z ⁇ RO AN ⁇   ⁇ ERE  ⁇ N  ⁇ EAR  ⁇ N  ⁇ EAR ⁇  OR  ⁇ UZZ ⁇ ER CURRENT ⁇   ⁇ AN ⁇ ER T ⁇ E ⁇ E  ⁇   ⁇ EA ⁇  TO T ⁇ E ER ⁇ T ⁇ N ⁇   ⁇ N ACT ⁇ ON\n",
      "\n",
      "==================================================\n",
      "Grapheme-to-Phoneme (G2P):\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 61422.86it/s]\n",
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/espnet2/s2t/espnet_model.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "Phoneme-to-Grapheme (P2G):\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 95948.13it/s]\n",
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/espnet2/s2t/espnet_model.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN ⁇  ANOT ⁇ ER  ⁇ N ⁇ ER  ⁇  FOR A ⁇ U ⁇ T ⁇ N ⁇  T ⁇ E FREQUENC ⁇  OF AFTE ⁇  CO ⁇ ONENT ⁇  E ⁇ T ⁇ ER  ⁇ A ⁇ E ⁇  OR  ⁇ UZZ ⁇ ER CURRENT ⁇   ⁇ AN ⁇ ER T ⁇ E ⁇ E  ⁇   ⁇ A ⁇  TO Z ⁇ RO AN ⁇   ⁇ ERE  ⁇ N A  ⁇ EAR  ⁇ A ⁇ E ⁇  OR  ⁇ UZZ ⁇ ER CURRENT ⁇   ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER T ⁇ E  ⁇ AN ⁇ ER  ⁇ AN ⁇ ER  ⁇ AN ⁇ ER  ⁇ AN ⁇ ER\n"
     ]
    }
   ],
   "source": [
    "# Example: All POWSM Tasks (PR, ASR, G2P, P2G)\n",
    "# IMPORTANT: Each task needs its own model instance - you cannot change task_sym after initialization\n",
    "from espnet2.bin.s2t_inference import Speech2Text\n",
    "import soundfile as sf\n",
    "\n",
    "# Load audio\n",
    "speech, rate = sf.read(\"./audio/pi_powsm.wav\")\n",
    "print(f\"Audio loaded: {len(speech)} samples at {rate} Hz\\n\")\n",
    "\n",
    "# Task 1: Phone Recognition (PR)\n",
    "print(\"=\" * 50)\n",
    "print(\"Phone Recognition (PR):\")\n",
    "print(\"=\" * 50)\n",
    "s2t_pr = Speech2Text.from_pretrained(\n",
    "    \"espnet/powsm\",\n",
    "    device=\"cpu\",\n",
    "    lang_sym=\"<eng>\",\n",
    "    task_sym=\"<pr>\",\n",
    ")\n",
    "pred_pr = s2t_pr(speech, text_prev=\"<na>\")[0][0]\n",
    "if \"<notimestamps>\" in pred_pr:\n",
    "    pred_pr = pred_pr.split(\"<notimestamps>\")[1].strip()\n",
    "pred_pr = pred_pr.replace(\"/\", \"\")  # Remove slashes for PR\n",
    "print(pred_pr)\n",
    "\n",
    "# Task 2: Automatic Speech Recognition (ASR)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Automatic Speech Recognition (ASR):\")\n",
    "print(\"=\" * 50)\n",
    "s2t_asr = Speech2Text.from_pretrained(\n",
    "    \"espnet/powsm\",\n",
    "    device=\"cpu\",\n",
    "    lang_sym=\"<eng>\",\n",
    "    task_sym=\"<asr>\",\n",
    ")\n",
    "pred_asr = s2t_asr(speech, text_prev=\"<na>\")[0][0]\n",
    "if \"<notimestamps>\" in pred_asr:\n",
    "    pred_asr = pred_asr.split(\"<notimestamps>\")[1].strip()\n",
    "print(pred_asr)\n",
    "\n",
    "# Task 3: Grapheme-to-Phoneme (G2P) - needs ASR transcript as prompt\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Grapheme-to-Phoneme (G2P):\")\n",
    "print(\"=\" * 50)\n",
    "s2t_g2p = Speech2Text.from_pretrained(\n",
    "    \"espnet/powsm\",\n",
    "    device=\"cpu\",\n",
    "    lang_sym=\"<eng>\",\n",
    "    task_sym=\"<g2p>\",\n",
    ")\n",
    "# Use ASR transcript as prompt\n",
    "pred_g2p = s2t_g2p(speech, text_prev=pred_asr)[0][0]\n",
    "if \"<notimestamps>\" in pred_g2p:\n",
    "    pred_g2p = pred_g2p.split(\"<notimestamps>\")[1].strip()\n",
    "pred_g2p = pred_g2p.replace(\"/\", \"\")  # Remove slashes for G2P\n",
    "print(pred_g2p)\n",
    "\n",
    "# Task 4: Phoneme-to-Grapheme (P2G) - needs phone transcription with slashes as prompt\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Phoneme-to-Grapheme (P2G):\")\n",
    "print(\"=\" * 50)\n",
    "s2t_p2g = Speech2Text.from_pretrained(\n",
    "    \"espnet/powsm\",\n",
    "    device=\"cpu\",\n",
    "    lang_sym=\"<eng>\",\n",
    "    task_sym=\"<p2g>\",\n",
    ")\n",
    "# Use phone transcription with slashes as prompt (from PR result)\n",
    "# Format: /pʰ//ɔ//s//ə//m/ (each phone enclosed in slashes)\n",
    "phone_with_slashes = \" \".join([f\"/{p}/\" for p in pred_pr.split() if p.strip()])\n",
    "pred_p2g = s2t_p2g(speech, text_prev=phone_with_slashes)[0][0]\n",
    "if \"<notimestamps>\" in pred_p2g:\n",
    "    pred_p2g = pred_p2g.split(\"<notimestamps>\")[1].strip()\n",
    "print(pred_p2g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745272d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Check audio properties and try a simple PR example\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# Check the audio file\n",
    "speech, rate = sf.read(\"./audio/pi_powsm.wav\")\n",
    "print(f\"Audio properties:\")\n",
    "print(f\"  Sample rate: {rate} Hz\")\n",
    "print(f\"  Duration: {len(speech)/rate:.2f} seconds\")\n",
    "print(f\"  Samples: {len(speech)}\")\n",
    "print(f\"  Data type: {speech.dtype}\")\n",
    "print(f\"  Min/Max values: {speech.min():.4f} / {speech.max():.4f}\")\n",
    "print(f\"  RMS (loudness): {np.sqrt(np.mean(speech**2)):.4f}\")\n",
    "\n",
    "# Note: If the audio is not actual speech (e.g., music, tones, digits read aloud),\n",
    "# the model may produce garbled output. POWSM is designed for natural speech.\n",
    "# The special character ⁇ indicates unknown tokens, which can happen when:\n",
    "# 1. The audio content doesn't match the training data distribution\n",
    "# 2. The audio quality is poor\n",
    "# 3. The language doesn't match the lang_sym setting\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
