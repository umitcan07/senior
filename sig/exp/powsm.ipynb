{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0e8956",
   "metadata": {},
   "source": [
    "## Convert audio files under ./powsm into .wav (16kHz 16bit mono 20sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c1e1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 sentence directory(ies) to process:\n",
      "\n",
      "üìù Sentence 12 transcript:\n",
      "   The weather is rather warm this Thursday. I think we should go to the theater together. Thank you for thinking about this thoroughly.\n",
      "\n",
      "   Processing umit12.m4a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/0bk8sm9136q_16hvc9hdhr6m0000gn/T/ipykernel_46927/3385434185.py:60: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(str(audio_file), sr=None, mono=False)\n",
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Saved umit12-r.wav (20.00s, 16000Hz, mono, 16-bit)\n",
      "   Processing yusuf12.m4a...\n",
      "   ‚úì Saved yusuf12-r.wav (20.00s, 16000Hz, mono, 16-bit)\n",
      "\n",
      "üìù Sentence 14 transcript:\n",
      "   The red car arrived early in the morning. The driver parked near the restaurant and ordered breakfast. The fresh bread was really delicious.\n",
      "\n",
      "   Processing umit14.m4a...\n",
      "   ‚úì Saved umit14-r.wav (20.00s, 16000Hz, mono, 16-bit)\n",
      "\n",
      "Conversion complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/0bk8sm9136q_16hvc9hdhr6m0000gn/T/ipykernel_46927/3385434185.py:60: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(str(audio_file), sr=None, mono=False)\n",
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "base_dir = \"./audio/powsm\"\n",
    "target_sr = 16000  # 16kHz\n",
    "target_duration = 20  # 20 seconds\n",
    "target_channels = 1  # Mono\n",
    "\n",
    "# Supported audio extensions\n",
    "audio_extensions = {'.m4a', '.mp3', '.wav', '.flac', '.ogg', '.aac', '.mp4', '.m4v'}\n",
    "\n",
    "# Find all numbered subdirectories (sentence directories)\n",
    "base_path = Path(base_dir)\n",
    "sentence_dirs = [d for d in base_path.iterdir() if d.is_dir() and d.name.isdigit()]\n",
    "sentence_dirs.sort(key=lambda x: int(x.name))\n",
    "\n",
    "if not sentence_dirs:\n",
    "    print(f\"No sentence directories found in {base_dir}\")\n",
    "else:\n",
    "    print(f\"Found {len(sentence_dirs)} sentence directory(ies) to process:\\n\")\n",
    "\n",
    "for sentence_dir in sentence_dirs:\n",
    "    sentence_num = sentence_dir.name\n",
    "    text_file = sentence_dir / \"text\"\n",
    "    \n",
    "    # Read transcript\n",
    "    transcript = \"\"\n",
    "    if text_file.exists():\n",
    "        with open(text_file, 'r', encoding='utf-8') as f:\n",
    "            transcript = f.read().strip()\n",
    "        print(f\"üìù Sentence {sentence_num} transcript:\")\n",
    "        print(f\"   {transcript}\\n\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Sentence {sentence_num}: No transcript file found\\n\")\n",
    "    \n",
    "    # Find all audio files in this directory (excluding already converted -r.wav files)\n",
    "    audio_files = [\n",
    "        f for f in sentence_dir.iterdir() \n",
    "        if f.suffix.lower() in audio_extensions \n",
    "        and f.is_file()\n",
    "        and not f.name.endswith('-r.wav')  # Skip already converted files\n",
    "    ]\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(f\"   No audio files to convert in sentence {sentence_num}\\n\")\n",
    "        continue\n",
    "    \n",
    "    for audio_file in audio_files:\n",
    "        filename = audio_file.name\n",
    "        output_filename = audio_file.stem + \"-r.wav\"\n",
    "        output_path = sentence_dir / output_filename\n",
    "        \n",
    "        print(f\"   Processing {filename}...\")\n",
    "        \n",
    "        # Load audio file\n",
    "        audio, sr = librosa.load(str(audio_file), sr=None, mono=False)\n",
    "        \n",
    "        # Convert to mono if stereo\n",
    "        if len(audio.shape) > 1:\n",
    "            audio = librosa.to_mono(audio)\n",
    "        \n",
    "        # Resample to 16kHz\n",
    "        if sr != target_sr:\n",
    "            audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "        \n",
    "        # Trim or pad to 20 seconds\n",
    "        target_samples = target_sr * target_duration\n",
    "        if len(audio) > target_samples:\n",
    "            # Trim to 20 seconds\n",
    "            audio = audio[:target_samples]\n",
    "        elif len(audio) < target_samples:\n",
    "            # Pad with zeros to 20 seconds\n",
    "            padding = target_samples - len(audio)\n",
    "            audio = np.pad(audio, (0, padding), mode='constant')\n",
    "        \n",
    "        # Save as 16-bit WAV file\n",
    "        sf.write(str(output_path), audio, target_sr, subtype='PCM_16')\n",
    "        \n",
    "        print(f\"   ‚úì Saved {output_filename} ({len(audio)/target_sr:.2f}s, {target_sr}Hz, mono, 16-bit)\")\n",
    "    \n",
    "    print()  # Empty line between sentences\n",
    "\n",
    "print(\"Conversion complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52f938",
   "metadata": {},
   "source": [
    "## Phone Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b747ee37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 sentence directory(ies) to process:\n",
      "\n",
      "Loading language detection model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 26522.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Phone Recognition model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 137840.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Sentence 12\n",
      "======================================================================\n",
      "üìù Transcript: The weather is rather warm this Thursday. I think we should go to the theater together. Thank you for thinking about this thoroughly.\n",
      "\n",
      "\n",
      "üé§ Processing: umit12-r.wav\n",
      "   Audio: 20.00s at 16000Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/espnet2/s2t/espnet_model.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Detected language: <eng>\n",
      "\n",
      "   üìû Phone Recognition Result:\n",
      "   √∞…ôw…õ√∞…úÀû…™z…π…ô√∞…úÀûw…î…πmd√∞…™sŒ∏…úÀûnzde…™a…™Œ∏…™ÃÉ≈ãkwi É ädko ät ∞u√∞…ôŒ∏i…ôt…úÀût ∞…ô…°…õ√∞…úÀûŒ∏√¶ÃÉ≈ãkjuf…π…úÀûŒ∏…™ÃÉ≈ãk…™ÃÉ≈ã…ôba ät√∞…™st…î…πo älÃ¥i\n",
      "\n",
      "üé§ Processing: yusuf12-r.wav\n",
      "   Audio: 20.00s at 16000Hz\n",
      "   Detected language: <eng>\n",
      "\n",
      "   üìû Phone Recognition Result:\n",
      "   √∞…ôw…õ√∞…úÀû…™z…π…ô√∞…úÀûw…î…πm√∞…™sŒ∏…úÀûdzde…™a…™Œ∏…™ÃÉ≈ãkwi Éik ∞…îz…™tŒ∏i…ôt…úÀût ∞…ô…°…õ√∞…úÀûŒ∏√¶ÃÉ≈ãkjuf…π…úÀûŒ∏…™ÃÉ≈ãk…™ÃÉ≈ã…ôba ät…™z…ôŒ∏…î…πo älÃ¥i\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Sentence 14\n",
      "======================================================================\n",
      "üìù Transcript: The red car arrived early in the morning. The driver parked near the restaurant and ordered breakfast. The fresh bread was really delicious.\n",
      "\n",
      "\n",
      "üé§ Processing: umit14-r.wav\n",
      "   Audio: 20.00s at 16000Hz\n",
      "   Detected language: <eng>\n",
      "\n",
      "   üìû Phone Recognition Result:\n",
      "   √∞…ô…π…õdk ∞…ë…π…úÀûa…™vd…úÀûlÃ¥i…™ÃÉn√∞…ôm…î…πn…™ÃÉ≈ã√∞…ôt ∞…πa…™v…úÀûp ∞…ë…πkn…™…π√∞…ô…π…õst…úÀû…ëÃÉnt…ônd…î…πd…úÀûdp…π…õkf…ôstt ∞uf…π…õ Ép…π…õdw…ëz…πilÃ¥it…™lÃ¥…™ É…ôs\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Writing results to files...\n",
      "‚úì JSON results saved to: ./powsm_pr_results.json\n",
      "‚úì Text results saved to: ./powsm_pr_results.txt\n",
      "\n",
      "======================================================================\n",
      "Phone Recognition complete!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from espnet2.bin.s2t_inference import Speech2Text\n",
    "from espnet2.bin.s2t_inference_language import Speech2Language\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "base_dir = \"./audio/powsm\"\n",
    "device = \"cpu\"  # Change to \"cuda\" if you have GPU\n",
    "output_file_json = \"./powsm_pr_results.json\"\n",
    "output_file_txt = \"./powsm_pr_results.txt\"\n",
    "\n",
    "# Initialize results storage\n",
    "results = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"model\": \"espnet/powsm\",\n",
    "    \"task\": \"Phone Recognition (PR)\",\n",
    "    \"results\": []\n",
    "}\n",
    "\n",
    "# Find all numbered subdirectories (sentence directories)\n",
    "base_path = Path(base_dir)\n",
    "sentence_dirs = [d for d in base_path.iterdir() if d.is_dir() and d.name.isdigit()]\n",
    "sentence_dirs.sort(key=lambda x: int(x.name))\n",
    "\n",
    "if not sentence_dirs:\n",
    "    print(f\"No sentence directories found in {base_dir}\")\n",
    "else:\n",
    "    print(f\"Found {len(sentence_dirs)} sentence directory(ies) to process:\\n\")\n",
    "    \n",
    "    # Initialize language detection model (for automatic language detection)\n",
    "    print(\"Loading language detection model...\")\n",
    "    s2lang = Speech2Language.from_pretrained(\n",
    "        \"espnet/powsm\",\n",
    "        device=device,\n",
    "        nbest=1,\n",
    "        first_lang_sym=\"<afr>\",\n",
    "        last_lang_sym=\"<zul>\"\n",
    "    )\n",
    "    \n",
    "    # Initialize PR model\n",
    "    print(\"Loading Phone Recognition model...\")\n",
    "    s2t_pr = Speech2Text.from_pretrained(\n",
    "        \"espnet/powsm\",\n",
    "        device=device,\n",
    "        lang_sym=\"<eng>\",  # Default to English, can be changed per file\n",
    "        task_sym=\"<pr>\",\n",
    "    )\n",
    "    \n",
    "    for sentence_dir in sentence_dirs:\n",
    "        sentence_num = sentence_dir.name\n",
    "        text_file = sentence_dir / \"text\"\n",
    "        \n",
    "        # Read transcript\n",
    "        transcript = \"\"\n",
    "        if text_file.exists():\n",
    "            with open(text_file, 'r', encoding='utf-8') as f:\n",
    "                transcript = f.read().strip()\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Sentence {sentence_num}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        if transcript:\n",
    "            print(f\"üìù Transcript: {transcript}\\n\")\n",
    "        \n",
    "        # Find all converted audio files (-r.wav)\n",
    "        audio_files = [\n",
    "            f for f in sentence_dir.iterdir() \n",
    "            if f.is_file() and f.name.endswith('-r.wav')\n",
    "        ]\n",
    "        \n",
    "        if not audio_files:\n",
    "            print(f\"   No converted audio files found in sentence {sentence_num}\\n\")\n",
    "            continue\n",
    "        \n",
    "        for audio_file in audio_files:\n",
    "            filename = audio_file.name\n",
    "            print(f\"\\nüé§ Processing: {filename}\")\n",
    "            \n",
    "            # Load audio\n",
    "            speech, rate = sf.read(str(audio_file))\n",
    "            print(f\"   Audio: {len(speech)/rate:.2f}s at {rate}Hz\")\n",
    "            \n",
    "            # Detect language (optional - can help with accuracy)\n",
    "            try:\n",
    "                lang_pred = s2lang(speech)[0]\n",
    "                detected_lang = lang_pred[0] if lang_pred else \"<eng>\"\n",
    "                print(f\"   Detected language: {detected_lang}\")\n",
    "            except:\n",
    "                detected_lang = \"<eng>\"\n",
    "                print(f\"   Using default language: {detected_lang}\")\n",
    "            \n",
    "            # Phone Recognition\n",
    "            try:\n",
    "                result = s2t_pr(speech, text_prev=\"<na>\")\n",
    "                pred = result[0][0]\n",
    "                \n",
    "                # Post-processing\n",
    "                if \"<notimestamps>\" in pred:\n",
    "                    pred = pred.split(\"<notimestamps>\")[1].strip()\n",
    "                else:\n",
    "                    pred = pred.strip()\n",
    "                \n",
    "                # Remove slashes for cleaner output\n",
    "                pred_clean = pred.replace(\"/\", \"\")\n",
    "                \n",
    "                print(f\"\\n   üìû Phone Recognition Result:\")\n",
    "                print(f\"   {pred_clean}\")\n",
    "                \n",
    "                # Store result\n",
    "                result_entry = {\n",
    "                    \"sentence_id\": sentence_num,\n",
    "                    \"audio_file\": filename,\n",
    "                    \"transcript\": transcript,\n",
    "                    \"detected_language\": detected_lang,\n",
    "                    \"phone_recognition\": {\n",
    "                        \"with_slashes\": pred,\n",
    "                        \"clean\": pred_clean\n",
    "                    }\n",
    "                }\n",
    "                results[\"results\"].append(result_entry)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error during PR: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                \n",
    "                # Store error\n",
    "                result_entry = {\n",
    "                    \"sentence_id\": sentence_num,\n",
    "                    \"audio_file\": filename,\n",
    "                    \"transcript\": transcript,\n",
    "                    \"detected_language\": detected_lang,\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "                results[\"results\"].append(result_entry)\n",
    "        \n",
    "        print()  # Empty line between sentences\n",
    "\n",
    "# Write results to files\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Writing results to files...\")\n",
    "\n",
    "# Write JSON file\n",
    "with open(output_file_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "print(f\"‚úì JSON results saved to: {output_file_json}\")\n",
    "\n",
    "# Write human-readable text file\n",
    "with open(output_file_txt, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"POWSM Phone Recognition Results\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(f\"Timestamp: {results['timestamp']}\\n\")\n",
    "    f.write(f\"Model: {results['model']}\\n\")\n",
    "    f.write(f\"Task: {results['task']}\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    \n",
    "    for entry in results[\"results\"]:\n",
    "        f.write(f\"\\nSentence ID: {entry['sentence_id']}\\n\")\n",
    "        f.write(f\"Audio File: {entry['audio_file']}\\n\")\n",
    "        f.write(f\"Transcript: {entry.get('transcript', 'N/A')}\\n\")\n",
    "        f.write(f\"Detected Language: {entry.get('detected_language', 'N/A')}\\n\")\n",
    "        \n",
    "        if 'error' in entry:\n",
    "            f.write(f\"Error: {entry['error']}\\n\")\n",
    "        else:\n",
    "            f.write(f\"Phone Recognition (clean): {entry['phone_recognition']['clean']}\\n\")\n",
    "            f.write(f\"Phone Recognition (with slashes): {entry['phone_recognition']['with_slashes']}\\n\")\n",
    "        \n",
    "        f.write(\"-\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"‚úì Text results saved to: {output_file_txt}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Phone Recognition complete!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1768e22",
   "metadata": {},
   "source": [
    "## Audio Guided Grapheme to Phoneme Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fcc8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 sentence directory(ies) to process:\n",
      "\n",
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 109552.72it/s]\n",
      "Fetching 7 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 118387.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Sentence 12\n",
      "======================================================================\n",
      "üìù Ground Truth Transcript: The weather is rather warm this Thursday. I think we should go to the theater together. Thank you for thinking about this thoroughly.\n",
      "\n",
      "\n",
      "üé§ Processing: umit12-r.wav\n",
      "   Audio: 20.00s at 16000Hz\n",
      "\n",
      "   Step 1: Getting ASR transcript...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/espnet2/s2t/espnet_model.py:338: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìù ASR Result: the weather is rather warm this turnsday  ‚Åá  think we should go to the theatre together think you for thinking about this toroli\n",
      "\n",
      "   Step 2: Audio-guided Grapheme-to-Phoneme conversion...\n",
      "\n",
      "   üî§ G2P Result (phones):\n",
      "   √∞…ôw…õ√∞…úÀû…™z…π…ô√∞…úÀûw…î…πm√∞…™st ∞…úÀûnzde…™a…™Œ∏…™ÃÉ≈ãkwi É ädko ät ∞u√∞…ôŒ∏i…ôt…úÀût ∞…ô…°…õ√∞…úÀûŒ∏…™ÃÉ≈ãkjuf…π…úÀûŒ∏…™ÃÉ≈ãk…™ÃÉ≈ã…ôba ät√∞…™st ∞…î…πo älÃ¥i\n",
      "\n",
      "   üî§ G2P Result (with slashes):\n",
      "   /√∞//…ô//w//…õ//√∞//…úÀû//…™//z//…π//…ô//√∞//…úÀû//w//…î//…π//m//√∞//…™//s//t ∞//…úÀû//n//z//d//e//…™//a//…™//Œ∏//…™ÃÉ//≈ã//k//w//i// É// ä//d//k//o// ä//t ∞//u//√∞//…ô//Œ∏//i//…ô//t//…úÀû//t ∞//…ô//…°//…õ//√∞//…úÀû//Œ∏//…™ÃÉ//≈ã//k//j//u//f//…π//…úÀû//Œ∏//…™ÃÉ//≈ã//k//…™ÃÉ//≈ã//…ô//b//a// ä//t//√∞//…™//s//t ∞//…î//…π//o// ä//lÃ¥//i/\n",
      "\n",
      "üé§ Processing: yusuf12-r.wav\n",
      "   Audio: 20.00s at 16000Hz\n",
      "\n",
      "   Step 1: Getting ASR transcript...\n",
      "   üìù ASR Result: the weather is rather warm this Thursday  ‚Åá  think we she cause it the theater together think you for thinking about is authority\n",
      "\n",
      "   Step 2: Audio-guided Grapheme-to-Phoneme conversion...\n",
      "\n",
      "   üî§ G2P Result (phones):\n",
      "   √∞…ôw…õ√∞…úÀû…™z…π…ô√∞…úÀûw…î…πm√∞…™sŒ∏…úÀûzde…™a…™Œ∏…™ÃÉ≈ãkwi Éik ∞…îz…™tŒ∏i…ôt…úÀût ∞…ô…°…õ√∞…úÀûŒ∏…™ÃÉ≈ãkjuf…π…úÀûŒ∏…™ÃÉ≈ãk…™ÃÉ≈ã…ôba ät…™z…ôŒ∏…î…π…ôti\n",
      "\n",
      "   üî§ G2P Result (with slashes):\n",
      "   /√∞//…ô//w//…õ//√∞//…úÀû//…™//z//…π//…ô//√∞//…úÀû//w//…î//…π//m//√∞//…™//s//Œ∏//…úÀû//z//d//e//…™//a//…™//Œ∏//…™ÃÉ//≈ã//k//w//i// É//i//k ∞//…î//z//…™//t//Œ∏//i//…ô//t//…úÀû//t ∞//…ô//…°//…õ//√∞//…úÀû//Œ∏//…™ÃÉ//≈ã//k//j//u//f//…π//…úÀû//Œ∏//…™ÃÉ//≈ã//k//…™ÃÉ//≈ã//…ô//b//a// ä//t//…™//z//…ô//Œ∏//…î//…π//…ô//t//i/\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Sentence 14\n",
      "======================================================================\n",
      "üìù Ground Truth Transcript: The red car arrived early in the morning. The driver parked near the restaurant and ordered breakfast. The fresh bread was really delicious.\n",
      "\n",
      "\n",
      "üé§ Processing: umit14-r.wav\n",
      "   Audio: 20.00s at 16000Hz\n",
      "\n",
      "   Step 1: Getting ASR transcript...\n",
      "   üìù ASR Result: the red car arrived early in the morning the driver park near the restaurant and ordered broadfast to fresh bred was really delicious\n",
      "\n",
      "   Step 2: Audio-guided Grapheme-to-Phoneme conversion...\n",
      "\n",
      "   üî§ G2P Result (phones):\n",
      "   √∞…ô…π…õdk ∞…ë…π…úÀûa…™vd…úÀûlÃ¥i…™ÃÉn√∞…ôm…î…πn…™ÃÉ≈ã√∞…ôt…πa…™v…úÀûp ∞…ë…πkn…™…π√∞…ô…π…õst…úÀû…ëÃÉnt…ônd…î…πd…úÀûdp…π…îdf√¶stt ∞uf…π…õ Ép…π…õdw…ëz…πilÃ¥it…™lÃ¥…™ É…ôs\n",
      "\n",
      "   üî§ G2P Result (with slashes):\n",
      "   /√∞//…ô//…π//…õ//d//k ∞//…ë//…π//…úÀû//a//…™//v//d//…úÀû//lÃ¥//i//…™ÃÉ//n//√∞//…ô//m//…î//…π//n//…™ÃÉ//≈ã//√∞//…ô//t//…π//a//…™//v//…úÀû//p ∞//…ë//…π//k//n//…™//…π//√∞//…ô//…π//…õ//s//t//…úÀû//…ëÃÉ//n//t//…ô//n//d//…î//…π//d//…úÀû//d//p//…π//…î//d//f//√¶//s//t//t ∞//u//f//…π//…õ// É//p//…π//…õ//d//w//…ë//z//…π//i//lÃ¥//i//t//…™//lÃ¥//…™// É//…ô//s/\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Writing results to files...\n",
      "‚úì JSON results saved to: ./powsm_g2p_results.json\n",
      "‚úì Text results saved to: ./powsm_g2p_results.txt\n",
      "\n",
      "======================================================================\n",
      "Audio-guided Grapheme-to-Phoneme conversion complete!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from espnet2.bin.s2t_inference import Speech2Text\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "base_dir = \"./audio/powsm\"\n",
    "device = \"cpu\"  # Change to \"cuda\" if you have GPU\n",
    "output_file_json = \"./powsm_g2p_results.json\"\n",
    "output_file_txt = \"./powsm_g2p_results.txt\"\n",
    "\n",
    "# Initialize results storage\n",
    "results = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"model\": \"espnet/powsm\",\n",
    "    \"task\": \"Audio-guided Grapheme-to-Phoneme (G2P)\",\n",
    "    \"results\": []\n",
    "}\n",
    "\n",
    "# Find all numbered subdirectories (sentence directories)\n",
    "base_path = Path(base_dir)\n",
    "sentence_dirs = [d for d in base_path.iterdir() if d.is_dir() and d.name.isdigit()]\n",
    "sentence_dirs.sort(key=lambda x: int(x.name))\n",
    "\n",
    "if not sentence_dirs:\n",
    "    print(f\"No sentence directories found in {base_dir}\")\n",
    "else:\n",
    "    print(f\"Found {len(sentence_dirs)} sentence directory(ies) to process:\\n\")\n",
    "    \n",
    "    # Initialize models\n",
    "    print(\"Loading models...\")\n",
    "    \n",
    "    # ASR model (needed to get transcript for G2P)\n",
    "    s2t_asr = Speech2Text.from_pretrained(\n",
    "        \"espnet/powsm\",\n",
    "        device=device,\n",
    "        lang_sym=\"<eng>\",\n",
    "        task_sym=\"<asr>\",\n",
    "    )\n",
    "    \n",
    "    # G2P model\n",
    "    s2t_g2p = Speech2Text.from_pretrained(\n",
    "        \"espnet/powsm\",\n",
    "        device=device,\n",
    "        lang_sym=\"<eng>\",\n",
    "        task_sym=\"<g2p>\",\n",
    "    )\n",
    "    \n",
    "    for sentence_dir in sentence_dirs:\n",
    "        sentence_num = sentence_dir.name\n",
    "        text_file = sentence_dir / \"text\"\n",
    "        \n",
    "        # Read transcript\n",
    "        transcript = \"\"\n",
    "        if text_file.exists():\n",
    "            with open(text_file, 'r', encoding='utf-8') as f:\n",
    "                transcript = f.read().strip()\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Sentence {sentence_num}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        if transcript:\n",
    "            print(f\"üìù Ground Truth Transcript: {transcript}\\n\")\n",
    "        \n",
    "        # Find all converted audio files (-r.wav)\n",
    "        audio_files = [\n",
    "            f for f in sentence_dir.iterdir() \n",
    "            if f.is_file() and f.name.endswith('-r.wav')\n",
    "        ]\n",
    "        \n",
    "        if not audio_files:\n",
    "            print(f\"   No converted audio files found in sentence {sentence_num}\\n\")\n",
    "            continue\n",
    "        \n",
    "        for audio_file in audio_files:\n",
    "            filename = audio_file.name\n",
    "            print(f\"\\nüé§ Processing: {filename}\")\n",
    "            \n",
    "            # Load audio\n",
    "            speech, rate = sf.read(str(audio_file))\n",
    "            print(f\"   Audio: {len(speech)/rate:.2f}s at {rate}Hz\")\n",
    "            \n",
    "            # Step 1: Get ASR transcript (needed as prompt for G2P)\n",
    "            try:\n",
    "                print(f\"\\n   Step 1: Getting ASR transcript...\")\n",
    "                result_asr = s2t_asr(speech, text_prev=\"<na>\")\n",
    "                pred_asr = result_asr[0][0]\n",
    "                \n",
    "                # Post-process ASR\n",
    "                if \"<notimestamps>\" in pred_asr:\n",
    "                    pred_asr = pred_asr.split(\"<notimestamps>\")[1].strip()\n",
    "                else:\n",
    "                    pred_asr = pred_asr.strip()\n",
    "                \n",
    "                print(f\"   üìù ASR Result: {pred_asr}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error during ASR: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "            \n",
    "            # Step 2: Audio-guided G2P (uses both speech and text prompt)\n",
    "            try:\n",
    "                print(f\"\\n   Step 2: Audio-guided Grapheme-to-Phoneme conversion...\")\n",
    "                result_g2p = s2t_g2p(speech, text_prev=pred_asr)\n",
    "                pred_g2p = result_g2p[0][0]\n",
    "                \n",
    "                # Post-processing\n",
    "                if \"<notimestamps>\" in pred_g2p:\n",
    "                    pred_g2p = pred_g2p.split(\"<notimestamps>\")[1].strip()\n",
    "                else:\n",
    "                    pred_g2p = pred_g2p.strip()\n",
    "                \n",
    "                # Remove slashes for cleaner output\n",
    "                pred_g2p_clean = pred_g2p.replace(\"/\", \"\")\n",
    "                \n",
    "                print(f\"\\n   üî§ G2P Result (phones):\")\n",
    "                print(f\"   {pred_g2p_clean}\")\n",
    "                \n",
    "                # Also show with slashes for reference\n",
    "                print(f\"\\n   üî§ G2P Result (with slashes):\")\n",
    "                print(f\"   {pred_g2p}\")\n",
    "                \n",
    "                # Store result\n",
    "                result_entry = {\n",
    "                    \"sentence_id\": sentence_num,\n",
    "                    \"audio_file\": filename,\n",
    "                    \"ground_truth_transcript\": transcript,\n",
    "                    \"asr_transcript\": pred_asr,\n",
    "                    \"g2p_result\": {\n",
    "                        \"with_slashes\": pred_g2p,\n",
    "                        \"clean\": pred_g2p_clean\n",
    "                    }\n",
    "                }\n",
    "                results[\"results\"].append(result_entry)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error during G2P: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                \n",
    "                # Store error\n",
    "                result_entry = {\n",
    "                    \"sentence_id\": sentence_num,\n",
    "                    \"audio_file\": filename,\n",
    "                    \"ground_truth_transcript\": transcript,\n",
    "                    \"asr_transcript\": pred_asr if 'pred_asr' in locals() else \"N/A\",\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "                results[\"results\"].append(result_entry)\n",
    "        \n",
    "        print()  # Empty line between sentences\n",
    "\n",
    "# Write results to files\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Writing results to files...\")\n",
    "\n",
    "# Write JSON file\n",
    "with open(output_file_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "print(f\"‚úì JSON results saved to: {output_file_json}\")\n",
    "\n",
    "# Write human-readable text file\n",
    "with open(output_file_txt, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"POWSM Audio-guided Grapheme-to-Phoneme (G2P) Results\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(f\"Timestamp: {results['timestamp']}\\n\")\n",
    "    f.write(f\"Model: {results['model']}\\n\")\n",
    "    f.write(f\"Task: {results['task']}\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    \n",
    "    for entry in results[\"results\"]:\n",
    "        f.write(f\"\\nSentence ID: {entry['sentence_id']}\\n\")\n",
    "        f.write(f\"Audio File: {entry['audio_file']}\\n\")\n",
    "        f.write(f\"Ground Truth Transcript: {entry.get('ground_truth_transcript', 'N/A')}\\n\")\n",
    "        f.write(f\"ASR Transcript: {entry.get('asr_transcript', 'N/A')}\\n\")\n",
    "        \n",
    "        if 'error' in entry:\n",
    "            f.write(f\"Error: {entry['error']}\\n\")\n",
    "        else:\n",
    "            f.write(f\"G2P Result (clean): {entry['g2p_result']['clean']}\\n\")\n",
    "            f.write(f\"G2P Result (with slashes): {entry['g2p_result']['with_slashes']}\\n\")\n",
    "        \n",
    "        f.write(\"-\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"‚úì Text results saved to: {output_file_txt}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Audio-guided Grapheme-to-Phoneme conversion complete!\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
