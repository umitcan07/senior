{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to import Flash Attention, using ESPnet default: No module named 'flash_attn'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/umitcanevleksiz/Documents/Programming/senior/sig/exp/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking for MFA availability...\n",
            "======================================================================\n",
            "MFA Setup: Hybrid Conda/Venv Configuration\n",
            "======================================================================\n",
            "This notebook runs in a Python venv but uses MFA from a conda environment.\n",
            "MFA requires Kaldi, kalpy, and OpenFST which are conda-only packages.\n",
            "======================================================================\n",
            "\n",
            "âœ“ Found conda MFA at: /Users/umitcanevleksiz/miniconda3/envs/aligner/bin/mfa\n",
            "  Conda environment: /Users/umitcanevleksiz/miniconda3/envs/aligner\n",
            "  âœ“ Dependencies check passed (OpenFST, Kaldi found)\n",
            "\n",
            "âœ“ MFA is available and ready to use!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import json\n",
        "import shutil\n",
        "from typing import Dict, List\n",
        "\n",
        "# Add mod directory to path for imports\n",
        "mod_path = Path(\"../../mod\")\n",
        "sys.path.insert(0, str(mod_path.absolute()))\n",
        "\n",
        "# POWSM imports\n",
        "from espnet2.bin.s2t_inference import Speech2Text\n",
        "from espnet2.bin.s2t_inference_language import Speech2Language\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# MFA availability check\n",
        "# MFA requires Kaldi/kalpy which are conda packages\n",
        "# We need to find the conda MFA, not the venv one (which lacks kalpy)\n",
        "import subprocess\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "MFA_AVAILABLE = False\n",
        "MFA_CMD = None\n",
        "\n",
        "def find_conda_mfa():\n",
        "    \"\"\"Try to find MFA in conda environments.\"\"\"\n",
        "    # Common conda installation paths\n",
        "    conda_bases = [\n",
        "        os.path.expanduser(\"~/miniconda3\"),\n",
        "        os.path.expanduser(\"~/anaconda3\"),\n",
        "        os.path.expanduser(\"~/opt/anaconda3\"),\n",
        "        os.path.expanduser(\"~/conda\"),\n",
        "        \"/opt/anaconda3\",\n",
        "        \"/opt/miniconda3\",\n",
        "        \"/usr/local/anaconda3\",\n",
        "        \"/usr/local/miniconda3\",\n",
        "    ]\n",
        "    \n",
        "    # Check CONDA_PREFIX environment variable (current conda env)\n",
        "    if \"CONDA_PREFIX\" in os.environ:\n",
        "        conda_bases.insert(0, os.environ[\"CONDA_PREFIX\"])\n",
        "    \n",
        "    # Check CONDA_DEFAULT_ENV to see if we're in a conda env\n",
        "    if \"CONDA_DEFAULT_ENV\" in os.environ:\n",
        "        env_name = os.environ[\"CONDA_DEFAULT_ENV\"]\n",
        "        if \"CONDA_PREFIX\" in os.environ:\n",
        "            mfa_path = os.path.join(os.environ[\"CONDA_PREFIX\"], \"bin\", \"mfa\")\n",
        "            if os.path.exists(mfa_path):\n",
        "                return mfa_path, os.environ[\"CONDA_PREFIX\"]\n",
        "    \n",
        "    # Check common environment names\n",
        "    env_names = [\"aligner\", \"mfa\", \"pronunciation\", \"base\"]\n",
        "    \n",
        "    for conda_base in conda_bases:\n",
        "        if os.path.exists(conda_base):\n",
        "            # Check if it's a conda base or envs directory\n",
        "            envs_dir = os.path.join(conda_base, \"envs\")\n",
        "            if os.path.exists(envs_dir):\n",
        "                # It's a conda base, check envs\n",
        "                for env_name in env_names:\n",
        "                    env_path = os.path.join(envs_dir, env_name)\n",
        "                    mfa_path = os.path.join(env_path, \"bin\", \"mfa\")\n",
        "                    if os.path.exists(mfa_path):\n",
        "                        return mfa_path, env_path\n",
        "            else:\n",
        "                # Might be a direct environment\n",
        "                mfa_path = os.path.join(conda_base, \"bin\", \"mfa\")\n",
        "                if os.path.exists(mfa_path):\n",
        "                    return mfa_path, conda_base\n",
        "    \n",
        "    return None, None\n",
        "\n",
        "def check_mfa_dependencies(conda_env_path):\n",
        "    \"\"\"Check if MFA dependencies (openfst, kaldi, kalpy) are available.\"\"\"\n",
        "    if not conda_env_path:\n",
        "        return False, []\n",
        "    \n",
        "    bin_dir = os.path.join(conda_env_path, \"bin\")\n",
        "    missing = []\n",
        "    \n",
        "    # Check for fstcompile (OpenFST)\n",
        "    fstcompile = os.path.join(bin_dir, \"fstcompile\")\n",
        "    if not os.path.exists(fstcompile):\n",
        "        missing.append(\"openfst (fstcompile)\")\n",
        "    \n",
        "    # Check for kaldi binaries (at least one)\n",
        "    kaldi_bins = [\"gmm-align-compiled\", \"gmm-latgen-faster\", \"fstcompile\"]\n",
        "    has_kaldi = any(os.path.exists(os.path.join(bin_dir, bin_name)) for bin_name in kaldi_bins)\n",
        "    if not has_kaldi:\n",
        "        missing.append(\"kaldi\")\n",
        "    \n",
        "    # Check for kalpy (Python module - harder to check, but we'll try)\n",
        "    # We can't easily check Python modules from here, but we'll catch it at runtime\n",
        "    \n",
        "    return len(missing) == 0, missing\n",
        "\n",
        "# Strategy: Try conda MFA first, then check PATH\n",
        "print(\"Checking for MFA availability...\")\n",
        "print(\"=\"*70)\n",
        "print(\"MFA Setup: Hybrid Conda/Venv Configuration\")\n",
        "print(\"=\"*70)\n",
        "print(\"This notebook runs in a Python venv but uses MFA from a conda environment.\")\n",
        "print(\"MFA requires Kaldi, kalpy, and OpenFST which are conda-only packages.\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# First, try to find conda MFA\n",
        "conda_mfa, conda_env_path = find_conda_mfa()\n",
        "if conda_mfa:\n",
        "    print(f\"\\nâœ“ Found conda MFA at: {conda_mfa}\")\n",
        "    if conda_env_path:\n",
        "        print(f\"  Conda environment: {conda_env_path}\")\n",
        "    \n",
        "    # Check for required dependencies\n",
        "    deps_ok, missing_deps = check_mfa_dependencies(conda_env_path)\n",
        "    if not deps_ok:\n",
        "        print(f\"\\nâš ï¸  Missing MFA dependencies: {', '.join(missing_deps)}\")\n",
        "        print(\"\\nTo fix, run in your terminal:\")\n",
        "        print(f\"  conda activate {os.path.basename(conda_env_path) if conda_env_path else 'aligner'}\")\n",
        "        print(\"  conda install -c conda-forge openfst kaldi kalpy\")\n",
        "        print(\"\\nOr reinstall MFA with all dependencies:\")\n",
        "        print(\"  conda install -c conda-forge montreal-forced-aligner --force-reinstall\")\n",
        "    else:\n",
        "        print(\"  âœ“ Dependencies check passed (OpenFST, Kaldi found)\")\n",
        "    \n",
        "    MFA_CMD = conda_mfa\n",
        "    \n",
        "    # Test if MFA works - check if it's executable and doesn't have kalpy errors\n",
        "    mfa_works = False\n",
        "    \n",
        "    # Simple test: try any MFA command and check for errors\n",
        "    test_commands = [\n",
        "        [\"--help\"],\n",
        "        [\"version\"],\n",
        "    ]\n",
        "    \n",
        "    for test_cmd in test_commands:\n",
        "        try:\n",
        "            # Use conda run to ensure proper environment\n",
        "            if conda_env_path:\n",
        "                # Try using conda run to execute in the right environment\n",
        "                env_name = os.path.basename(conda_env_path)\n",
        "                result = subprocess.run(\n",
        "                    [\"conda\", \"run\", \"-n\", env_name, \"mfa\"] + test_cmd,\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=5,\n",
        "                    env=os.environ.copy()\n",
        "                )\n",
        "            else:\n",
        "                result = subprocess.run(\n",
        "                    [conda_mfa] + test_cmd,\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=5,\n",
        "                    env=os.environ.copy()\n",
        "                )\n",
        "            \n",
        "            # Check for common errors\n",
        "            error_output = (result.stderr + result.stdout).lower()\n",
        "            \n",
        "            # Check for kalpy error\n",
        "            if \"kalpy\" in error_output or \"_kalpy\" in error_output or \"no module named '_kalpy'\" in error_output:\n",
        "                print(f\"\\nâš ï¸  MFA found but missing kalpy (Kaldi Python bindings)\")\n",
        "                print(\"   Run: conda install -c conda-forge kalpy\")\n",
        "                break\n",
        "            \n",
        "            # Check for openfst/fstcompile error\n",
        "            if \"fstcompile\" in error_output or \"openfst\" in error_output or \"thirdparty\" in error_output:\n",
        "                print(f\"\\nâš ï¸  MFA found but missing OpenFST (fstcompile)\")\n",
        "                print(\"   Run: conda install -c conda-forge openfst\")\n",
        "                break\n",
        "            \n",
        "            # If we get here and no errors, MFA should work\n",
        "            if \"usage\" in error_output or \"command\" in error_output or result.returncode == 0:\n",
        "                mfa_works = True\n",
        "                if \"version\" in test_cmd and result.returncode == 0:\n",
        "                    version_info = (result.stdout + result.stderr).strip()\n",
        "                    if version_info:\n",
        "                        print(f\"\\nâœ“ MFA version: {version_info}\")\n",
        "                break\n",
        "        except FileNotFoundError:\n",
        "            # conda command not found - try direct execution\n",
        "            try:\n",
        "                result = subprocess.run(\n",
        "                    [conda_mfa] + test_cmd,\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=5,\n",
        "                    env=os.environ.copy()\n",
        "                )\n",
        "                error_output = (result.stderr + result.stdout).lower()\n",
        "                if \"kalpy\" not in error_output and \"fstcompile\" not in error_output:\n",
        "                    if \"usage\" in error_output or \"command\" in error_output or result.returncode == 0:\n",
        "                        mfa_works = True\n",
        "                        break\n",
        "            except:\n",
        "                pass\n",
        "        except Exception as e:\n",
        "            continue\n",
        "    \n",
        "    if mfa_works:\n",
        "        MFA_AVAILABLE = True\n",
        "        print(\"\\nâœ“ MFA is available and ready to use!\")\n",
        "        # Store conda env info for later use\n",
        "        if conda_env_path:\n",
        "            MFA_CONDA_ENV = os.path.basename(conda_env_path)\n",
        "            MFA_CONDA_ENV_PATH = conda_env_path  # Store full path for PATH manipulation\n",
        "        else:\n",
        "            MFA_CONDA_ENV = None\n",
        "            MFA_CONDA_ENV_PATH = None\n",
        "    else:\n",
        "        print(\"\\nâš ï¸  MFA found but may not work properly. Check dependencies above.\")\n",
        "        # Still store the path even if test failed, in case dependencies are installed later\n",
        "        if conda_env_path:\n",
        "            MFA_CONDA_ENV = os.path.basename(conda_env_path)\n",
        "            MFA_CONDA_ENV_PATH = conda_env_path\n",
        "        else:\n",
        "            MFA_CONDA_ENV = None\n",
        "            MFA_CONDA_ENV_PATH = None\n",
        "\n",
        "# If conda MFA not found or not working, check PATH\n",
        "if not MFA_AVAILABLE:\n",
        "    mfa_path = shutil.which(\"mfa\")\n",
        "    if mfa_path:\n",
        "        # Check if it's the venv one (which won't work)\n",
        "        if \".venv\" in mfa_path or \"venv\" in mfa_path:\n",
        "            print(f\"âš ï¸  Found MFA in venv ({mfa_path}), but it requires kalpy (conda-only)\")\n",
        "            print(\"   The venv MFA package is installed but cannot run without Kaldi/kalpy.\")\n",
        "            print(\"   \")\n",
        "            print(\"   To use MFA, you need to:\")\n",
        "            print(\"   1. Activate your conda environment: conda activate aligner\")\n",
        "            print(\"   2. Make sure conda's bin directory is in PATH\")\n",
        "            print(\"   3. Restart this notebook\")\n",
        "        else:\n",
        "            print(f\"âœ“ Found MFA command at: {mfa_path}\")\n",
        "            MFA_CMD = mfa_path\n",
        "            try:\n",
        "                result = subprocess.run(\n",
        "                    [\"mfa\", \"--version\"],\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=5\n",
        "                )\n",
        "                if result.returncode == 0:\n",
        "                    MFA_AVAILABLE = True\n",
        "                    print(f\"âœ“ MFA available: {result.stdout.strip()}\")\n",
        "                else:\n",
        "                    print(f\"âš ï¸  MFA command found but returned error\")\n",
        "                    print(f\"   Error: {result.stderr if result.stderr else 'Unknown error'}\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  Error running MFA: {e}\")\n",
        "\n",
        "if not MFA_AVAILABLE:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"âš ï¸  MFA not available or not working\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nMFA requires conda installation (Kaldi, kalpy, OpenFST are conda-only packages)\")\n",
        "    print(\"\\nðŸ“‹ Installation Instructions:\")\n",
        "    print(\"\\n1. Create conda environment with MFA:\")\n",
        "    print(\"   conda create -n aligner -c conda-forge montreal-forced-aligner\")\n",
        "    print(\"\\n2. Activate the environment:\")\n",
        "    print(\"   conda activate aligner\")\n",
        "    print(\"\\n3. Verify installation:\")\n",
        "    print(\"   mfa --version\")\n",
        "    print(\"   # Should show MFA version without errors\")\n",
        "    print(\"\\n4. Download required models:\")\n",
        "    print(\"   mfa model download dictionary english_us_mfa\")\n",
        "    print(\"   mfa model download acoustic english_mfa\")\n",
        "    print(\"\\n5. For Jupyter notebook:\")\n",
        "    print(\"   Option A: Install ipykernel in conda env and use it as kernel:\")\n",
        "    print(\"     conda activate aligner\")\n",
        "    print(\"     conda install ipykernel\")\n",
        "    print(\"     python -m ipykernel install --user --name aligner --display-name 'Python (aligner)'\")\n",
        "    print(\"     # Then select 'Python (aligner)' kernel in Jupyter\")\n",
        "    print(\"\\n   Option B: Keep using venv kernel, MFA will be called via subprocess\")\n",
        "    print(\"     (Current setup - should work if conda MFA is found)\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ðŸ“ Note: The notebook will still work without MFA, but timestamp alignment\")\n",
        "    print(\"   will use dummy/estimated timestamps instead of precise MFA alignments.\")\n",
        "    print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_powsm_phones(powsm_ipa: str) -> List[str]:\n",
        "    \"\"\"Parse IPA phonemes from POWSM format.\"\"\"\n",
        "    cleaned = powsm_ipa.strip().strip('/')\n",
        "    if not cleaned:\n",
        "        return []\n",
        "    phonemes = [p.strip('/') for p in cleaned.split('//') if p.strip('/')]\n",
        "    return phonemes\n",
        "\n",
        "\n",
        "def powsm_to_mfa_format(powsm_ipa: str) -> str:\n",
        "    \"\"\"Convert POWSM format to MFA space-separated format.\"\"\"\n",
        "    phones = parse_powsm_phones(powsm_ipa)\n",
        "    return ' '.join(phones)\n",
        "\n",
        "\n",
        "def mfa_to_powsm_format(mfa_ipa: str) -> str:\n",
        "    \"\"\"Convert MFA format to POWSM format.\"\"\"\n",
        "    if not mfa_ipa:\n",
        "        return \"\"\n",
        "    phones = mfa_ipa.strip().split()\n",
        "    return '//'.join(['/' + p + '/' for p in phones])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MFA utilities: validation and alignment helpers\n",
        "\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "\n",
        "def validate_mfa_alignment(alignments, audio_duration: float, expected_phone_count: Optional[int] = None):\n",
        "    \"\"\"Validate MFA alignment quality and return metrics.\n",
        "\n",
        "    Heuristics:\n",
        "    - Long phoneme durations (>0.5s) are suspicious\n",
        "    - Large gaps (>0.3s) between phonemes are suspicious\n",
        "    - Coverage vs. audio duration should be close\n",
        "    - Phoneme count compared to expected (if provided)\n",
        "    \"\"\"\n",
        "    metrics = {\n",
        "        \"quality_score\": 0.0,\n",
        "        \"warnings\": [],\n",
        "        \"counts\": {\n",
        "            \"phones\": len(alignments) if alignments else 0,\n",
        "            \"long_segments\": 0,\n",
        "            \"gap_segments\": 0,\n",
        "        },\n",
        "        \"coverage\": None,\n",
        "    }\n",
        "\n",
        "    if not alignments:\n",
        "        metrics[\"warnings\"].append(\"no_alignments\")\n",
        "        return metrics\n",
        "\n",
        "    durations = [max(0.0, a.get(\"end\", 0) - a.get(\"start\", 0)) for a in alignments]\n",
        "    total_duration = sum(durations)\n",
        "    long_threshold = 0.5\n",
        "    long_segments = [d for d in durations if d > long_threshold]\n",
        "    metrics[\"counts\"][\"long_segments\"] = len(long_segments)\n",
        "\n",
        "    # Gaps between consecutive segments\n",
        "    gaps = []\n",
        "    for prev, cur in zip(alignments, alignments[1:]):\n",
        "        gap = max(0.0, cur.get(\"start\", 0) - prev.get(\"end\", 0))\n",
        "        gaps.append(gap)\n",
        "    gap_threshold = 0.3\n",
        "    gap_segments = [g for g in gaps if g > gap_threshold]\n",
        "    metrics[\"counts\"][\"gap_segments\"] = len(gap_segments)\n",
        "\n",
        "    # Coverage relative to audio duration\n",
        "    if audio_duration and audio_duration > 0:\n",
        "        span = max(0.0, alignments[-1].get(\"end\", 0) - alignments[0].get(\"start\", 0))\n",
        "        metrics[\"coverage\"] = span / audio_duration if audio_duration else None\n",
        "    else:\n",
        "        span = 0.0\n",
        "\n",
        "    # Phoneme count comparison\n",
        "    count_penalty = 0.0\n",
        "    if expected_phone_count:\n",
        "        diff_ratio = abs(len(alignments) - expected_phone_count) / max(1, expected_phone_count)\n",
        "        if diff_ratio > 0.2:\n",
        "            metrics[\"warnings\"].append(f\"phone_count_mismatch_{diff_ratio:.2f}\")\n",
        "        count_penalty = min(0.4, diff_ratio)\n",
        "\n",
        "    # Scoring: start from 1.0 and subtract penalties\n",
        "    score = 1.0\n",
        "    if long_segments:\n",
        "        score -= min(0.6, (len(long_segments) / max(1, len(alignments))) * 0.8)\n",
        "        metrics[\"warnings\"].append(\"long_segments\")\n",
        "    if gap_segments:\n",
        "        score -= min(0.4, (len(gap_segments) / max(1, len(alignments))) * 0.6)\n",
        "        metrics[\"warnings\"].append(\"gappy_alignment\")\n",
        "    if metrics[\"coverage\"] is not None:\n",
        "        score -= min(0.4, abs(1.0 - metrics[\"coverage\"]))\n",
        "        if metrics[\"coverage\"] < 0.6 or metrics[\"coverage\"] > 1.2:\n",
        "            metrics[\"warnings\"].append(\"coverage_out_of_range\")\n",
        "    score -= count_penalty\n",
        "\n",
        "    metrics[\"quality_score\"] = max(0.0, min(1.0, score))\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def run_mfa_alignment(\n",
        "    audio_file: str,\n",
        "    transcription: str,\n",
        "    audio_basename: str,\n",
        "    temp_base: str,\n",
        "    mfa_command: str,\n",
        "    env: dict,\n",
        "    beam_sizes: Tuple[Tuple[int, int], ...],\n",
        "    audio_duration: float,\n",
        "    expected_phone_count: Optional[int] = None,\n",
        "    dictionary_id: str = \"english_us_mfa\",\n",
        "    acoustic_id: str = \"english_mfa\",\n",
        "    label: str = \"target\",\n",
        "):\n",
        "    \"\"\"Run MFA alignment for a given transcription and return alignments and diagnostics.\"\"\"\n",
        "    if not transcription:\n",
        "        return {\n",
        "            \"alignments\": [],\n",
        "            \"quality\": {\"quality_score\": 0.0, \"warnings\": [\"empty_transcription\"]},\n",
        "            \"stdout\": \"\",\n",
        "            \"stderr\": \"\",\n",
        "            \"returncode\": None,\n",
        "            \"textgrid_path\": None,\n",
        "        }\n",
        "\n",
        "    corpus_dir = os.path.join(temp_base, f\"corpus_{label}\")\n",
        "    output_dir = os.path.join(temp_base, f\"output_{label}\")\n",
        "    os.makedirs(corpus_dir, exist_ok=True)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    audio_in_corpus = os.path.join(corpus_dir, f\"{audio_basename}.wav\")\n",
        "    shutil.copy2(audio_file, audio_in_corpus)\n",
        "\n",
        "    lab_file = os.path.join(corpus_dir, f\"{audio_basename}.lab\")\n",
        "    with open(lab_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(transcription)\n",
        "\n",
        "    result = None\n",
        "    for beam, retry_beam in beam_sizes:\n",
        "        cmd = [\n",
        "            mfa_command,\n",
        "            \"align\",\n",
        "            corpus_dir,\n",
        "            dictionary_id,\n",
        "            acoustic_id,\n",
        "            output_dir,\n",
        "            \"--clean\",\n",
        "            \"--beam\",\n",
        "            str(beam),\n",
        "            \"--retry_beam\",\n",
        "            str(retry_beam),\n",
        "        ]\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300, env=env)\n",
        "        if result.returncode == 0:\n",
        "            break\n",
        "\n",
        "    alignments = []\n",
        "    textgrid_path = os.path.join(output_dir, f\"{audio_basename}.TextGrid\")\n",
        "    if result and result.returncode == 0 and os.path.exists(textgrid_path):\n",
        "        try:\n",
        "            from textgrid import TextGrid\n",
        "\n",
        "            tg = TextGrid.fromFile(textgrid_path)\n",
        "            for tier in tg.tiers:\n",
        "                if tier.name.lower() in [\"phones\", \"phone\"]:\n",
        "                    for interval in tier:\n",
        "                        if interval.mark.strip():\n",
        "                            alignments.append(\n",
        "                                {\n",
        "                                    \"phoneme\": interval.mark.strip(),\n",
        "                                    \"start\": interval.minTime,\n",
        "                                    \"end\": interval.maxTime,\n",
        "                                }\n",
        "                            )\n",
        "                    break\n",
        "        except ImportError:\n",
        "            pass\n",
        "\n",
        "    quality = validate_mfa_alignment(alignments, audio_duration=audio_duration, expected_phone_count=expected_phone_count)\n",
        "\n",
        "    return {\n",
        "        \"alignments\": alignments,\n",
        "        \"quality\": quality,\n",
        "        \"stdout\": result.stdout if result else \"\",\n",
        "        \"stderr\": result.stderr if result else \"\",\n",
        "        \"returncode\": result.returncode if result else None,\n",
        "        \"textgrid_path\": textgrid_path if os.path.exists(textgrid_path) else None,\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Audio trimming helper for MFA (keep original for POWSM)\n",
        "\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "\n",
        "\n",
        "def trim_audio_for_mfa(waveform: np.ndarray, sr: int, top_db: float = 40.0):\n",
        "    \"\"\"Trim leading/trailing silence for MFA alignment.\n",
        "    Returns trimmed audio, (start_sec, end_sec), and a flag indicating trimming was applied.\n",
        "    \"\"\"\n",
        "    if waveform.ndim > 1:\n",
        "        waveform = librosa.to_mono(waveform.T)\n",
        "    non_silent, idx = librosa.effects.trim(waveform, top_db=top_db)\n",
        "    if idx is None or len(non_silent) == 0:\n",
        "        return waveform, (0.0, len(waveform) / sr), False\n",
        "    start_sample, end_sample = idx\n",
        "    start_sec = start_sample / sr\n",
        "    end_sec = end_sample / sr\n",
        "    # Only consider it trimmed if we actually removed something noticeable (>10ms)\n",
        "    trimmed = (start_sample > sr * 0.01) or (len(waveform) - end_sample > sr * 0.01)\n",
        "    return non_silent, (start_sec, end_sec), trimmed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading POWSM models...\n",
            "  - Loading language detection model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 74329.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - Loading Phone Recognition (PR) model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 75089.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - Loading ASR model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 78713.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - Loading G2P model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 84368.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ All POWSM models loaded!\n"
          ]
        }
      ],
      "source": [
        "# Load POWSM models\n",
        "\n",
        "device = \"cpu\"  # Change to \"cuda\" if GPU available\n",
        "\n",
        "print(\"Loading POWSM models...\")\n",
        "\n",
        "# Language detection model\n",
        "print(\"  - Loading language detection model...\")\n",
        "s2lang = Speech2Language.from_pretrained(\n",
        "    \"espnet/powsm\",\n",
        "    device=device,\n",
        "    nbest=1,\n",
        "    first_lang_sym=\"<afr>\",\n",
        "    last_lang_sym=\"<zul>\"\n",
        ")\n",
        "\n",
        "# Phone Recognition model\n",
        "print(\"  - Loading Phone Recognition (PR) model...\")\n",
        "s2t_pr = Speech2Text.from_pretrained(\n",
        "    \"espnet/powsm\",\n",
        "    device=device,\n",
        "    lang_sym=\"<eng>\",\n",
        "    task_sym=\"<pr>\",\n",
        ")\n",
        "\n",
        "# ASR model (for G2P)\n",
        "print(\"  - Loading ASR model...\")\n",
        "s2t_asr = Speech2Text.from_pretrained(\n",
        "    \"espnet/powsm\",\n",
        "    device=device,\n",
        "    lang_sym=\"<eng>\",\n",
        "    task_sym=\"<asr>\",\n",
        ")\n",
        "\n",
        "# G2P model\n",
        "print(\"  - Loading G2P model...\")\n",
        "s2t_g2p = Speech2Text.from_pretrained(\n",
        "    \"espnet/powsm\",\n",
        "    device=device,\n",
        "    lang_sym=\"<eng>\",\n",
        "    task_sym=\"<g2p>\",\n",
        ")\n",
        "\n",
        "print(\"âœ“ All POWSM models loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio: audio/powsm/12/umit12-r.wav\n",
            "Text: The weather is rather warm this Thursday. I think we should go to the theater together. Thank you for thinking about this thoroughly....\n"
          ]
        }
      ],
      "source": [
        "# CONFIG: Set audio file and text file paths\n",
        "\n",
        "AUDIO_FILE = Path(\"./audio/powsm/12/umit12-r.wav\")\n",
        "TEXT_FILE = Path(\"./audio/powsm/12/text\")\n",
        "\n",
        "if not AUDIO_FILE.exists():\n",
        "    raise FileNotFoundError(f\"Audio file not found: {AUDIO_FILE}\")\n",
        "\n",
        "if not TEXT_FILE.exists():\n",
        "    raise FileNotFoundError(f\"Text file not found: {TEXT_FILE}\")\n",
        "\n",
        "with open(TEXT_FILE, 'r', encoding='utf-8') as f:\n",
        "    target_text = f.read().strip()\n",
        "\n",
        "audio_file = str(AUDIO_FILE)\n",
        "audio_basename = AUDIO_FILE.stem\n",
        "\n",
        "print(f\"Audio: {AUDIO_FILE}\")\n",
        "print(f\"Text: {target_text}...\")\n",
        "\n",
        "def map_errors_to_timestamps(\n",
        "    operations: List,\n",
        "    actual_phones: List[str],\n",
        "    target_phones: List[str],\n",
        "    mfa_alignments_actual: List[Dict],\n",
        "    mfa_alignments_target: List[Dict],\n",
        "    sample_rate: int\n",
        ") -> List[Dict]:\n",
        "    errors_with_timestamps = []\n",
        "\n",
        "    def pick_alignments(op_type: str):\n",
        "        if op_type == \"delete\":\n",
        "            return mfa_alignments_target or mfa_alignments_actual or []\n",
        "        return mfa_alignments_actual or mfa_alignments_target or []\n",
        "\n",
        "    def fallback_stamp(pos: int):\n",
        "        start_time = pos * 0.1\n",
        "        end_time = (pos + 1) * 0.1\n",
        "        return {\n",
        "            \"timestamp_seconds\": {\"start\": start_time, \"end\": end_time},\n",
        "            \"timestamp_samples\": {\"start\": int(start_time * sample_rate), \"end\": int(end_time * sample_rate)},\n",
        "        }\n",
        "\n",
        "    for op in operations:\n",
        "        op_type = op[0]\n",
        "        pos = op[1]\n",
        "        alignments = pick_alignments(op_type)\n",
        "        error_dict = {\"type\": op_type, \"position\": pos}\n",
        "\n",
        "        if op_type == \"substitute\":\n",
        "            error_dict[\"expected\"] = op[2] if len(op) > 2 else None\n",
        "            error_dict[\"actual\"] = op[3] if len(op) > 3 else None\n",
        "            if pos < len(alignments):\n",
        "                align = alignments[pos]\n",
        "                error_dict[\"timestamp_seconds\"] = {\"start\": align[\"start\"], \"end\": align[\"end\"]}\n",
        "                error_dict[\"timestamp_samples\"] = {\n",
        "                    \"start\": int(align[\"start\"] * sample_rate),\n",
        "                    \"end\": int(align[\"end\"] * sample_rate),\n",
        "                }\n",
        "            else:\n",
        "                error_dict.update(fallback_stamp(pos))\n",
        "        elif op_type == \"insert\":\n",
        "            error_dict[\"actual\"] = op[2] if len(op) > 2 else None\n",
        "            if pos > 0 and pos <= len(alignments):\n",
        "                if pos < len(alignments):\n",
        "                    prev_end = alignments[pos - 1][\"end\"]\n",
        "                    next_start = alignments[pos][\"start\"]\n",
        "                    mid_time = (prev_end + next_start) / 2\n",
        "                    error_dict[\"timestamp_seconds\"] = {\"start\": mid_time - 0.05, \"end\": mid_time + 0.05}\n",
        "                else:\n",
        "                    last_end = alignments[-1][\"end\"]\n",
        "                    error_dict[\"timestamp_seconds\"] = {\"start\": last_end, \"end\": last_end + 0.1}\n",
        "            else:\n",
        "                error_dict[\"timestamp_seconds\"] = {\"start\": 0.0, \"end\": 0.1}\n",
        "            error_dict[\"timestamp_samples\"] = {\n",
        "                \"start\": int(error_dict[\"timestamp_seconds\"][\"start\"] * sample_rate),\n",
        "                \"end\": int(error_dict[\"timestamp_seconds\"][\"end\"] * sample_rate),\n",
        "            }\n",
        "        elif op_type == \"delete\":\n",
        "            error_dict[\"expected\"] = op[2] if len(op) > 2 else None\n",
        "            if pos < len(alignments):\n",
        "                align = alignments[pos]\n",
        "                error_dict[\"timestamp_seconds\"] = {\"start\": align[\"start\"], \"end\": align[\"end\"]}\n",
        "                error_dict[\"timestamp_samples\"] = {\n",
        "                    \"start\": int(align[\"start\"] * sample_rate),\n",
        "                    \"end\": int(align[\"end\"] * sample_rate),\n",
        "                }\n",
        "            else:\n",
        "                error_dict.update(fallback_stamp(pos))\n",
        "        else:\n",
        "            error_dict.update(fallback_stamp(pos))\n",
        "\n",
        "        errors_with_timestamps.append(error_dict)\n",
        "\n",
        "    return errors_with_timestamps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio loaded: 20.00s @ 16000Hz (MFA uses trimmed 9.15s, trimmed=True)\n",
            "\n",
            "Step 1: Phone Recognition...\n",
            "Detected 86 phones\n",
            "\n",
            "Step 2: G2P...\n",
            "Target: 85 phones\n",
            "\n",
            "Step 3: MFA Alignment...\n",
            "Aligned target 77 phones\n",
            "Aligned actual 68 phones\n",
            "\n",
            "Step 4: Error Detection...\n",
            "Errors: 8, Score: 93.53%\n",
            "\n",
            "Word Error Rate: 21.74%\n",
            "\n",
            "Results saved to: results/umit12-r_20251211_115310.json\n",
            "Pronunciation Score: 93.53%\n",
            "Word Error Rate: 21.74%\n"
          ]
        }
      ],
      "source": [
        "# Load audio\n",
        "\n",
        "try:\n",
        "    speech, rate = sf.read(audio_file)\n",
        "except Exception as e:\n",
        "    print(f\"soundfile failed, trying librosa...\")\n",
        "    speech, rate = librosa.load(audio_file, sr=16000)\n",
        "\n",
        "# Trim for MFA alignment only (keep original for POWSM inference)\n",
        "speech_mfa, (trim_start, trim_end), was_trimmed = trim_audio_for_mfa(speech, rate, top_db=40.0)\n",
        "trimmed_duration = len(speech_mfa) / rate\n",
        "\n",
        "audio_duration = len(speech) / rate\n",
        "print(f\"Audio loaded: {audio_duration:.2f}s @ {rate}Hz (MFA uses trimmed {trimmed_duration:.2f}s, trimmed={was_trimmed})\")\n",
        "\n",
        "# Step 1: Extract actual pronunciation from audio\n",
        "\n",
        "print(\"\\nStep 1: Phone Recognition...\")\n",
        "result_pr = s2t_pr(speech, text_prev=\"<na>\")\n",
        "pred_pr = result_pr[0][0]\n",
        "\n",
        "if \"<notimestamps>\" in pred_pr:\n",
        "    pred_pr = pred_pr.split(\"<notimestamps>\")[1].strip()\n",
        "else:\n",
        "    pred_pr = pred_pr.strip()\n",
        "\n",
        "actual_phones = parse_powsm_phones(pred_pr)\n",
        "print(f\"Detected {len(actual_phones)} phones\")\n",
        "\n",
        "# Step 2: Generate target pronunciation from text\n",
        "\n",
        "print(\"\\nStep 2: G2P...\")\n",
        "result_asr = s2t_asr(speech, text_prev=\"<na>\")\n",
        "pred_asr = result_asr[0][0]\n",
        "if \"<notimestamps>\" in pred_asr:\n",
        "    pred_asr = pred_asr.split(\"<notimestamps>\")[1].strip()\n",
        "else:\n",
        "    pred_asr = pred_asr.strip()\n",
        "\n",
        "result_g2p = s2t_g2p(speech, text_prev=target_text)\n",
        "pred_g2p = result_g2p[0][0]\n",
        "if \"<notimestamps>\" in pred_g2p:\n",
        "    pred_g2p = pred_g2p.split(\"<notimestamps>\")[1].strip()\n",
        "else:\n",
        "    pred_g2p = pred_g2p.strip()\n",
        "\n",
        "target_phones = parse_powsm_phones(pred_g2p)\n",
        "print(f\"Target: {len(target_phones)} phones\")\n",
        "\n",
        "# Step 3: MFA alignment\n",
        "\n",
        "print(\"\\nStep 3: MFA Alignment...\")\n",
        "mfa_alignments_target = []\n",
        "mfa_alignments_actual = []\n",
        "mfa_quality_target = {}\n",
        "mfa_quality_actual = {}\n",
        "beam_sizes = ((400, 1600))\n",
        "\n",
        "if MFA_AVAILABLE:\n",
        "    with tempfile.TemporaryDirectory() as temp_base:\n",
        "        try:\n",
        "            mfa_command = MFA_CMD if MFA_CMD else \"mfa\"\n",
        "            env = os.environ.copy()\n",
        "            if 'MFA_CONDA_ENV_PATH' in globals() and MFA_CONDA_ENV_PATH:\n",
        "                conda_bin = os.path.join(MFA_CONDA_ENV_PATH, \"bin\")\n",
        "                env[\"PATH\"] = conda_bin + os.pathsep + env.get(\"PATH\", \"\")\n",
        "\n",
        "            # Write trimmed audio for MFA use\n",
        "            trimmed_audio_path = os.path.join(temp_base, \"audio_for_mfa.wav\")\n",
        "            sf.write(trimmed_audio_path, speech_mfa, rate)\n",
        "            audio_used_for_mfa = trimmed_audio_path if was_trimmed else audio_file\n",
        "\n",
        "            target_result = run_mfa_alignment(\n",
        "                audio_file=audio_used_for_mfa,\n",
        "                transcription=target_text,\n",
        "                audio_basename=audio_basename,\n",
        "                temp_base=temp_base,\n",
        "                mfa_command=mfa_command,\n",
        "                env=env,\n",
        "                beam_sizes=beam_sizes,\n",
        "                audio_duration=trimmed_duration if was_trimmed else audio_duration,\n",
        "                expected_phone_count=len(target_phones),\n",
        "                label=\"target\",\n",
        "            )\n",
        "            mfa_alignments_target = target_result[\"alignments\"]\n",
        "            mfa_quality_target = target_result[\"quality\"]\n",
        "            if mfa_alignments_target:\n",
        "                print(f\"Aligned target {len(mfa_alignments_target)} phones\")\n",
        "            else:\n",
        "                print(\"No target alignment returned\")\n",
        "\n",
        "            actual_result = run_mfa_alignment(\n",
        "                audio_file=audio_used_for_mfa,\n",
        "                transcription=pred_asr,\n",
        "                audio_basename=audio_basename,\n",
        "                temp_base=temp_base,\n",
        "                mfa_command=mfa_command,\n",
        "                env=env,\n",
        "                beam_sizes=beam_sizes,\n",
        "                audio_duration=trimmed_duration if was_trimmed else audio_duration,\n",
        "                expected_phone_count=len(actual_phones),\n",
        "                label=\"actual\",\n",
        "            )\n",
        "            mfa_alignments_actual = actual_result[\"alignments\"]\n",
        "            mfa_quality_actual = actual_result[\"quality\"]\n",
        "            if mfa_alignments_actual:\n",
        "                print(f\"Aligned actual {len(mfa_alignments_actual)} phones\")\n",
        "            else:\n",
        "                print(\"No actual alignment returned\")\n",
        "        except Exception as e:\n",
        "            print(f\"MFA error: {e}\")\n",
        "else:\n",
        "    print(\"MFA not available; using estimated timestamps\")\n",
        "\n",
        "# Step 4: Compare actual vs target\n",
        "\n",
        "print(\"\\nStep 4: Error Detection...\")\n",
        "sys.path.insert(0, str(mod_path / \"assessment\"))\n",
        "from edit_distance import edit_operations\n",
        "\n",
        "operations = edit_operations(actual_phones, target_phones)\n",
        "# Operations format:\n",
        "# - insert: (op_type, pos_in_actual, actual_value) - extra element you said\n",
        "# - delete: (op_type, pos_in_target, target_value) - missing element you should have said\n",
        "# - substitute: (op_type, pos_in_actual, expected, actual_value) - changed FROM expected TO actual_value\n",
        "substitutes = [op for op in operations if op[0] == \"substitute\"]\n",
        "inserts = [op for op in operations if op[0] == \"insert\"]\n",
        "deletes = [op for op in operations if op[0] == \"delete\"]\n",
        "\n",
        "total_phonemes = len(target_phones)\n",
        "if total_phonemes == 0:\n",
        "    score = 1.0 if len(actual_phones) == 0 else 0.0\n",
        "else:\n",
        "    error_cost = sum(\n",
        "        1 if op[0] == \"delete\" else\n",
        "        1 if op[0] == \"insert\" else\n",
        "        2 if op[0] == \"substitute\" else 0\n",
        "        for op in operations\n",
        "    )\n",
        "    max_cost = total_phonemes * 2\n",
        "    score = max(0.0, 1.0 - (error_cost / max_cost))\n",
        "\n",
        "print(f\"Errors: {len(operations)}, Score: {score:.2%}\")\n",
        "\n",
        "# Step 5: Map errors to timestamps\n",
        "\n",
        "errors_with_timestamps = map_errors_to_timestamps(\n",
        "    operations,\n",
        "    actual_phones,\n",
        "    target_phones,\n",
        "    mfa_alignments_actual,\n",
        "    mfa_alignments_target,\n",
        "    rate,\n",
        ")\n",
        "\n",
        "# Step 6: Word-level comparison\n",
        "\n",
        "import re\n",
        "def tokenize_words(text: str):\n",
        "    if not text:\n",
        "        return []\n",
        "    return re.findall(r\"[A-Za-z']+\", text.lower())\n",
        "\n",
        "target_words = tokenize_words(target_text)\n",
        "actual_words = tokenize_words(pred_asr)\n",
        "word_operations = edit_operations(actual_words, target_words)\n",
        "\n",
        "if len(target_words) == 0:\n",
        "    word_error_rate = 0.0 if len(actual_words) == 0 else 1.0\n",
        "else:\n",
        "    word_error_rate = len(word_operations) / len(target_words)\n",
        "\n",
        "print(f\"\\nWord Error Rate: {word_error_rate:.2%}\")\n",
        "\n",
        "# Save results\n",
        "\n",
        "from datetime import datetime\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "assessment_result = {\n",
        "    \"metadata\": {\n",
        "        \"audio_file\": os.path.basename(audio_file),\n",
        "        \"audio_path\": audio_file,\n",
        "        \"audio_basename\": audio_basename,\n",
        "        \"audio_duration_seconds\": audio_duration,\n",
        "        \"sample_rate\": rate,\n",
        "        \"timestamp\": timestamp,\n",
        "        \"trim_for_mfa_seconds\": {\n",
        "            \"start\": trim_start,\n",
        "            \"end\": trim_end,\n",
        "            \"duration\": trimmed_duration,\n",
        "            \"applied\": was_trimmed,\n",
        "        },\n",
        "    },    \n",
        "    \"statistics\": {\n",
        "        \"total_errors\": len(operations),\n",
        "        \"substitutions\": len(substitutes),\n",
        "        \"insertions\": len(inserts),\n",
        "        \"deletions\": len(deletes),\n",
        "        \"actual_phone_count\": len(actual_phones),\n",
        "        \"target_phone_count\": len(target_phones),\n",
        "    },\n",
        "    \"word_level\": {\n",
        "        \"target_words\": target_words,\n",
        "        \"actual_words\": actual_words,\n",
        "        \"errors\": word_operations,\n",
        "        \"statistics\": {\n",
        "            \"total_errors\": len(word_operations),\n",
        "            \"target_word_count\": len(target_words),\n",
        "            \"actual_word_count\": len(actual_words),\n",
        "            \"word_error_rate\": word_error_rate,\n",
        "        },\n",
        "    },\n",
        "    \"target_text\": target_text,\n",
        "    \"actual_text\": pred_asr,\n",
        "    \"actual_ipa_powsm\": pred_pr,\n",
        "    \"target_ipa_powsm\": pred_g2p,\n",
        "    \"actual_phones\": actual_phones,\n",
        "    \"target_phones\": target_phones,\n",
        "    \"score\": score,\n",
        "    \"errors\": errors_with_timestamps,\n",
        "    \"mfa_alignments\": mfa_alignments_actual or mfa_alignments_target,\n",
        "    \"mfa_alignments_actual\": mfa_alignments_actual,\n",
        "    \"mfa_alignments_target\": mfa_alignments_target,\n",
        "    \"mfa\": {\n",
        "        \"available\": MFA_AVAILABLE,\n",
        "        \"target\": {\n",
        "            \"quality_score\": mfa_quality_target.get(\"quality_score\"),\n",
        "            \"warnings\": mfa_quality_target.get(\"warnings\", []),\n",
        "            \"metrics\": mfa_quality_target,\n",
        "        },\n",
        "        \"actual\": {\n",
        "            \"quality_score\": mfa_quality_actual.get(\"quality_score\"),\n",
        "            \"warnings\": mfa_quality_actual.get(\"warnings\", []),\n",
        "            \"metrics\": mfa_quality_actual,\n",
        "        },\n",
        "    },\n",
        "\n",
        "}\n",
        "\n",
        "output_dir = Path(\"results\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "output_filename = f\"{audio_basename}_{timestamp}.json\"\n",
        "output_file = output_dir / output_filename\n",
        "\n",
        "assessment_result[\"metadata\"][\"output_file\"] = str(output_file)\n",
        "\n",
        "def _json_default(obj):\n",
        "    try:\n",
        "        import numpy as np  # local import to avoid dependency if not needed\n",
        "        if isinstance(obj, (np.bool_,)):\n",
        "            return bool(obj)\n",
        "        if isinstance(obj, (np.integer,)):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, (np.floating,)):\n",
        "            return float(obj)\n",
        "    except Exception:\n",
        "        pass\n",
        "    raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(assessment_result, f, indent=2, ensure_ascii=False, default=_json_default)\n",
        "\n",
        "print(f\"\\nResults saved to: {output_file}\")\n",
        "print(f\"Pronunciation Score: {score:.2%}\")\n",
        "print(f\"Word Error Rate: {word_error_rate:.2%}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
