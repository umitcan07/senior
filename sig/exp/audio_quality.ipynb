{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3801970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Quality Metrics: SNR, VAD, Empty Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04625648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "def calculate_snr(signal, noise):\n",
    "    \"\"\"\n",
    "    Calculate Signal-to-Noise Ratio (SNR) in dB.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal : array-like\n",
    "        The clean signal\n",
    "    noise : array-like\n",
    "        The noise signal (must be same length as signal)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    snr_db : float\n",
    "        SNR in decibels\n",
    "    \"\"\"\n",
    "    # Ensure arrays are numpy arrays and same length\n",
    "    signal = np.array(signal)\n",
    "    noise = np.array(noise)\n",
    "    \n",
    "    if len(signal) != len(noise):\n",
    "        raise ValueError(\"Signal and noise must have the same length\")\n",
    "    \n",
    "    # Calculate power (mean squared value)\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if noise_power == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    # Calculate SNR in dB\n",
    "    snr_db = 10 * np.log10(signal_power / noise_power)\n",
    "    \n",
    "    return snr_db\n",
    "\n",
    "def calculate_snr_from_files(clean_file, noisy_file):\n",
    "    \"\"\"\n",
    "    Calculate SNR between two audio files.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    clean_file : str\n",
    "        Path to clean/reference audio file\n",
    "    noisy_file : str\n",
    "        Path to noisy audio file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    snr_db : float\n",
    "        SNR in decibels\n",
    "    \"\"\"\n",
    "    # Load audio files\n",
    "    clean, sr_clean = librosa.load(clean_file, sr=None)\n",
    "    noisy, sr_noisy = librosa.load(noisy_file, sr=None)\n",
    "    \n",
    "    # Resample if sample rates differ\n",
    "    if sr_clean != sr_noisy:\n",
    "        noisy = librosa.resample(noisy, orig_sr=sr_noisy, target_sr=sr_clean)\n",
    "    \n",
    "    # Trim to same length\n",
    "    min_len = min(len(clean), len(noisy))\n",
    "    clean = clean[:min_len]\n",
    "    noisy = noisy[:min_len]\n",
    "    \n",
    "    # Calculate noise as difference\n",
    "    noise = noisy - clean\n",
    "    \n",
    "    # Calculate SNR\n",
    "    snr_db = calculate_snr(clean, noise)\n",
    "    \n",
    "    return snr_db\n",
    "\n",
    "def detect_noise_segments(signal, sr, frame_length=2048, hop_length=512, energy_threshold_percentile=20):\n",
    "    \"\"\"\n",
    "    Detect noise-only segments in an audio signal using energy-based Voice Activity Detection (VAD).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal : array-like\n",
    "        Audio signal\n",
    "    sr : int\n",
    "        Sample rate\n",
    "    frame_length : int\n",
    "        Frame length for analysis\n",
    "    hop_length : int\n",
    "        Hop length for analysis\n",
    "    energy_threshold_percentile : float\n",
    "        Percentile to use as threshold (lower = more sensitive to noise)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    noise_mask : array\n",
    "        Boolean mask indicating noise segments\n",
    "    \"\"\"\n",
    "    signal = np.array(signal)\n",
    "    frame_energy = []\n",
    "    \n",
    "    # Calculate frame energy\n",
    "    for i in range(0, len(signal) - frame_length + 1, hop_length):\n",
    "        frame = signal[i:i + frame_length]\n",
    "        energy = np.mean(frame ** 2)\n",
    "        frame_energy.append(energy)\n",
    "    \n",
    "    frame_energy = np.array(frame_energy)\n",
    "    \n",
    "    # Use percentile as threshold (lower energy segments are likely noise)\n",
    "    threshold = np.percentile(frame_energy, energy_threshold_percentile)\n",
    "    \n",
    "    # Identify noise frames\n",
    "    noise_frames = frame_energy < threshold\n",
    "    \n",
    "    # Convert frame-level mask to sample-level mask\n",
    "    noise_mask = np.zeros(len(signal), dtype=bool)\n",
    "    for i, is_noise in enumerate(noise_frames):\n",
    "        start = i * hop_length\n",
    "        end = min(start + frame_length, len(signal))\n",
    "        noise_mask[start:end] = is_noise\n",
    "    \n",
    "    return noise_mask\n",
    "\n",
    "def estimate_noise_from_signal(signal, sr, method='vad', **kwargs):\n",
    "    \"\"\"\n",
    "    Estimate noise characteristics from a single audio signal.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal : array-like\n",
    "        Audio signal\n",
    "    sr : int\n",
    "        Sample rate\n",
    "    method : str\n",
    "        Method to use: 'vad' (Voice Activity Detection) or 'spectral_subtraction'\n",
    "    **kwargs\n",
    "        Additional parameters for noise detection\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    noise_estimate : array\n",
    "        Estimated noise signal\n",
    "    noise_mask : array\n",
    "        Boolean mask indicating noise segments\n",
    "    \"\"\"\n",
    "    signal = np.array(signal)\n",
    "    \n",
    "    if method == 'vad':\n",
    "        # Use VAD to detect noise segments\n",
    "        noise_mask = detect_noise_segments(signal, sr, **kwargs)\n",
    "        \n",
    "        # Estimate noise from detected segments\n",
    "        if np.any(noise_mask):\n",
    "            # Use noise segments directly\n",
    "            noise_estimate = signal.copy()\n",
    "            noise_estimate[~noise_mask] = 0  # Zero out speech segments\n",
    "        else:\n",
    "            # If no noise segments found, use minimum energy approach\n",
    "            frame_length = kwargs.get('frame_length', 2048)\n",
    "            hop_length = kwargs.get('hop_length', 512)\n",
    "            frame_energy = []\n",
    "            for i in range(0, len(signal) - frame_length + 1, hop_length):\n",
    "                frame = signal[i:i + frame_length]\n",
    "                energy = np.mean(frame ** 2)\n",
    "                frame_energy.append(energy)\n",
    "            frame_energy = np.array(frame_energy)\n",
    "            min_energy_idx = np.argmin(frame_energy)\n",
    "            start = min_energy_idx * hop_length\n",
    "            end = min(start + frame_length, len(signal))\n",
    "            noise_estimate = np.zeros_like(signal)\n",
    "            noise_estimate[start:end] = signal[start:end]\n",
    "            noise_mask = np.zeros(len(signal), dtype=bool)\n",
    "            noise_mask[start:end] = True\n",
    "    \n",
    "    elif method == 'spectral_subtraction':\n",
    "        # Estimate noise from spectral minimums (assumes stationary noise)\n",
    "        stft = librosa.stft(signal)\n",
    "        magnitude = np.abs(stft)\n",
    "        \n",
    "        # Estimate noise spectrum as minimum over time\n",
    "        noise_spectrum = np.min(magnitude, axis=1, keepdims=True)\n",
    "        \n",
    "        # Reconstruct noise signal\n",
    "        noise_stft = noise_spectrum * np.exp(1j * np.angle(stft))\n",
    "        noise_estimate = librosa.istft(noise_stft, length=len(signal))\n",
    "        noise_mask = np.ones(len(signal), dtype=bool)  # All segments considered\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    return noise_estimate, noise_mask\n",
    "\n",
    "def detect_empty_segments(signal, sr, frame_length=2048, hop_length=512, quiet_percentile=10, min_segment_duration=0.1):\n",
    "    \"\"\"\n",
    "    Detect almost empty (quiet/silence) segments in a microphone recording.\n",
    "    Since microphone recordings always have background noise, this detects segments\n",
    "    that are significantly quieter than speech segments.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal : array-like\n",
    "        Audio signal\n",
    "    sr : int\n",
    "        Sample rate\n",
    "    frame_length : int\n",
    "        Frame length for analysis\n",
    "    hop_length : int\n",
    "        Hop length for analysis\n",
    "    quiet_percentile : float\n",
    "        Percentile threshold for quiet segments (default 10th percentile)\n",
    "        Lower values = more sensitive (detects more quiet segments)\n",
    "    min_segment_duration : float\n",
    "        Minimum duration in seconds for a segment to be considered (default 0.1s)\n",
    "        Filters out very brief quiet moments\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    empty_mask : array\n",
    "        Boolean mask indicating quiet/almost empty segments\n",
    "    empty_segments : list\n",
    "        List of tuples (start_time, end_time) in seconds for each quiet segment\n",
    "    \"\"\"\n",
    "    signal = np.array(signal)\n",
    "    frame_energy = []\n",
    "    frame_times = []\n",
    "    \n",
    "    # Calculate frame energy\n",
    "    for i in range(0, len(signal) - frame_length + 1, hop_length):\n",
    "        frame = signal[i:i + frame_length]\n",
    "        energy = np.mean(frame ** 2)\n",
    "        frame_energy.append(energy)\n",
    "        frame_times.append(i / sr)  # Time in seconds\n",
    "    \n",
    "    frame_energy = np.array(frame_energy)\n",
    "    frame_times = np.array(frame_times)\n",
    "    \n",
    "    if len(frame_energy) == 0 or np.max(frame_energy) == 0:\n",
    "        # If signal is completely silent\n",
    "        empty_mask = np.ones(len(signal), dtype=bool)\n",
    "        empty_segments = [(0, len(signal) / sr)]\n",
    "        return empty_mask, empty_segments\n",
    "    \n",
    "    # Use percentile-based threshold - segments below this are considered \"almost empty\"\n",
    "    # This accounts for the fact that microphone recordings always have background noise\n",
    "    threshold_linear = np.percentile(frame_energy, quiet_percentile)\n",
    "    \n",
    "    # Alternative: Use median of lower quartile as threshold (more robust)\n",
    "    # This identifies segments that are significantly quieter than typical speech\n",
    "    lower_quartile_energy = frame_energy[frame_energy < np.percentile(frame_energy, 25)]\n",
    "    if len(lower_quartile_energy) > 0:\n",
    "        # Use median of quietest 25% as threshold\n",
    "        threshold_linear = np.median(lower_quartile_energy)\n",
    "    else:\n",
    "        threshold_linear = np.percentile(frame_energy, quiet_percentile)\n",
    "    \n",
    "    # Identify quiet frames (almost empty segments)\n",
    "    quiet_frames = frame_energy < threshold_linear\n",
    "    \n",
    "    # Convert frame-level mask to sample-level mask\n",
    "    empty_mask = np.zeros(len(signal), dtype=bool)\n",
    "    for i, is_quiet in enumerate(quiet_frames):\n",
    "        start = i * hop_length\n",
    "        end = min(start + frame_length, len(signal))\n",
    "        empty_mask[start:end] = is_quiet\n",
    "    \n",
    "    # Extract continuous quiet segments (filter by minimum duration)\n",
    "    empty_segments = []\n",
    "    in_segment = False\n",
    "    segment_start = 0\n",
    "    min_frames = int(min_segment_duration * sr / hop_length)\n",
    "    segment_start_frame = 0\n",
    "    \n",
    "    for i, is_quiet in enumerate(quiet_frames):\n",
    "        if is_quiet and not in_segment:\n",
    "            # Start of new quiet segment\n",
    "            in_segment = True\n",
    "            segment_start = frame_times[i]\n",
    "            segment_start_frame = i\n",
    "        elif not is_quiet and in_segment:\n",
    "            # End of quiet segment\n",
    "            in_segment = False\n",
    "            segment_end = frame_times[i]\n",
    "            # Only include if segment is long enough\n",
    "            if (i - segment_start_frame) >= min_frames:\n",
    "                empty_segments.append((segment_start, segment_end))\n",
    "    \n",
    "    # Handle case where segment extends to end\n",
    "    if in_segment:\n",
    "        segment_end = len(signal) / sr\n",
    "        if (len(quiet_frames) - segment_start_frame) >= min_frames:\n",
    "            empty_segments.append((segment_start, segment_end))\n",
    "    \n",
    "    return empty_mask, empty_segments\n",
    "\n",
    "def calculate_snr_from_single_file(audio_file, method='vad', **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate SNR from a single audio file by estimating noise.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    audio_file : str\n",
    "        Path to audio file\n",
    "    method : str\n",
    "        Method to estimate noise: 'vad' or 'spectral_subtraction'\n",
    "    **kwargs\n",
    "        Additional parameters for noise estimation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    snr_db : float\n",
    "        SNR in decibels\n",
    "    noise_estimate : array\n",
    "        Estimated noise signal\n",
    "    noise_mask : array\n",
    "        Boolean mask indicating noise segments\n",
    "    empty_mask : array\n",
    "        Boolean mask indicating empty/almost empty segments\n",
    "    empty_segments : list\n",
    "        List of tuples (start_time, end_time) in seconds for each empty segment\n",
    "    \"\"\"\n",
    "    # Load audio file\n",
    "    signal, sr = librosa.load(audio_file, sr=None)\n",
    "    \n",
    "    # Estimate noise\n",
    "    noise_estimate, noise_mask = estimate_noise_from_signal(signal, sr, method=method, **kwargs)\n",
    "    \n",
    "    # Detect almost empty (quiet) segments\n",
    "    quiet_percentile = kwargs.get('quiet_percentile', 10)\n",
    "    min_segment_duration = kwargs.get('min_segment_duration', 0.1)\n",
    "    empty_mask, empty_segments = detect_empty_segments(signal, sr, quiet_percentile=quiet_percentile, min_segment_duration=min_segment_duration)\n",
    "    \n",
    "    # Calculate signal power (from speech segments if using VAD)\n",
    "    if method == 'vad' and np.any(~noise_mask):\n",
    "        signal_segments = signal[~noise_mask]\n",
    "        signal_power = np.mean(signal_segments ** 2)\n",
    "    else:\n",
    "        signal_power = np.mean(signal ** 2)\n",
    "    \n",
    "    # Calculate noise power\n",
    "    if np.any(noise_mask):\n",
    "        noise_segments = noise_estimate[noise_mask]\n",
    "        noise_power = np.mean(noise_segments ** 2) if len(noise_segments) > 0 else np.mean(noise_estimate ** 2)\n",
    "    else:\n",
    "        noise_power = np.mean(noise_estimate ** 2)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if noise_power == 0:\n",
    "        snr_db = np.inf\n",
    "    else:\n",
    "        snr_db = 10 * np.log10(signal_power / noise_power)\n",
    "    \n",
    "    return snr_db, noise_estimate, noise_mask, empty_mask, empty_segments\n",
    "\n",
    "def calculate_clipping_ratio(signal, threshold=0.99):\n",
    "    \"\"\"\n",
    "    Calculate the clipping ratio of an audio signal.\n",
    "    \n",
    "    Clipping occurs when audio samples exceed the maximum representable amplitude,\n",
    "    causing distortion. This function calculates the percentage of samples that\n",
    "    are at or near the clipping threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal : array-like\n",
    "        Audio signal (assumed to be normalized to [-1, 1])\n",
    "    threshold : float\n",
    "        Threshold for considering a sample as clipped (default 0.99)\n",
    "        Values at or above this absolute value are considered clipped\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    clipping_ratio : float\n",
    "        Percentage of samples that are clipped (0-100)\n",
    "    num_clipped : int\n",
    "        Number of clipped samples\n",
    "    peak_amplitude : float\n",
    "        Maximum absolute amplitude in the signal\n",
    "    \"\"\"\n",
    "    signal = np.array(signal)\n",
    "    \n",
    "    # Count samples at or above threshold (both positive and negative)\n",
    "    clipped_mask = np.abs(signal) >= threshold\n",
    "    num_clipped = np.sum(clipped_mask)\n",
    "    \n",
    "    # Calculate ratio as percentage\n",
    "    clipping_ratio = (num_clipped / len(signal)) * 100\n",
    "    \n",
    "    # Get peak amplitude\n",
    "    peak_amplitude = np.max(np.abs(signal))\n",
    "    \n",
    "    return clipping_ratio, num_clipped, peak_amplitude\n",
    "\n",
    "def calculate_clipping_from_file(audio_file, threshold=0.99):\n",
    "    \"\"\"\n",
    "    Calculate clipping ratio from an audio file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    audio_file : str\n",
    "        Path to audio file\n",
    "    threshold : float\n",
    "        Threshold for considering a sample as clipped (default 0.99)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    clipping_ratio : float\n",
    "        Percentage of samples that are clipped (0-100)\n",
    "    num_clipped : int\n",
    "        Number of clipped samples\n",
    "    peak_amplitude : float\n",
    "        Maximum absolute amplitude in the signal\n",
    "    peak_db : float\n",
    "        Peak amplitude in dB (relative to full scale)\n",
    "    \"\"\"\n",
    "    # Load audio file\n",
    "    signal, sr = librosa.load(audio_file, sr=None)\n",
    "    \n",
    "    clipping_ratio, num_clipped, peak_amplitude = calculate_clipping_ratio(signal, threshold)\n",
    "    \n",
    "    # Calculate peak in dB (dBFS - decibels relative to full scale)\n",
    "    if peak_amplitude > 0:\n",
    "        peak_db = 20 * np.log10(peak_amplitude)\n",
    "    else:\n",
    "        peak_db = -np.inf\n",
    "    \n",
    "    return clipping_ratio, num_clipped, peak_amplitude, peak_db\n",
    "\n",
    "def visualize_segments(signal, sr, noise_mask, empty_mask, empty_segments, width=80):\n",
    "    \"\"\"\n",
    "    Visualize audio segments in terminal with colors.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal : array-like\n",
    "        Audio signal\n",
    "    sr : int\n",
    "        Sample rate\n",
    "    noise_mask : array\n",
    "        Boolean mask for noise segments\n",
    "    empty_mask : array\n",
    "        Boolean mask for empty/quiet segments\n",
    "    empty_segments : list\n",
    "        List of (start, end) tuples in seconds\n",
    "    width : int\n",
    "        Width of visualization in characters\n",
    "    \"\"\"\n",
    "    duration = len(signal) / sr\n",
    "    \n",
    "    # ANSI color codes\n",
    "    RESET = '\\033[0m'\n",
    "    SPEECH = '\\033[92m'  # Green\n",
    "    NOISE = '\\033[93m'   # Yellow\n",
    "    EMPTY = '\\033[91m'   # Red\n",
    "    BOLD = '\\033[1m'\n",
    "    \n",
    "    # Create timeline visualization\n",
    "    timeline = []\n",
    "    for i in range(width):\n",
    "        # Map character position to time\n",
    "        t = (i / width) * duration\n",
    "        sample_idx = int(t * sr)\n",
    "        if sample_idx >= len(signal):\n",
    "            sample_idx = len(signal) - 1\n",
    "        \n",
    "        if empty_mask[sample_idx]:\n",
    "            timeline.append(f\"{EMPTY}█{RESET}\")\n",
    "        elif noise_mask[sample_idx]:\n",
    "            timeline.append(f\"{NOISE}█{RESET}\")\n",
    "        else:\n",
    "            timeline.append(f\"{SPEECH}█{RESET}\")\n",
    "    \n",
    "    # Create legend\n",
    "    legend = f\"{BOLD}Legend:{RESET} {SPEECH}█{RESET} Speech  {NOISE}█{RESET} Noise  {EMPTY}█{RESET} Empty/Quiet\"\n",
    "    \n",
    "    # Format empty segments nicely\n",
    "    formatted_segments = []\n",
    "    for start, end in empty_segments:\n",
    "        formatted_segments.append(f\"({float(start):.3f}, {float(end):.3f})\")\n",
    "    \n",
    "    return ''.join(timeline), legend, formatted_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4e4da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SNR, clipping ratio, and empty segments from single files:\n",
      "\n",
      "\n",
      "================================================================================\n",
      "File: 01.wav\n",
      "================================================================================\n",
      "SNR: 17.61 dB\n",
      "Peak amplitude: 0.7030 (-3.06 dBFS)\n",
      "Clipping ratio: 0.0000% (0 samples)\n",
      "Noise segments: 20.8%\n",
      "Empty/almost empty segments: 12.3%\n",
      "Number of empty segments: 1\n",
      "\n",
      "\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[93m█\u001b[0m\u001b[93m█\u001b[0m\n",
      "\u001b[1mLegend:\u001b[0m \u001b[92m█\u001b[0m Speech  \u001b[93m█\u001b[0m Noise  \u001b[91m█\u001b[0m Empty/Quiet\n",
      "\n",
      "Empty segment times (seconds):\n",
      "  (0.000, 1.088)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "File: 02.wav\n",
      "================================================================================\n",
      "SNR: 16.87 dB\n",
      "Peak amplitude: 0.7143 (-2.92 dBFS)\n",
      "Clipping ratio: 0.0000% (0 samples)\n",
      "Noise segments: 20.9%\n",
      "Empty/almost empty segments: 13.3%\n",
      "Number of empty segments: 6\n",
      "\n",
      "\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[91m█\u001b[0m\u001b[93m█\u001b[0m\u001b[93m█\u001b[0m\u001b[91m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[91m█\u001b[0m\n",
      "\u001b[1mLegend:\u001b[0m \u001b[92m█\u001b[0m Speech  \u001b[93m█\u001b[0m Noise  \u001b[91m█\u001b[0m Empty/Quiet\n",
      "\n",
      "Empty segment times (seconds):\n",
      "  (0.000, 0.608)\n",
      "  (6.912, 7.040)\n",
      "  (7.136, 7.296)\n",
      "  (8.544, 8.704)\n",
      "  (8.864, 8.960)\n",
      "  (10.816, 11.049)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "File: 03.wav\n",
      "================================================================================\n",
      "SNR: 18.04 dB\n",
      "Peak amplitude: 0.9626 (-0.33 dBFS)\n",
      "Clipping ratio: 0.0000% (0 samples)\n",
      "Noise segments: 20.7%\n",
      "Empty/almost empty segments: 13.2%\n",
      "Number of empty segments: 3\n",
      "\n",
      "\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[93m█\u001b[0m\u001b[93m█\u001b[0m\u001b[93m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\n",
      "\u001b[1mLegend:\u001b[0m \u001b[92m█\u001b[0m Speech  \u001b[93m█\u001b[0m Noise  \u001b[91m█\u001b[0m Empty/Quiet\n",
      "\n",
      "Empty segment times (seconds):\n",
      "  (0.000, 0.352)\n",
      "  (0.704, 0.960)\n",
      "  (9.568, 10.217)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "File: 04.wav\n",
      "================================================================================\n",
      "SNR: 15.99 dB\n",
      "Peak amplitude: 0.8905 (-1.01 dBFS)\n",
      "Clipping ratio: 0.0000% (0 samples)\n",
      "Noise segments: 21.2%\n",
      "Empty/almost empty segments: 13.3%\n",
      "Number of empty segments: 3\n",
      "\n",
      "\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[91m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[93m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\n",
      "\u001b[1mLegend:\u001b[0m \u001b[92m█\u001b[0m Speech  \u001b[93m█\u001b[0m Noise  \u001b[91m█\u001b[0m Empty/Quiet\n",
      "\n",
      "Empty segment times (seconds):\n",
      "  (0.000, 0.384)\n",
      "  (5.696, 5.792)\n",
      "  (7.584, 8.169)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "File: 05.wav\n",
      "================================================================================\n",
      "SNR: 17.23 dB\n",
      "Peak amplitude: 0.8673 (-1.24 dBFS)\n",
      "Clipping ratio: 0.0000% (0 samples)\n",
      "Noise segments: 20.7%\n",
      "Empty/almost empty segments: 13.1%\n",
      "Number of empty segments: 3\n",
      "\n",
      "\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[91m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[93m█\u001b[0m\u001b[91m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[92m█\u001b[0m\u001b[93m█\u001b[0m\u001b[91m█\u001b[0m\u001b[93m█\u001b[0m\u001b[91m█\u001b[0m\n",
      "\u001b[1mLegend:\u001b[0m \u001b[92m█\u001b[0m Speech  \u001b[93m█\u001b[0m Noise  \u001b[91m█\u001b[0m Empty/Quiet\n",
      "\n",
      "Empty segment times (seconds):\n",
      "  (0.000, 0.864)\n",
      "  (9.984, 10.112)\n",
      "  (10.240, 10.495)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate SNR from single audio files\n",
    "dir = \"./audio/development/ruken\"\n",
    "\n",
    "# Get all wav files\n",
    "wav_files = sorted([f for f in os.listdir(dir) if f.endswith(\".wav\")])\n",
    "\n",
    "print(\"Calculating SNR, clipping ratio, and empty segments from single files:\\n\")\n",
    "for wav_file in wav_files[:5]:  # Process first 5 files\n",
    "    file_path = os.path.join(dir, wav_file)\n",
    "    signal, sr = librosa.load(file_path, sr=None)\n",
    "    snr, noise_est, noise_mask, empty_mask, empty_segments = calculate_snr_from_single_file(file_path, method='vad')\n",
    "    \n",
    "    # Calculate clipping ratio\n",
    "    clipping_ratio, num_clipped, peak_amplitude, peak_db = calculate_clipping_from_file(file_path)\n",
    "    \n",
    "    noise_percentage = np.sum(noise_mask) / len(noise_mask) * 100\n",
    "    empty_percentage = np.sum(empty_mask) / len(empty_mask) * 100\n",
    "    \n",
    "    # Visualize segments\n",
    "    timeline, legend, formatted_segments = visualize_segments(signal, sr, noise_mask, empty_mask, empty_segments)\n",
    "    \n",
    "    # Print results with visualization\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"File: {wav_file}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"SNR: {snr:.2f} dB\")\n",
    "    print(f\"Peak amplitude: {peak_amplitude:.4f} ({peak_db:.2f} dBFS)\")\n",
    "    print(f\"Clipping ratio: {clipping_ratio:.4f}% ({num_clipped} samples)\")\n",
    "    print(f\"Noise segments: {noise_percentage:.1f}%\")\n",
    "    print(f\"Empty/almost empty segments: {empty_percentage:.1f}%\")\n",
    "    print(f\"Number of empty segments: {len(empty_segments)}\")\n",
    "    print()\n",
    "    print(timeline)\n",
    "    print(legend)\n",
    "    print()\n",
    "    if formatted_segments:\n",
    "        print(f\"Empty segment times (seconds):\")\n",
    "        for seg in formatted_segments:\n",
    "            print(f\"  {seg}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
